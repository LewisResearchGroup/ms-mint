{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MS-MINT","text":"<p>MS-MINT (Mass Spectrometry-Metabolomics Integration Toolkit) is a Python library for large-scale targeted metabolomics.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Fast Processing: Handle large batches of MS files efficiently</li> <li>Interactive Visualization: Explore your data with interactive plots</li> <li>Target Optimization: Automatically optimize retention time parameters</li> <li>Flexible Export: Export results in various formats for downstream analysis</li> </ul>"},{"location":"installation/","title":"Installation instructions","text":"<p>You can install the latest release of ms-mint directly from PyPI using pip:</p> <pre><code>pip install ms-mint\n</code></pre> <p>This will install the core library for use in scripts, notebooks, or other Python-based workflows.</p> <p>Note: As of version <code>1.0.0</code>, ms-mint uses PEP 621 standards via <code>pyproject.toml</code> for packaging. If you plan to install from source or contribute, ensure you have an up-to-date version of <code>pip</code>, <code>setuptools</code>, and <code>build</code> installed:</p> <pre><code>pip install --upgrade pip setuptools build\n</code></pre> <p>To install the latest development version directly from GitHub:</p> <pre><code>pip install git+https://github.com/LewisResearchGroup/ms-mint.git\n</code></pre> <p>For most users, the PyPI version is sufficient and recommended.</p>"},{"location":"quickstart/","title":"Quickstart","text":"<p>Here\u2019s a minimal working example to get started with <code>ms-mint</code> in just a few steps:</p>"},{"location":"quickstart/#1-install-the-package","title":"1. Install the package","text":"<pre><code>pip install ms-mint\n</code></pre>"},{"location":"quickstart/#2-import-the-library","title":"2. Import the library","text":"<p>If you're using a script:</p> <pre><code>from ms_mint.Mint import Mint\nmint = Mint()\n</code></pre> <p>If you're using a Jupyter notebook:</p> <pre><code>%pylab inline\nfrom ms_mint.notebook import Mint\nmint = Mint()\n</code></pre>"},{"location":"quickstart/#3-load-your-mass-spectrometry-data-files","title":"3. Load your mass spectrometry data files","text":"<p>You can load individual files:</p> <pre><code>mint.ms_files = [\n    './input/sample1.mzML',\n    './input/sample2.mzXML',\n]\n</code></pre> <p>Or use wildcards to load multiple files:</p> <pre><code>mint.load_files('./input/*.mzML')\n</code></pre>"},{"location":"quickstart/#4-load-your-target-list","title":"4. Load your target list","text":"<p>From a CSV file:</p> <pre><code>mint.load_targets('targets.csv')\n</code></pre> <p>Or directly from a pandas DataFrame:</p> <pre><code>import pandas as pd\n\ntargets = pd.read_csv('targets.csv')\nmint.targets = targets\n</code></pre>"},{"location":"quickstart/#5-run-the-analysis","title":"5. Run the analysis","text":"<pre><code>mint.run()\n</code></pre> <p>If you're working with thousands of files, save results directly to a file to save memory:</p> <pre><code>mint.run(fn='results.csv')\n</code></pre>"},{"location":"quickstart/#6-view-results","title":"6. View results","text":"<pre><code>mint.results\n</code></pre>"},{"location":"quickstart/#optional-optimize-retention-time-ranges","title":"Optional: Optimize retention time ranges","text":"<p>For better peak detection, especially if your RT values are estimates:</p> <pre><code>mint.opt.rt_min_max(\n    peak_labels=['Xanthine', 'Succinate'],\n    plot=True\n)\n</code></pre> <p>You\u2019re now ready to process large-scale targeted metabolomics datasets with <code>ms-mint</code>!</p> <p>Continue with visualization or the structure of target lists.</p>"},{"location":"api_reference/","title":"API overview","text":""},{"location":"api_reference/core/","title":"Core classes (Mint, Chromatogram)","text":"<p>Main module of the ms-mint library.</p> <p>options:   show_root_heading: true   show_root_full_path: true   show_submodules: true   members_order: source</p> <p>Experimental module to run Mint interactively inside the Jupyter notebook.</p> Example usage <pre><code>from ms_mint.notebook import Mint\n\nmint = Mint()\n\nmint.display()\n</code></pre> <p>options:   show_root_heading: true   show_root_full_path: true   show_submodules: true   members_order: source</p>"},{"location":"api_reference/core/#ms_mint.Mint.Mint","title":"<code>Mint</code>","text":"<p>Main class of the ms_mint package for processing metabolomics files.</p> <p>This class provides the primary interface for extracting, processing, and analyzing mass spectrometry data for metabolomics analysis.</p> <p>Attributes:</p> Name Type Description <code>verbose</code> <p>Controls the verbosity level of the instance.</p> <code>version</code> <code>str</code> <p>The version of the ms_mint package being used.</p> <code>progress_callback</code> <p>Function to update progress information.</p> <code>plot</code> <p>Instance of MintPlotter for visualization.</p> <code>opt</code> <p>Instance of TargetOptimizer for target optimization.</p> <code>pca</code> <p>Instance of PrincipalComponentsAnalyser for PCA analysis.</p> <code>tqdm</code> <p>Progress bar utility.</p> <code>wdir</code> <p>Working directory for input/output operations.</p> <code>status</code> <code>str</code> <p>Current status of processing ('waiting', 'running', 'done').</p> <code>ms_files</code> <code>List[str]</code> <p>List of MS files to be processed.</p> <code>n_files</code> <code>int</code> <p>Number of MS files currently loaded.</p> <code>targets</code> <code>DataFrame</code> <p>DataFrame with target compounds information.</p> <code>results</code> <code>DataFrame</code> <p>DataFrame with analysis results.</p> <code>progress</code> <code>float</code> <p>Current progress of processing (0-100).</p> Source code in <code>src/ms_mint/Mint.py</code> <pre><code>class Mint:\n    \"\"\"Main class of the ms_mint package for processing metabolomics files.\n\n    This class provides the primary interface for extracting, processing, and\n    analyzing mass spectrometry data for metabolomics analysis.\n\n    Attributes:\n        verbose: Controls the verbosity level of the instance.\n        version: The version of the ms_mint package being used.\n        progress_callback: Function to update progress information.\n        plot: Instance of MintPlotter for visualization.\n        opt: Instance of TargetOptimizer for target optimization.\n        pca: Instance of PrincipalComponentsAnalyser for PCA analysis.\n        tqdm: Progress bar utility.\n        wdir: Working directory for input/output operations.\n        status: Current status of processing ('waiting', 'running', 'done').\n        ms_files: List of MS files to be processed.\n        n_files: Number of MS files currently loaded.\n        targets: DataFrame with target compounds information.\n        results: DataFrame with analysis results.\n        progress: Current progress of processing (0-100).\n    \"\"\"\n\n    def __init__(\n        self,\n        verbose: bool = False,\n        progress_callback: Optional[Callable[[float], None]] = None,\n        time_unit: str = \"s\",\n        wdir: Optional[Union[str, P]] = None,\n    ) -&gt; None:\n        \"\"\"Initialize a Mint instance.\n\n        Args:\n            verbose: Sets verbosity of the instance.\n            progress_callback: A callback function for reporting progress (0-100).\n            time_unit: Unit for time measurements.\n            wdir: Working directory. If None, uses current directory.\n        \"\"\"\n        self.verbose = verbose\n        self._version = ms_mint.__version__\n        if verbose:\n            print(f\"Mint version: {self.version}\\n\")\n        self.progress_callback = progress_callback\n        self.reset()\n        self.plot = MintPlotter(mint=self)\n        self.opt = TargetOptimizer(mint=self)\n        self.pca = PrincipalComponentsAnalyser(self)\n        self.tqdm = tqdm\n\n        # Setup working directory as pathlib.Path\n        self.wdir = P(os.getcwd() if wdir is None else wdir)\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Get the ms-mint version number.\n\n        Returns:\n            Version string.\n        \"\"\"\n        return self._version\n\n    def reset(self) -&gt; \"Mint\":\n        \"\"\"Reset Mint instance by removing targets, MS-files and results.\n\n        Returns:\n            Self for method chaining.\n        \"\"\"\n        self._files: List[str] = []\n        self._targets_files: List[str] = []\n        self._targets: pd.DataFrame = pd.DataFrame(columns=TARGETS_COLUMNS)\n        self._results: pd.DataFrame = pd.DataFrame({i: [] for i in MINT_RESULTS_COLUMNS})\n        self._all_df: Optional[pd.DataFrame] = None\n        self._progress: float = 0\n        self.runtime: Optional[float] = None\n        self._status: str = \"waiting\"\n        self._messages: List[str] = []\n        self.meta: pd.DataFrame = init_metadata()\n        return self\n\n    def clear_targets(self) -&gt; None:\n        \"\"\"Reset target list.\"\"\"\n        self.targets = pd.DataFrame(columns=TARGETS_COLUMNS)\n\n    def clear_results(self) -&gt; None:\n        \"\"\"Reset results.\"\"\"\n        self.results = pd.DataFrame(columns=MINT_RESULTS_COLUMNS)\n\n    def clear_ms_files(self) -&gt; None:\n        \"\"\"Reset MS files.\"\"\"\n        self.ms_files = []\n\n    def run(\n        self,\n        nthreads: Optional[int] = None,\n        rt_margin: float = 0.5,\n        mode: str = \"standard\",\n        fn: Optional[str] = None,\n        **kwargs,\n    ) -&gt; Optional[\"Mint\"]:\n        \"\"\"Run MINT and process MS-files with current target list.\n\n        Args:\n            nthreads: Number of cores to use. Options:\n                * None - Run with min(n_cpus, n_files) CPUs\n                * 1: Run without multiprocessing on one CPU\n                * &gt;1: Run with multiprocessing using specified threads\n            rt_margin: Margin to add to rt values when rt_min/rt_max not specified.\n            mode: Compute mode, one of:\n                * 'standard': calculates peak shapes projected to RT dimension\n                * 'express': omits calculation of other features, only peak_areas\n            fn: Output filename to save results directly to disk instead of memory.\n            **kwargs: Additional arguments passed to the processing function.\n\n        Returns:\n            Self for method chaining, or None if no files or targets loaded.\n        \"\"\"\n        self._status = \"running\"\n\n        if (self.n_files == 0) or (len(self.targets) == 0):\n            return None\n\n        targets = self.targets.reset_index()\n        self._set_rt_min_max(targets, rt_margin)\n\n        nthreads = self._determine_nthreads(nthreads)\n\n        if self.verbose:\n            print(f\"Run MINT with {nthreads} processes:\")\n\n        start = time.time()\n        if nthreads &gt; 1:\n            self._run_parallel(nthreads=nthreads, mode=mode, fn=fn, **kwargs)\n        else:\n            self._run_sequential(mode=mode, fn=fn, targets=targets)\n\n        self.progress = 100\n        self._report_runtime(start)\n\n        self._status = \"done\"\n        assert self.progress == 100\n        return self\n\n    def _set_rt_min_max(self, targets: pd.DataFrame, rt_margin: float) -&gt; None:\n        \"\"\"Set retention time min/max values based on rt and margin.\n\n        Args:\n            targets: DataFrame containing target information.\n            rt_margin: Margin to add/subtract from rt for min/max.\n        \"\"\"\n        if \"rt\" in targets.columns:\n            update_rt_min = (targets.rt_min.isna()) &amp; (~targets.rt.isna())\n            targets.loc[update_rt_min, \"rt_min\"] = targets.loc[update_rt_min, \"rt\"] - rt_margin\n            update_rt_max = (targets.rt_max.isna()) &amp; (~targets.rt.isna())\n            targets.loc[update_rt_max, \"rt_max\"] = targets.loc[update_rt_max, \"rt\"] + rt_margin\n\n    def _determine_nthreads(self, nthreads: Optional[int]) -&gt; int:\n        \"\"\"Determine number of threads to use for parallel processing.\n\n        Args:\n            nthreads: Requested number of threads, or None for automatic.\n\n        Returns:\n            Number of threads to use.\n        \"\"\"\n        if nthreads is None:\n            nthreads = min(cpu_count(), self.n_files)\n        return nthreads\n\n    def _run_sequential(self, mode: str, fn: Optional[str], targets: pd.DataFrame) -&gt; None:\n        \"\"\"Run processing sequentially (single-threaded).\n\n        Args:\n            mode: Processing mode ('standard' or 'express').\n            fn: Output filename or None.\n            targets: DataFrame of targets to process.\n        \"\"\"\n        results = []\n        for i, filename in enumerate(self.ms_files):\n            args = {\n                \"filename\": filename,\n                \"targets\": targets,\n                \"q\": None,\n                \"mode\": mode,\n                \"output_fn\": None,\n            }\n            results.append(process_ms1_files_in_parallel(args))\n            self.progress = int(100 * (i / self.n_files))\n        self.results = pd.concat(results).reset_index(drop=True)\n\n    def _report_runtime(self, start: float) -&gt; None:\n        \"\"\"Report runtime statistics after processing.\n\n        Args:\n            start: Start time of processing in seconds.\n        \"\"\"\n        end = time.time()\n        self.runtime = end - start\n        self.runtime_per_file = self.runtime / self.n_files\n        self.runtime_per_peak = self.runtime / self.n_files / len(self.targets)\n\n        if self.verbose:\n            print(f\"Total runtime: {self.runtime:.2f}s\")\n            print(f\"Runtime per file: {self.runtime_per_file:.2f}s\")\n            print(f\"Runtime per peak ({len(self.targets)}): {self.runtime_per_peak:.2f}s\\n\")\n            print(\"Results:\", self.results)\n\n    def _run_parallel(\n        self,\n        nthreads: int = 1,\n        mode: str = \"standard\",\n        maxtasksperchild: Optional[int] = None,\n        fn: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Run processing in parallel using multiple threads.\n\n        Args:\n            nthreads: Number of threads to use.\n            mode: Processing mode ('standard' or 'express').\n            maxtasksperchild: Maximum number of tasks per child process.\n            fn: Output filename or None.\n        \"\"\"\n        pool = Pool(processes=nthreads, maxtasksperchild=maxtasksperchild)\n        m = Manager()\n        q = m.Queue()\n        args = []\n\n        if fn is not None:\n            # Prepare output file (only headers)\n            pd.DataFrame(columns=MINT_RESULTS_COLUMNS).to_csv(fn, index=False)\n\n        for filename in self.ms_files:\n            args.append(\n                {\n                    \"filename\": filename,\n                    \"targets\": self.targets.reset_index(),\n                    \"queue\": q,\n                    \"mode\": mode,\n                    \"output_fn\": fn,\n                }\n            )\n\n        results = pool.map_async(process_ms1_files_in_parallel, args)\n        self._monitor_progress(results, q)\n\n        pool.close()\n        pool.join()\n\n        if fn is None:\n            results = results.get()\n            self.results = pd.concat(results).reset_index(drop=True)\n\n    def _monitor_progress(self, results: Any, q: Any) -&gt; None:\n        \"\"\"Monitor progress of parallel processing.\n\n        Args:\n            results: AsyncResult object from parallel processing.\n            q: Queue for tracking progress.\n        \"\"\"\n        while not results.ready():\n            size = q.qsize()\n            self.progress = 100 * size / self.n_files\n            time.sleep(1)\n        self.progress = 100\n\n    @property\n    def status(self) -&gt; str:\n        \"\"\"Get current status of Mint instance.\n\n        Returns:\n            Status string, one of: 'waiting', 'running', 'done'\n        \"\"\"\n        return self._status\n\n    @property\n    def ms_files(self) -&gt; List[str]:\n        \"\"\"Get list of MS files to process.\n\n        Returns:\n            List of filenames.\n        \"\"\"\n        return self._files\n\n    @ms_files.setter\n    def ms_files(self, list_of_files: Union[str, List[str]]) -&gt; None:\n        \"\"\"Set MS files to process.\n\n        Args:\n            list_of_files: Filename or list of file names of MS-files.\n        \"\"\"\n        if isinstance(list_of_files, str):\n            list_of_files = [list_of_files]\n        list_of_files = [str(P(i)) for i in list_of_files if is_ms_file(i)]\n        for f in list_of_files:\n            if not os.path.isfile(f):\n                logging.warning(f\"File not found ({f})\")\n        self._files = list_of_files\n        if self.verbose:\n            print(\"Set files to:\\n\" + \"\\n\".join(self.ms_files) + \"\\n\")\n        self.meta = self.meta.reindex([fn_to_label(fn) for fn in list_of_files])\n\n    @property\n    def n_files(self) -&gt; int:\n        \"\"\"Get number of currently stored MS filenames.\n\n        Returns:\n            Number of files stored in self.ms_files\n        \"\"\"\n        return len(self.ms_files)\n\n    def load_files(self, obj: Union[str, List[str]]) -&gt; \"Mint\":\n        \"\"\"Load MS files and return self for chaining.\n\n        Args:\n            obj: Filename pattern (for glob) or list of file names.\n\n        Returns:\n            Self for method chaining.\n        \"\"\"\n        if isinstance(obj, str):\n            self.ms_files = glob(obj, recursive=True)\n        elif isinstance(obj, list):\n            self.ms_files = obj\n        return self\n\n    def load_targets(self, list_of_files: Union[str, P, List[Union[str, P]]]) -&gt; \"Mint\":\n        \"\"\"Load targets from file(s) (csv, xlsx).\n\n        Args:\n            list_of_files: Filename or list of file names.\n\n        Returns:\n            Self for method chaining.\n\n        Raises:\n            ValueError: If input is not a list of files.\n            AssertionError: If a file is not found.\n        \"\"\"\n        if isinstance(list_of_files, str) or isinstance(list_of_files, P):\n            list_of_files = [list_of_files]\n        if not isinstance(list_of_files, list):\n            raise ValueError(\"Input should be a list of files.\")\n        for f in list_of_files:\n            assert os.path.isfile(f), f\"File not found ({f})\"\n        self._targets_files = list_of_files\n        if self.verbose:\n            print(\"Set targets files to:\\n\" + \"\\n\".join(str(f) for f in self._targets_files) + \"\\n\")\n        self.targets = read_targets(list_of_files)\n        return self\n\n    @property\n    def targets(self) -&gt; pd.DataFrame:\n        \"\"\"Get target list.\n\n        Returns:\n            Target list DataFrame.\n        \"\"\"\n        return self._targets\n\n    @targets.setter\n    def targets(self, targets: pd.DataFrame) -&gt; None:\n        \"\"\"Set target list.\n\n        Args:\n            targets: DataFrame containing target information.\n\n        Raises:\n            AssertionError: If targets validation fails.\n        \"\"\"\n        targets = standardize_targets(targets)\n        assert check_targets(targets), check_targets(targets)\n        self._targets = targets.set_index(\"peak_label\")\n        if self.verbose:\n            print(\"Set targets to:\\n\", self.targets.to_string(), \"\\n\")\n\n    def get_target_params(self, peak_label: str) -&gt; Tuple[float, float, float, float]:\n        \"\"\"Get target parameters for a specific peak label.\n\n        Args:\n            peak_label: Label of the target peak.\n\n        Returns:\n            Tuple of (mz_mean, mz_width, rt_min, rt_max).\n        \"\"\"\n        target_data = self.targets.loc[peak_label]\n        mz_mean, mz_width, rt_min, rt_max = target_data[[\"mz_mean\", \"mz_width\", \"rt_min\", \"rt_max\"]]\n        return mz_mean, mz_width, rt_min, rt_max\n\n    @property\n    def peak_labels(self) -&gt; List[str]:\n        \"\"\"Get list of peak labels from targets.\n\n        Returns:\n            List of peak label strings.\n        \"\"\"\n        return self.targets.index.to_list()\n\n    @property\n    def results(self) -&gt; pd.DataFrame:\n        \"\"\"Get results DataFrame.\n\n        Returns:\n            DataFrame containing analysis results.\n        \"\"\"\n        return self._results\n\n    @results.setter\n    def results(self, df: pd.DataFrame) -&gt; None:\n        \"\"\"Set results DataFrame.\n\n        Args:\n            df: DataFrame with MINT results.\n        \"\"\"\n        self._results = df\n\n    def crosstab(\n        self,\n        var_name: Optional[str] = None,\n        index: Optional[Union[str, List[str]]] = None,\n        column: Optional[str] = None,\n        aggfunc: str = \"mean\",\n        apply: Optional[Callable] = None,\n        scaler: Optional[Union[str, Any]] = None,\n        groupby: Optional[Union[str, List[str]]] = None,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Create condensed representation of the results.\n\n        Creates a cross-table with filenames as index and target labels as columns.\n        The values in the cells are determined by var_name.\n\n        Args:\n            var_name: Name of the column from results table for cell values.\n                Defaults to 'peak_area_top3'.\n            index: Column(s) to use as index in the resulting cross-tabulation.\n                Defaults to 'ms_file_label'.\n            column: Column to use as columns in the resulting cross-tabulation.\n                Defaults to 'peak_label'.\n            aggfunc: Aggregation function for aggregating values. Defaults to 'mean'.\n            apply: Function to apply to the resulting cross-tabulation.\n                Options include 'log2p1', 'logp1', or a custom function.\n            scaler: Function or name of scaler to scale the data.\n                Options include 'standard', 'robust', 'minmax', or a scikit-learn scaler.\n            groupby: Column(s) to group data before scaling.\n\n        Returns:\n            DataFrame representing the cross-tabulation.\n\n        Raises:\n            ValueError: If an unsupported scaler is specified.\n        \"\"\"\n        df_meta = pd.merge(self.meta, self.results, left_index=True, right_on=\"ms_file_label\")\n        # Remove None if in index\n        if isinstance(index, list):\n            if None in index:\n                index.remove(None)\n        if isinstance(groupby, str):\n            groupby = [groupby]\n\n        if index is None:\n            index = \"ms_file_label\"\n        if column is None:\n            column = \"peak_label\"\n        if var_name is None:\n            var_name = \"peak_area_top3\"\n        if apply:\n            if apply == \"log2p1\":\n                apply = log2p1\n            if apply == \"logp1\":\n                apply = np.log1p\n            df_meta[var_name] = df_meta[var_name].apply(apply)\n        if isinstance(scaler, str):\n            scaler_dict = {\n                \"standard\": StandardScaler(),\n                \"robust\": RobustScaler(),\n                \"minmax\": MinMaxScaler(),\n            }\n\n            if scaler not in scaler_dict:\n                raise ValueError(f\"Unsupported scaler: {scaler}\")\n\n            scaler = scaler_dict[scaler]\n\n        if scaler:\n            if groupby:\n                groupby_cols = groupby + [column]\n                df_meta[var_name] = df_meta.groupby(groupby_cols)[var_name].transform(\n                    lambda x: self._scale_group(x, scaler)\n                )\n            else:\n                df_meta[var_name] = df_meta.groupby(column)[var_name].transform(\n                    lambda x: self._scale_group(x, scaler)\n                )\n\n        df = pd.pivot_table(\n            df_meta,\n            index=index,\n            columns=column,\n            values=var_name,\n            aggfunc=aggfunc,\n        ).astype(np.float64)\n        return df\n\n    @property\n    def progress(self) -&gt; float:\n        \"\"\"Get current progress value.\n\n        Returns:\n            Current progress value (0-100).\n        \"\"\"\n        return self._progress\n\n    @progress.setter\n    def progress(self, value: float) -&gt; None:\n        \"\"\"Set progress and call progress callback function.\n\n        Args:\n            value: Progress value between 0 and 100.\n\n        Raises:\n            AssertionError: If value is outside the range 0-100.\n        \"\"\"\n        assert value &gt;= 0, value\n        assert value &lt;= 100, value\n        self._progress = value\n        if self.progress_callback is not None:\n            self.progress_callback(value)\n\n    def export(self, fn: Optional[str] = None) -&gt; Optional[BytesIO]:\n        \"\"\"Export current results to file.\n\n        Args:\n            fn: Filename to export to. If None, returns file buffer.\n                Supported formats: .xlsx, .csv, .parquet\n\n        Returns:\n            BytesIO buffer if fn is None, otherwise None.\n        \"\"\"\n        if fn is None:\n            buffer = export_to_excel(self, fn=fn)\n            return buffer\n        elif fn.endswith(\".xlsx\"):\n            export_to_excel(self, fn=fn)\n        elif fn.endswith(\".csv\"):\n            self.results.to_csv(fn, index=False)\n        elif fn.endswith(\".parquet\"):\n            self.results.to_parquet(fn, index=False)\n        return None\n\n    def load(self, fn: Union[str, BytesIO]) -&gt; \"Mint\":\n        \"\"\"Load results into Mint instance.\n\n        Args:\n            fn: Filename (csv, xlsx, parquet) or file-like object.\n\n        Returns:\n            Self for method chaining.\n        \"\"\"\n        if self.verbose:\n            print(f\"Loading MINT results from {fn}\")\n\n        if isinstance(fn, str):\n            if fn.endswith(\"xlsx\"):\n                results = pd.read_excel(fn, sheet_name=\"Results\")\n                self.results = results\n\n            elif fn.endswith(\".csv\"):\n                results = pd.read_csv(fn)\n                results[\"peak_shape_rt\"] = results[\"peak_shape_rt\"].fillna(\"\")\n                results[\"peak_shape_int\"] = results[\"peak_shape_int\"].fillna(\"\")\n                self.results = results\n\n            elif fn.endswith(\".parquet\"):\n                results = pd.read_parquet(fn)\n        else:\n            results = pd.read_csv(fn)\n\n        # Add file labels if not present already\n        if \"ms_file_label\" not in results.columns:\n            results[\"ms_file_label\"] = [fn_to_label(fn) for fn in results.ms_file]\n\n        self.results = results.rename(columns=DEPRECATED_LABELS)\n        self.digest_results()\n        return self\n\n    def digest_results(self) -&gt; None:\n        \"\"\"Extract MS files and targets from results and set them in the instance.\"\"\"\n        self.ms_files = get_ms_files_from_results(self.results)\n        self.targets = get_targets_from_results(self.results)\n\n    def get_chromatograms(\n        self,\n        fns: Optional[List[str]] = None,\n        peak_labels: Optional[List[str]] = None,\n        filters: Optional[List[Any]] = None,\n        **kwargs,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Get chromatograms for specified files and peak labels.\n\n        Args:\n            fns: List of filenames to extract chromatograms from. Defaults to all MS files.\n            peak_labels: List of peak labels to extract. Defaults to all peak labels.\n            filters: List of filters to apply to the chromatograms.\n            **kwargs: Additional arguments to pass to the Chromatogram constructor.\n\n        Returns:\n            DataFrame containing chromatogram data.\n        \"\"\"\n        if fns is None:\n            fns = self.ms_files\n        if peak_labels is None:\n            peak_labels = self.peak_labels\n        return self._get_chromatograms(\n            fns=tuple(fns),\n            peak_labels=tuple(peak_labels),\n            filters=tuple(filters) if filters is not None else None,\n            **kwargs,\n        )\n\n    @lru_cache(1)\n    def _get_chromatograms(\n        self,\n        fns: Optional[Tuple[str, ...]] = None,\n        peak_labels: Optional[Tuple[str, ...]] = None,\n        filters: Optional[Tuple[Any, ...]] = None,\n        **kwargs,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Cached implementation of get_chromatograms.\n\n        Args:\n            fns: Tuple of filenames to extract chromatograms from.\n            peak_labels: Tuple of peak labels to extract.\n            filters: Tuple of filters to apply to the chromatograms.\n            **kwargs: Additional arguments to pass to the Chromatogram constructor.\n\n        Returns:\n            DataFrame containing chromatogram data.\n        \"\"\"\n        if isinstance(fns, tuple):\n            fns = list(fns)\n\n        if not isinstance(fns, list):\n            fns = [fns]\n\n        labels = [fn_to_label(fn) for fn in fns]\n\n        # Need to get the actual file names with get_chromatogramsath\n        # in case only ms_file_labels are provided\n        fns = [fn for fn in self.ms_files if fn_to_label(fn) in labels]\n\n        data = []\n\n        for fn in self.tqdm(fns, desc=\"Loading chromatograms\"):\n            df = ms_file_to_df(fn)\n            for label in peak_labels:\n                mz_mean, mz_width, rt_min, rt_max = self.get_target_params(label)\n                chrom_raw = extract_chromatogram_from_ms1(\n                    df, mz_mean=mz_mean, mz_width=mz_width\n                ).to_frame()\n                if len(chrom_raw) == 0:\n                    continue\n                chrom = Chromatogram(chrom_raw.index, chrom_raw.values, filters=filters, **kwargs)\n                if filters is not None:\n                    chrom.apply_filters()\n                chrom_data = chrom.data\n                chrom_data[\"ms_file\"] = fn\n                chrom_data[\"ms_file_label\"] = fn_to_label(fn)\n                chrom_data[\"peak_label\"] = label\n                chrom_data[\"rt_min\"] = rt_min\n                chrom_data[\"rt_max\"] = rt_max\n                data.append(chrom_data)\n\n        data = pd.concat(data).reset_index()\n\n        data[\"ms_file\"] = data[\"ms_file\"].apply(lambda x: P(x).with_suffix(\"\").name)\n        return data\n\n    def load_metadata(self, fn: Optional[Union[str, P]] = None) -&gt; \"Mint\":\n        \"\"\"Load metadata from file.\n\n        Args:\n            fn: Filename to load metadata from. Defaults to metadata.parquet in working directory.\n\n        Returns:\n            Self for method chaining.\n        \"\"\"\n        if fn is None:\n            fn = self.wdir / METADATA_DEFAUT_FN\n        if str(fn).endswith(\".csv\"):\n            self.meta = pd.read_csv(fn, index_col=0)\n        elif str(fn).endswith(\".parquet\"):\n            self.meta = pd.read_parquet(fn)\n        if \"ms_file_label\" in self.meta.columns:\n            self.meta = self.meta.set_index(\"ms_file_label\")\n        return self\n\n    def save_metadata(self, fn: Optional[Union[str, P]] = None) -&gt; \"Mint\":\n        \"\"\"Save metadata to file.\n\n        Args:\n            fn: Filename to save metadata to. Defaults to metadata.parquet in working directory.\n\n        Returns:\n            Self for method chaining.\n        \"\"\"\n        if fn is None:\n            fn = self.wdir / METADATA_DEFAUT_FN\n        if str(fn).endswith(\".csv\"):\n            self.meta.to_csv(fn, na_filter=False)\n        elif str(fn).endswith(\".parquet\"):\n            self.meta.to_parquet(fn)\n        return self\n\n    def _scale_group(self, group: pd.Series, scaler: Any) -&gt; np.ndarray:\n        \"\"\"Scale a group of values using a scaler.\n\n        Args:\n            group: Series of values to scale.\n            scaler: Scikit-learn scaler with fit_transform method.\n\n        Returns:\n            Scaled values as a numpy array.\n        \"\"\"\n        return scaler.fit_transform(group.to_numpy().reshape(-1, 1)).flatten()\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.ms_files","title":"<code>ms_files: List[str]</code>  <code>property</code> <code>writable</code>","text":"<p>Get list of MS files to process.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of filenames.</p>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.n_files","title":"<code>n_files: int</code>  <code>property</code>","text":"<p>Get number of currently stored MS filenames.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of files stored in self.ms_files</p>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.peak_labels","title":"<code>peak_labels: List[str]</code>  <code>property</code>","text":"<p>Get list of peak labels from targets.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of peak label strings.</p>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.progress","title":"<code>progress: float</code>  <code>property</code> <code>writable</code>","text":"<p>Get current progress value.</p> <p>Returns:</p> Type Description <code>float</code> <p>Current progress value (0-100).</p>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.results","title":"<code>results: pd.DataFrame</code>  <code>property</code> <code>writable</code>","text":"<p>Get results DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing analysis results.</p>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.status","title":"<code>status: str</code>  <code>property</code>","text":"<p>Get current status of Mint instance.</p> <p>Returns:</p> Type Description <code>str</code> <p>Status string, one of: 'waiting', 'running', 'done'</p>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.targets","title":"<code>targets: pd.DataFrame</code>  <code>property</code> <code>writable</code>","text":"<p>Get target list.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Target list DataFrame.</p>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.version","title":"<code>version: str</code>  <code>property</code>","text":"<p>Get the ms-mint version number.</p> <p>Returns:</p> Type Description <code>str</code> <p>Version string.</p>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.__init__","title":"<code>__init__(verbose=False, progress_callback=None, time_unit='s', wdir=None)</code>","text":"<p>Initialize a Mint instance.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>Sets verbosity of the instance.</p> <code>False</code> <code>progress_callback</code> <code>Optional[Callable[[float], None]]</code> <p>A callback function for reporting progress (0-100).</p> <code>None</code> <code>time_unit</code> <code>str</code> <p>Unit for time measurements.</p> <code>'s'</code> <code>wdir</code> <code>Optional[Union[str, Path]]</code> <p>Working directory. If None, uses current directory.</p> <code>None</code> Source code in <code>src/ms_mint/Mint.py</code> <pre><code>def __init__(\n    self,\n    verbose: bool = False,\n    progress_callback: Optional[Callable[[float], None]] = None,\n    time_unit: str = \"s\",\n    wdir: Optional[Union[str, P]] = None,\n) -&gt; None:\n    \"\"\"Initialize a Mint instance.\n\n    Args:\n        verbose: Sets verbosity of the instance.\n        progress_callback: A callback function for reporting progress (0-100).\n        time_unit: Unit for time measurements.\n        wdir: Working directory. If None, uses current directory.\n    \"\"\"\n    self.verbose = verbose\n    self._version = ms_mint.__version__\n    if verbose:\n        print(f\"Mint version: {self.version}\\n\")\n    self.progress_callback = progress_callback\n    self.reset()\n    self.plot = MintPlotter(mint=self)\n    self.opt = TargetOptimizer(mint=self)\n    self.pca = PrincipalComponentsAnalyser(self)\n    self.tqdm = tqdm\n\n    # Setup working directory as pathlib.Path\n    self.wdir = P(os.getcwd() if wdir is None else wdir)\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.clear_ms_files","title":"<code>clear_ms_files()</code>","text":"<p>Reset MS files.</p> Source code in <code>src/ms_mint/Mint.py</code> <pre><code>def clear_ms_files(self) -&gt; None:\n    \"\"\"Reset MS files.\"\"\"\n    self.ms_files = []\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.clear_results","title":"<code>clear_results()</code>","text":"<p>Reset results.</p> Source code in <code>src/ms_mint/Mint.py</code> <pre><code>def clear_results(self) -&gt; None:\n    \"\"\"Reset results.\"\"\"\n    self.results = pd.DataFrame(columns=MINT_RESULTS_COLUMNS)\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.clear_targets","title":"<code>clear_targets()</code>","text":"<p>Reset target list.</p> Source code in <code>src/ms_mint/Mint.py</code> <pre><code>def clear_targets(self) -&gt; None:\n    \"\"\"Reset target list.\"\"\"\n    self.targets = pd.DataFrame(columns=TARGETS_COLUMNS)\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.crosstab","title":"<code>crosstab(var_name=None, index=None, column=None, aggfunc='mean', apply=None, scaler=None, groupby=None)</code>","text":"<p>Create condensed representation of the results.</p> <p>Creates a cross-table with filenames as index and target labels as columns. The values in the cells are determined by var_name.</p> <p>Parameters:</p> Name Type Description Default <code>var_name</code> <code>Optional[str]</code> <p>Name of the column from results table for cell values. Defaults to 'peak_area_top3'.</p> <code>None</code> <code>index</code> <code>Optional[Union[str, List[str]]]</code> <p>Column(s) to use as index in the resulting cross-tabulation. Defaults to 'ms_file_label'.</p> <code>None</code> <code>column</code> <code>Optional[str]</code> <p>Column to use as columns in the resulting cross-tabulation. Defaults to 'peak_label'.</p> <code>None</code> <code>aggfunc</code> <code>str</code> <p>Aggregation function for aggregating values. Defaults to 'mean'.</p> <code>'mean'</code> <code>apply</code> <code>Optional[Callable]</code> <p>Function to apply to the resulting cross-tabulation. Options include 'log2p1', 'logp1', or a custom function.</p> <code>None</code> <code>scaler</code> <code>Optional[Union[str, Any]]</code> <p>Function or name of scaler to scale the data. Options include 'standard', 'robust', 'minmax', or a scikit-learn scaler.</p> <code>None</code> <code>groupby</code> <code>Optional[Union[str, List[str]]]</code> <p>Column(s) to group data before scaling.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame representing the cross-tabulation.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an unsupported scaler is specified.</p> Source code in <code>src/ms_mint/Mint.py</code> <pre><code>def crosstab(\n    self,\n    var_name: Optional[str] = None,\n    index: Optional[Union[str, List[str]]] = None,\n    column: Optional[str] = None,\n    aggfunc: str = \"mean\",\n    apply: Optional[Callable] = None,\n    scaler: Optional[Union[str, Any]] = None,\n    groupby: Optional[Union[str, List[str]]] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"Create condensed representation of the results.\n\n    Creates a cross-table with filenames as index and target labels as columns.\n    The values in the cells are determined by var_name.\n\n    Args:\n        var_name: Name of the column from results table for cell values.\n            Defaults to 'peak_area_top3'.\n        index: Column(s) to use as index in the resulting cross-tabulation.\n            Defaults to 'ms_file_label'.\n        column: Column to use as columns in the resulting cross-tabulation.\n            Defaults to 'peak_label'.\n        aggfunc: Aggregation function for aggregating values. Defaults to 'mean'.\n        apply: Function to apply to the resulting cross-tabulation.\n            Options include 'log2p1', 'logp1', or a custom function.\n        scaler: Function or name of scaler to scale the data.\n            Options include 'standard', 'robust', 'minmax', or a scikit-learn scaler.\n        groupby: Column(s) to group data before scaling.\n\n    Returns:\n        DataFrame representing the cross-tabulation.\n\n    Raises:\n        ValueError: If an unsupported scaler is specified.\n    \"\"\"\n    df_meta = pd.merge(self.meta, self.results, left_index=True, right_on=\"ms_file_label\")\n    # Remove None if in index\n    if isinstance(index, list):\n        if None in index:\n            index.remove(None)\n    if isinstance(groupby, str):\n        groupby = [groupby]\n\n    if index is None:\n        index = \"ms_file_label\"\n    if column is None:\n        column = \"peak_label\"\n    if var_name is None:\n        var_name = \"peak_area_top3\"\n    if apply:\n        if apply == \"log2p1\":\n            apply = log2p1\n        if apply == \"logp1\":\n            apply = np.log1p\n        df_meta[var_name] = df_meta[var_name].apply(apply)\n    if isinstance(scaler, str):\n        scaler_dict = {\n            \"standard\": StandardScaler(),\n            \"robust\": RobustScaler(),\n            \"minmax\": MinMaxScaler(),\n        }\n\n        if scaler not in scaler_dict:\n            raise ValueError(f\"Unsupported scaler: {scaler}\")\n\n        scaler = scaler_dict[scaler]\n\n    if scaler:\n        if groupby:\n            groupby_cols = groupby + [column]\n            df_meta[var_name] = df_meta.groupby(groupby_cols)[var_name].transform(\n                lambda x: self._scale_group(x, scaler)\n            )\n        else:\n            df_meta[var_name] = df_meta.groupby(column)[var_name].transform(\n                lambda x: self._scale_group(x, scaler)\n            )\n\n    df = pd.pivot_table(\n        df_meta,\n        index=index,\n        columns=column,\n        values=var_name,\n        aggfunc=aggfunc,\n    ).astype(np.float64)\n    return df\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.digest_results","title":"<code>digest_results()</code>","text":"<p>Extract MS files and targets from results and set them in the instance.</p> Source code in <code>src/ms_mint/Mint.py</code> <pre><code>def digest_results(self) -&gt; None:\n    \"\"\"Extract MS files and targets from results and set them in the instance.\"\"\"\n    self.ms_files = get_ms_files_from_results(self.results)\n    self.targets = get_targets_from_results(self.results)\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.export","title":"<code>export(fn=None)</code>","text":"<p>Export current results to file.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Optional[str]</code> <p>Filename to export to. If None, returns file buffer. Supported formats: .xlsx, .csv, .parquet</p> <code>None</code> <p>Returns:</p> Type Description <code>Optional[BytesIO]</code> <p>BytesIO buffer if fn is None, otherwise None.</p> Source code in <code>src/ms_mint/Mint.py</code> <pre><code>def export(self, fn: Optional[str] = None) -&gt; Optional[BytesIO]:\n    \"\"\"Export current results to file.\n\n    Args:\n        fn: Filename to export to. If None, returns file buffer.\n            Supported formats: .xlsx, .csv, .parquet\n\n    Returns:\n        BytesIO buffer if fn is None, otherwise None.\n    \"\"\"\n    if fn is None:\n        buffer = export_to_excel(self, fn=fn)\n        return buffer\n    elif fn.endswith(\".xlsx\"):\n        export_to_excel(self, fn=fn)\n    elif fn.endswith(\".csv\"):\n        self.results.to_csv(fn, index=False)\n    elif fn.endswith(\".parquet\"):\n        self.results.to_parquet(fn, index=False)\n    return None\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.get_chromatograms","title":"<code>get_chromatograms(fns=None, peak_labels=None, filters=None, **kwargs)</code>","text":"<p>Get chromatograms for specified files and peak labels.</p> <p>Parameters:</p> Name Type Description Default <code>fns</code> <code>Optional[List[str]]</code> <p>List of filenames to extract chromatograms from. Defaults to all MS files.</p> <code>None</code> <code>peak_labels</code> <code>Optional[List[str]]</code> <p>List of peak labels to extract. Defaults to all peak labels.</p> <code>None</code> <code>filters</code> <code>Optional[List[Any]]</code> <p>List of filters to apply to the chromatograms.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments to pass to the Chromatogram constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing chromatogram data.</p> Source code in <code>src/ms_mint/Mint.py</code> <pre><code>def get_chromatograms(\n    self,\n    fns: Optional[List[str]] = None,\n    peak_labels: Optional[List[str]] = None,\n    filters: Optional[List[Any]] = None,\n    **kwargs,\n) -&gt; pd.DataFrame:\n    \"\"\"Get chromatograms for specified files and peak labels.\n\n    Args:\n        fns: List of filenames to extract chromatograms from. Defaults to all MS files.\n        peak_labels: List of peak labels to extract. Defaults to all peak labels.\n        filters: List of filters to apply to the chromatograms.\n        **kwargs: Additional arguments to pass to the Chromatogram constructor.\n\n    Returns:\n        DataFrame containing chromatogram data.\n    \"\"\"\n    if fns is None:\n        fns = self.ms_files\n    if peak_labels is None:\n        peak_labels = self.peak_labels\n    return self._get_chromatograms(\n        fns=tuple(fns),\n        peak_labels=tuple(peak_labels),\n        filters=tuple(filters) if filters is not None else None,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.get_target_params","title":"<code>get_target_params(peak_label)</code>","text":"<p>Get target parameters for a specific peak label.</p> <p>Parameters:</p> Name Type Description Default <code>peak_label</code> <code>str</code> <p>Label of the target peak.</p> required <p>Returns:</p> Type Description <code>Tuple[float, float, float, float]</code> <p>Tuple of (mz_mean, mz_width, rt_min, rt_max).</p> Source code in <code>src/ms_mint/Mint.py</code> <pre><code>def get_target_params(self, peak_label: str) -&gt; Tuple[float, float, float, float]:\n    \"\"\"Get target parameters for a specific peak label.\n\n    Args:\n        peak_label: Label of the target peak.\n\n    Returns:\n        Tuple of (mz_mean, mz_width, rt_min, rt_max).\n    \"\"\"\n    target_data = self.targets.loc[peak_label]\n    mz_mean, mz_width, rt_min, rt_max = target_data[[\"mz_mean\", \"mz_width\", \"rt_min\", \"rt_max\"]]\n    return mz_mean, mz_width, rt_min, rt_max\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.load","title":"<code>load(fn)</code>","text":"<p>Load results into Mint instance.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Union[str, BytesIO]</code> <p>Filename (csv, xlsx, parquet) or file-like object.</p> required <p>Returns:</p> Type Description <code>Mint</code> <p>Self for method chaining.</p> Source code in <code>src/ms_mint/Mint.py</code> <pre><code>def load(self, fn: Union[str, BytesIO]) -&gt; \"Mint\":\n    \"\"\"Load results into Mint instance.\n\n    Args:\n        fn: Filename (csv, xlsx, parquet) or file-like object.\n\n    Returns:\n        Self for method chaining.\n    \"\"\"\n    if self.verbose:\n        print(f\"Loading MINT results from {fn}\")\n\n    if isinstance(fn, str):\n        if fn.endswith(\"xlsx\"):\n            results = pd.read_excel(fn, sheet_name=\"Results\")\n            self.results = results\n\n        elif fn.endswith(\".csv\"):\n            results = pd.read_csv(fn)\n            results[\"peak_shape_rt\"] = results[\"peak_shape_rt\"].fillna(\"\")\n            results[\"peak_shape_int\"] = results[\"peak_shape_int\"].fillna(\"\")\n            self.results = results\n\n        elif fn.endswith(\".parquet\"):\n            results = pd.read_parquet(fn)\n    else:\n        results = pd.read_csv(fn)\n\n    # Add file labels if not present already\n    if \"ms_file_label\" not in results.columns:\n        results[\"ms_file_label\"] = [fn_to_label(fn) for fn in results.ms_file]\n\n    self.results = results.rename(columns=DEPRECATED_LABELS)\n    self.digest_results()\n    return self\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.load_files","title":"<code>load_files(obj)</code>","text":"<p>Load MS files and return self for chaining.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Union[str, List[str]]</code> <p>Filename pattern (for glob) or list of file names.</p> required <p>Returns:</p> Type Description <code>Mint</code> <p>Self for method chaining.</p> Source code in <code>src/ms_mint/Mint.py</code> <pre><code>def load_files(self, obj: Union[str, List[str]]) -&gt; \"Mint\":\n    \"\"\"Load MS files and return self for chaining.\n\n    Args:\n        obj: Filename pattern (for glob) or list of file names.\n\n    Returns:\n        Self for method chaining.\n    \"\"\"\n    if isinstance(obj, str):\n        self.ms_files = glob(obj, recursive=True)\n    elif isinstance(obj, list):\n        self.ms_files = obj\n    return self\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.load_metadata","title":"<code>load_metadata(fn=None)</code>","text":"<p>Load metadata from file.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Optional[Union[str, Path]]</code> <p>Filename to load metadata from. Defaults to metadata.parquet in working directory.</p> <code>None</code> <p>Returns:</p> Type Description <code>Mint</code> <p>Self for method chaining.</p> Source code in <code>src/ms_mint/Mint.py</code> <pre><code>def load_metadata(self, fn: Optional[Union[str, P]] = None) -&gt; \"Mint\":\n    \"\"\"Load metadata from file.\n\n    Args:\n        fn: Filename to load metadata from. Defaults to metadata.parquet in working directory.\n\n    Returns:\n        Self for method chaining.\n    \"\"\"\n    if fn is None:\n        fn = self.wdir / METADATA_DEFAUT_FN\n    if str(fn).endswith(\".csv\"):\n        self.meta = pd.read_csv(fn, index_col=0)\n    elif str(fn).endswith(\".parquet\"):\n        self.meta = pd.read_parquet(fn)\n    if \"ms_file_label\" in self.meta.columns:\n        self.meta = self.meta.set_index(\"ms_file_label\")\n    return self\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.load_targets","title":"<code>load_targets(list_of_files)</code>","text":"<p>Load targets from file(s) (csv, xlsx).</p> <p>Parameters:</p> Name Type Description Default <code>list_of_files</code> <code>Union[str, Path, List[Union[str, Path]]]</code> <p>Filename or list of file names.</p> required <p>Returns:</p> Type Description <code>Mint</code> <p>Self for method chaining.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If input is not a list of files.</p> <code>AssertionError</code> <p>If a file is not found.</p> Source code in <code>src/ms_mint/Mint.py</code> <pre><code>def load_targets(self, list_of_files: Union[str, P, List[Union[str, P]]]) -&gt; \"Mint\":\n    \"\"\"Load targets from file(s) (csv, xlsx).\n\n    Args:\n        list_of_files: Filename or list of file names.\n\n    Returns:\n        Self for method chaining.\n\n    Raises:\n        ValueError: If input is not a list of files.\n        AssertionError: If a file is not found.\n    \"\"\"\n    if isinstance(list_of_files, str) or isinstance(list_of_files, P):\n        list_of_files = [list_of_files]\n    if not isinstance(list_of_files, list):\n        raise ValueError(\"Input should be a list of files.\")\n    for f in list_of_files:\n        assert os.path.isfile(f), f\"File not found ({f})\"\n    self._targets_files = list_of_files\n    if self.verbose:\n        print(\"Set targets files to:\\n\" + \"\\n\".join(str(f) for f in self._targets_files) + \"\\n\")\n    self.targets = read_targets(list_of_files)\n    return self\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.reset","title":"<code>reset()</code>","text":"<p>Reset Mint instance by removing targets, MS-files and results.</p> <p>Returns:</p> Type Description <code>Mint</code> <p>Self for method chaining.</p> Source code in <code>src/ms_mint/Mint.py</code> <pre><code>def reset(self) -&gt; \"Mint\":\n    \"\"\"Reset Mint instance by removing targets, MS-files and results.\n\n    Returns:\n        Self for method chaining.\n    \"\"\"\n    self._files: List[str] = []\n    self._targets_files: List[str] = []\n    self._targets: pd.DataFrame = pd.DataFrame(columns=TARGETS_COLUMNS)\n    self._results: pd.DataFrame = pd.DataFrame({i: [] for i in MINT_RESULTS_COLUMNS})\n    self._all_df: Optional[pd.DataFrame] = None\n    self._progress: float = 0\n    self.runtime: Optional[float] = None\n    self._status: str = \"waiting\"\n    self._messages: List[str] = []\n    self.meta: pd.DataFrame = init_metadata()\n    return self\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.run","title":"<code>run(nthreads=None, rt_margin=0.5, mode='standard', fn=None, **kwargs)</code>","text":"<p>Run MINT and process MS-files with current target list.</p> <p>Parameters:</p> Name Type Description Default <code>nthreads</code> <code>Optional[int]</code> <p>Number of cores to use. Options: * None - Run with min(n_cpus, n_files) CPUs * 1: Run without multiprocessing on one CPU * &gt;1: Run with multiprocessing using specified threads</p> <code>None</code> <code>rt_margin</code> <code>float</code> <p>Margin to add to rt values when rt_min/rt_max not specified.</p> <code>0.5</code> <code>mode</code> <code>str</code> <p>Compute mode, one of: * 'standard': calculates peak shapes projected to RT dimension * 'express': omits calculation of other features, only peak_areas</p> <code>'standard'</code> <code>fn</code> <code>Optional[str]</code> <p>Output filename to save results directly to disk instead of memory.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to the processing function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Optional[Mint]</code> <p>Self for method chaining, or None if no files or targets loaded.</p> Source code in <code>src/ms_mint/Mint.py</code> <pre><code>def run(\n    self,\n    nthreads: Optional[int] = None,\n    rt_margin: float = 0.5,\n    mode: str = \"standard\",\n    fn: Optional[str] = None,\n    **kwargs,\n) -&gt; Optional[\"Mint\"]:\n    \"\"\"Run MINT and process MS-files with current target list.\n\n    Args:\n        nthreads: Number of cores to use. Options:\n            * None - Run with min(n_cpus, n_files) CPUs\n            * 1: Run without multiprocessing on one CPU\n            * &gt;1: Run with multiprocessing using specified threads\n        rt_margin: Margin to add to rt values when rt_min/rt_max not specified.\n        mode: Compute mode, one of:\n            * 'standard': calculates peak shapes projected to RT dimension\n            * 'express': omits calculation of other features, only peak_areas\n        fn: Output filename to save results directly to disk instead of memory.\n        **kwargs: Additional arguments passed to the processing function.\n\n    Returns:\n        Self for method chaining, or None if no files or targets loaded.\n    \"\"\"\n    self._status = \"running\"\n\n    if (self.n_files == 0) or (len(self.targets) == 0):\n        return None\n\n    targets = self.targets.reset_index()\n    self._set_rt_min_max(targets, rt_margin)\n\n    nthreads = self._determine_nthreads(nthreads)\n\n    if self.verbose:\n        print(f\"Run MINT with {nthreads} processes:\")\n\n    start = time.time()\n    if nthreads &gt; 1:\n        self._run_parallel(nthreads=nthreads, mode=mode, fn=fn, **kwargs)\n    else:\n        self._run_sequential(mode=mode, fn=fn, targets=targets)\n\n    self.progress = 100\n    self._report_runtime(start)\n\n    self._status = \"done\"\n    assert self.progress == 100\n    return self\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Mint.Mint.save_metadata","title":"<code>save_metadata(fn=None)</code>","text":"<p>Save metadata to file.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Optional[Union[str, Path]]</code> <p>Filename to save metadata to. Defaults to metadata.parquet in working directory.</p> <code>None</code> <p>Returns:</p> Type Description <code>Mint</code> <p>Self for method chaining.</p> Source code in <code>src/ms_mint/Mint.py</code> <pre><code>def save_metadata(self, fn: Optional[Union[str, P]] = None) -&gt; \"Mint\":\n    \"\"\"Save metadata to file.\n\n    Args:\n        fn: Filename to save metadata to. Defaults to metadata.parquet in working directory.\n\n    Returns:\n        Self for method chaining.\n    \"\"\"\n    if fn is None:\n        fn = self.wdir / METADATA_DEFAUT_FN\n    if str(fn).endswith(\".csv\"):\n        self.meta.to_csv(fn, na_filter=False)\n    elif str(fn).endswith(\".parquet\"):\n        self.meta.to_parquet(fn)\n    return self\n</code></pre>"},{"location":"api_reference/core/#ms_mint.notebook.Mint","title":"<code>Mint</code>","text":"<p>               Bases: <code>Mint</code></p> <p>Interactive MINT for Jupyter Notebook environment (experimental).</p> <p>This class extends the base Mint class with interactive widgets and controls for use in Jupyter notebooks, allowing for a graphical user interface to manage MS files, target lists, and process data.</p> <p>Attributes:</p> Name Type Description <code>progress_callback</code> <p>Function to update progress bar.</p> <code>ms_storage_path</code> <p>File chooser widget for MS file directory.</p> <code>target_files_button</code> <p>Upload widget for target files.</p> <code>load_ms_button</code> <p>Button to load MS files from selected directory.</p> <code>message_box</code> <p>Text area for displaying messages.</p> <code>run_button</code> <p>Button to start processing.</p> <code>download_button</code> <p>Button to export results.</p> <code>progress_bar</code> <p>Progress indicator for processing.</p> <code>layout</code> <p>Main container for all widgets.</p> Source code in <code>src/ms_mint/notebook.py</code> <pre><code>class Mint(_Mint_):\n    \"\"\"Interactive MINT for Jupyter Notebook environment (experimental).\n\n    This class extends the base Mint class with interactive widgets and controls\n    for use in Jupyter notebooks, allowing for a graphical user interface to\n    manage MS files, target lists, and process data.\n\n    Attributes:\n        progress_callback: Function to update progress bar.\n        ms_storage_path: File chooser widget for MS file directory.\n        target_files_button: Upload widget for target files.\n        load_ms_button: Button to load MS files from selected directory.\n        message_box: Text area for displaying messages.\n        run_button: Button to start processing.\n        download_button: Button to export results.\n        progress_bar: Progress indicator for processing.\n        layout: Main container for all widgets.\n    \"\"\"\n\n    def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize the interactive Mint instance.\n\n        Args:\n            *args: Positional arguments passed to the parent Mint class.\n            **kwargs: Keyword arguments passed to the parent Mint class.\n        \"\"\"\n        self.progress_callback = self._set_progress_\n\n        super().__init__(progress_callback=self.progress_callback, *args, **kwargs)\n\n        # Initialize file chooser for MS files directory\n        fc = FileChooser()\n        fc.show_only_dirs = True\n        fc.default_path = os.getcwd()\n        self.ms_storage_path = fc\n\n        # Target file upload widget\n        self.target_files_button = W.FileUpload(\n            description=\"Peaklists\", accept=\"csv,xlsx\", multiple=False\n        )\n        self.target_files_button.observe(self._load_target_from_bytes_, names=\"value\")\n\n        # Button to load MS files\n        self.load_ms_button = W.Button(description=\"Load MS-files\")\n        self.load_ms_button.on_click(self._search_files_)\n\n        # Message display area\n        self.message_box = W.Textarea(\n            value=\"\",\n            placeholder=\"Please, select ms-files define a target list.\",\n            description=\"\",\n            disabled=True,\n            layout={\"width\": \"90%\", \"height\": \"500px\", \"font_family\": \"monospace\"},\n        )\n\n        # Processing buttons\n        self.run_button = W.Button(description=\"Run\")\n        self.run_button.on_click(self._run_)\n        self.run_button.style.button_color = \"lightgray\"\n\n        self.download_button = W.Button(description=\"Export\")\n        self.download_button.on_click(self._export_action_)\n        self.download_button.style.button_color = \"lightgray\"\n\n        # Progress indicator\n        self.progress_bar = W.IntProgress(\n            min=0,\n            max=100,\n            layout=W.Layout(width=\"90%\"),\n            description=\"Progress:\",\n            bar_style=\"info\",\n        )\n\n        self.output = W.Output()\n\n        # Create tabs for file selection\n        tabs = W.Tab()\n        tabs.children = [\n            W.HBox([self.ms_storage_path, self.load_ms_button]),\n            W.HBox(\n                [\n                    self.target_files_button,\n                ]\n            ),\n        ]\n\n        tabs.set_title(0, \"MS-Files\")\n        tabs.set_title(1, \"Peaklists\")\n\n        # Main layout\n        self.layout = W.VBox(\n            [\n                tabs,\n                self.message_box,\n                W.HBox([self.run_button, self.download_button]),\n                self.progress_bar,\n            ]\n        )\n\n        self.tqdm = tqdm\n\n    def _load_target_from_bytes_(self, value: Dict[str, Any]) -&gt; None:\n        \"\"\"Load target list from uploaded file bytes.\n\n        Args:\n            value: Dictionary containing upload widget's value information.\n        \"\"\"\n        for data in value[\"new\"].values():\n            self.load(io.BytesIO(data[\"content\"]))\n        self._message_(f\"{len(self.targets)} targets loaded.\")\n\n    @property\n    def messages(self) -&gt; List[str]:\n        \"\"\"Get the list of messages displayed in the message box.\n\n        Returns:\n            List of messages.\n        \"\"\"\n        return self._messages\n\n    def _message_(self, text: str) -&gt; None:\n        \"\"\"Add a message to the message box.\n\n        Args:\n            text: Message text to add.\n        \"\"\"\n        self.message_box.value = f\"{text}\\n\" + self.message_box.value\n\n    def _clear_messages_(self) -&gt; None:\n        \"\"\"Clear all messages from the message box.\"\"\"\n        self.message_box.value = \"\"\n\n    def _search_files_(self, b: Optional[W.Button] = None) -&gt; None:\n        \"\"\"Search for MS files in the selected directory.\n\n        Args:\n            b: Button that triggered the action (not used).\n        \"\"\"\n        self.ms_files = (\n            glob(os.path.join(self.ms_storage_path.selected_path, \"*mzXML\"))\n            + glob(os.path.join(self.ms_storage_path.selected_path, \"*mzML\"))\n            + glob(os.path.join(self.ms_storage_path.selected_path, \"*mzHDF\"))\n            + glob(os.path.join(self.ms_storage_path.selected_path, \"*mzxml\"))\n            + glob(os.path.join(self.ms_storage_path.selected_path, \"*mzml\"))\n            + glob(os.path.join(self.ms_storage_path.selected_path, \"*mzhdf\"))\n        )\n        self.message(\n            f\"{self.n_files} MS-files loaded.\"\n        )  # This should be self._message_ instead of self.message\n\n    def display(self) -&gt; W.VBox:\n        \"\"\"Display control elements in Jupyter notebook.\n\n        Returns:\n            The main widget layout container.\n        \"\"\"\n        display(HTML(\"&lt;style&gt;textarea, input { font-family: monospace; }&lt;/style&gt;\"))\n        return self.layout\n\n    def _run_(self, b: Optional[W.Button] = None, **kwargs: Any) -&gt; None:\n        \"\"\"Run data processing with the current settings.\n\n        Args:\n            b: Button that triggered the action (not used).\n            **kwargs: Additional keyword arguments passed to the run method.\n        \"\"\"\n        self._message_(\"Start processing...\")\n        self.progress = 0\n        self.run(**kwargs)\n        self._message_(\"...finished processing.\")\n        if self.results is not None:\n            self.download_button.style.button_color = \"lightgreen\"\n\n    def _set_progress_(self, value: int) -&gt; None:\n        \"\"\"Update the progress bar value.\n\n        Args:\n            value: Progress value (0-100).\n        \"\"\"\n        self.progress_bar.value = value\n\n    def _export_action_(self, b: Optional[W.Button] = None, filename: Optional[str] = None) -&gt; None:\n        \"\"\"Export results to an Excel file.\n\n        Args:\n            b: Button that triggered the action (not used).\n            filename: Output filename. If None, uses a default name.\n        \"\"\"\n        if filename is None:\n            filename = \"MINT__results.xlsx\"\n            filename = os.path.join(os.getcwd(), filename)\n        self.export(filename)\n        self._message_(f\"\\nExported results to: {filename}\")\n</code></pre>"},{"location":"api_reference/core/#ms_mint.notebook.Mint.messages","title":"<code>messages: List[str]</code>  <code>property</code>","text":"<p>Get the list of messages displayed in the message box.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of messages.</p>"},{"location":"api_reference/core/#ms_mint.notebook.Mint.__init__","title":"<code>__init__(*args, **kwargs)</code>","text":"<p>Initialize the interactive Mint instance.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Any</code> <p>Positional arguments passed to the parent Mint class.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Keyword arguments passed to the parent Mint class.</p> <code>{}</code> Source code in <code>src/ms_mint/notebook.py</code> <pre><code>def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize the interactive Mint instance.\n\n    Args:\n        *args: Positional arguments passed to the parent Mint class.\n        **kwargs: Keyword arguments passed to the parent Mint class.\n    \"\"\"\n    self.progress_callback = self._set_progress_\n\n    super().__init__(progress_callback=self.progress_callback, *args, **kwargs)\n\n    # Initialize file chooser for MS files directory\n    fc = FileChooser()\n    fc.show_only_dirs = True\n    fc.default_path = os.getcwd()\n    self.ms_storage_path = fc\n\n    # Target file upload widget\n    self.target_files_button = W.FileUpload(\n        description=\"Peaklists\", accept=\"csv,xlsx\", multiple=False\n    )\n    self.target_files_button.observe(self._load_target_from_bytes_, names=\"value\")\n\n    # Button to load MS files\n    self.load_ms_button = W.Button(description=\"Load MS-files\")\n    self.load_ms_button.on_click(self._search_files_)\n\n    # Message display area\n    self.message_box = W.Textarea(\n        value=\"\",\n        placeholder=\"Please, select ms-files define a target list.\",\n        description=\"\",\n        disabled=True,\n        layout={\"width\": \"90%\", \"height\": \"500px\", \"font_family\": \"monospace\"},\n    )\n\n    # Processing buttons\n    self.run_button = W.Button(description=\"Run\")\n    self.run_button.on_click(self._run_)\n    self.run_button.style.button_color = \"lightgray\"\n\n    self.download_button = W.Button(description=\"Export\")\n    self.download_button.on_click(self._export_action_)\n    self.download_button.style.button_color = \"lightgray\"\n\n    # Progress indicator\n    self.progress_bar = W.IntProgress(\n        min=0,\n        max=100,\n        layout=W.Layout(width=\"90%\"),\n        description=\"Progress:\",\n        bar_style=\"info\",\n    )\n\n    self.output = W.Output()\n\n    # Create tabs for file selection\n    tabs = W.Tab()\n    tabs.children = [\n        W.HBox([self.ms_storage_path, self.load_ms_button]),\n        W.HBox(\n            [\n                self.target_files_button,\n            ]\n        ),\n    ]\n\n    tabs.set_title(0, \"MS-Files\")\n    tabs.set_title(1, \"Peaklists\")\n\n    # Main layout\n    self.layout = W.VBox(\n        [\n            tabs,\n            self.message_box,\n            W.HBox([self.run_button, self.download_button]),\n            self.progress_bar,\n        ]\n    )\n\n    self.tqdm = tqdm\n</code></pre>"},{"location":"api_reference/core/#ms_mint.notebook.Mint.display","title":"<code>display()</code>","text":"<p>Display control elements in Jupyter notebook.</p> <p>Returns:</p> Type Description <code>VBox</code> <p>The main widget layout container.</p> Source code in <code>src/ms_mint/notebook.py</code> <pre><code>def display(self) -&gt; W.VBox:\n    \"\"\"Display control elements in Jupyter notebook.\n\n    Returns:\n        The main widget layout container.\n    \"\"\"\n    display(HTML(\"&lt;style&gt;textarea, input { font-family: monospace; }&lt;/style&gt;\"))\n    return self.layout\n</code></pre>"},{"location":"api_reference/core/#ms_mint.MintPlotter","title":"<code>ms_mint.MintPlotter</code>","text":""},{"location":"api_reference/core/#ms_mint.MintPlotter.MintPlotter","title":"<code>MintPlotter</code>","text":"<p>Plot generator for visualizing MS-MINT analysis results.</p> <p>This class provides various visualization methods for metabolomics data processed by MS-MINT, including heatmaps, chromatograms, peak shapes, and 2D histograms.</p> <p>Attributes:</p> Name Type Description <code>mint</code> <p>The Mint instance containing data to be visualized.</p> Source code in <code>src/ms_mint/MintPlotter.py</code> <pre><code>class MintPlotter:\n    \"\"\"Plot generator for visualizing MS-MINT analysis results.\n\n    This class provides various visualization methods for metabolomics data processed\n    by MS-MINT, including heatmaps, chromatograms, peak shapes, and 2D histograms.\n\n    Attributes:\n        mint: The Mint instance containing data to be visualized.\n    \"\"\"\n\n    def __init__(self, mint: \"ms_mint.Mint.Mint\") -&gt; None:\n        \"\"\"Initialize the MintPlotter with a Mint instance.\n\n        Args:\n            mint: Mint instance containing the data to visualize.\n        \"\"\"\n        self.mint = mint\n\n    def hierarchical_clustering(\n        self,\n        data: Optional[pd.DataFrame] = None,\n        peak_labels: Optional[List[str]] = None,\n        ms_files: Optional[List[str]] = None,\n        title: Optional[str] = None,\n        figsize: Tuple[int, int] = (8, 8),\n        targets_var: Optional[str] = None,\n        var_name: str = \"peak_max\",\n        vmin: int = -3,\n        vmax: int = 3,\n        xmaxticks: Optional[int] = None,\n        ymaxticks: Optional[int] = None,\n        apply: str = \"log2p1\",\n        metric: str = \"cosine\",\n        scaler: str = \"standard\",\n        groupby: Optional[str] = None,\n        transposed: bool = False,\n        **kwargs,\n    ) -&gt; matplotlib.figure.Figure:\n        \"\"\"Perform hierarchical clustering and plot a heatmap.\n\n        If no data is provided, data is taken from self.mint.crosstab(var_name).\n        The clustered non-transformed non-scaled data is stored in `self.mint.clustered`.\n\n        Args:\n            data: DataFrame with data to be used for clustering. If None, crosstab of\n                mint instance is used.\n            peak_labels: List of peak labels to include in the analysis.\n            ms_files: List of MS files to include in the analysis.\n            title: Title for the plot.\n            figsize: Tuple of (width, height) in inches for the figure.\n            targets_var: Deprecated, use var_name instead.\n            var_name: Name of the column from data to be used for cell values in the heatmap.\n            vmin: Minimum value for color scaling.\n            vmax: Maximum value for color scaling.\n            xmaxticks: Maximum number of ticks on x-axis.\n            ymaxticks: Maximum number of ticks on y-axis.\n            apply: Transformation to be applied on the data. Can be \"log1p\", \"log2p1\",\n                \"log10p1\" or None.\n            metric: The distance metric to use for the tree. Can be any metric supported\n                by scipy.spatial.distance.pdist.\n            scaler: Method to scale data along both axes. Can be \"standard\", \"robust\" or None.\n            groupby: Name of the column to group data before scaling. If None, scaling is\n                applied to the whole data, not group-wise.\n            transposed: Whether to transpose the figure or not.\n            **kwargs: Additional keyword arguments passed to hierarchical_clustering.\n\n        Returns:\n            Matplotlib figure representing the clustered heatmap.\n        \"\"\"\n        if targets_var is not None:\n            warnings.warn(\"targets_var is deprecated, use var_name instead\", DeprecationWarning)\n            var_name = targets_var\n\n        warnings.simplefilter(\"ignore\", ClusterWarning)\n        if data is None:\n            data = self.mint.crosstab(\n                var_name=var_name, apply=apply, scaler=scaler, groupby=groupby\n            )\n\n        if transposed:\n            data = data.T\n\n        _, fig, ndx_x, ndx_y = hierarchical_clustering(\n            data,\n            vmin=vmin,\n            vmax=vmax,\n            figsize=figsize,\n            xmaxticks=xmaxticks,\n            ymaxticks=ymaxticks,\n            metric=metric,\n            **kwargs,\n        )\n\n        self.mint.clustered = data.iloc[ndx_x, ndx_y]\n\n        return fig\n\n    def peak_shapes(\n        self,\n        fns: Optional[Union[str, List[str]]] = None,\n        peak_labels: Optional[Union[str, List[str]]] = None,\n        interactive: bool = False,\n        **kwargs,\n    ) -&gt; Union[sns.axisgrid.FacetGrid, PlotlyFigure]:\n        \"\"\"Plot peak shapes extracted from MS-MINT results.\n\n        Args:\n            fns: Filename(s) to include in the plot. If None, all files in results are used.\n            peak_labels: Peak label(s) to include in the plot. If None, all peaks are used.\n            interactive: If True, returns an interactive Plotly figure instead of a static\n                Matplotlib figure.\n            **kwargs: Additional keyword arguments passed to the underlying plotting functions.\n\n        Returns:\n            Either a seaborn FacetGrid or a Plotly figure depending on the 'interactive' parameter.\n        \"\"\"\n        if peak_labels is None:\n            peak_labels = self.mint.peak_labels\n\n        if len(self.mint.results) &gt; 0:\n            if not interactive:\n                return plot_peak_shapes(\n                    self.mint.results,\n                    mint_metadata=self.mint.meta,\n                    fns=fns,\n                    peak_labels=peak_labels,\n                    **kwargs,\n                )\n            else:\n                return plotly_peak_shapes(\n                    self.mint.results,\n                    mint_metadata=self.mint.meta,\n                    fns=fns,\n                    peak_labels=peak_labels,\n                    **kwargs,\n                )\n\n    def heatmap(\n        self,\n        col_name: str = \"peak_max\",\n        normed_by_cols: bool = True,\n        transposed: bool = False,\n        clustered: bool = False,\n        add_dendrogram: bool = False,\n        name: str = \"\",\n        correlation: bool = False,\n        **kwargs,\n    ) -&gt; Optional[PlotlyFigure]:\n        \"\"\"Create an interactive heatmap to explore the data.\n\n        Calls mint.crosstab() and then visualizes the result using plotly_heatmap.\n\n        Args:\n            col_name: Name of the column in mint.results to be analyzed.\n            normed_by_cols: Whether or not to normalize the columns in the crosstab.\n            transposed: If True, transpose matrix before plotting.\n            clustered: Whether or not to cluster the rows.\n            add_dendrogram: Whether or not to replace row labels with a dendrogram.\n            name: Label to use for the colorbar.\n            correlation: If True, convert data to correlation matrix before plotting.\n            **kwargs: Additional keyword arguments passed to plotly_heatmap.\n\n        Returns:\n            Interactive Plotly heatmap figure, or None if no results are available.\n        \"\"\"\n        data = self.mint.crosstab(col_name)\n\n        # Remove path and suffix from file name.\n        transform_filenames_func = lambda x: P(x).with_suffix(\"\").name\n        data.index = [transform_filenames_func(i) for i in data.index]\n\n        if len(self.mint.results) &gt; 0:\n            return plotly_heatmap(\n                data,\n                normed_by_cols=normed_by_cols,\n                transposed=transposed,\n                clustered=clustered,\n                add_dendrogram=add_dendrogram,\n                name=col_name if not name else name,\n                correlation=correlation,\n                **kwargs,\n            )\n        return None\n\n    def histogram_2d(\n        self,\n        fn: str,\n        peak_label: Optional[str] = None,\n        rt_margin: float = 0,\n        mz_margin: float = 0,\n        **kwargs,\n    ) -&gt; matplotlib.figure.Figure:\n        \"\"\"Create a 2D histogram of an MS file.\n\n        Args:\n            fn: File name of the MS file to visualize.\n            peak_label: Target to focus. If provided, the plot will highlight the region\n                defined by the target parameters.\n            rt_margin: Margin in retention time dimension to add around the target region.\n            mz_margin: Margin in m/z dimension to add around the target region.\n            **kwargs: Additional keyword arguments passed to plot_metabolomics_hist2d.\n\n        Returns:\n            Matplotlib Figure containing the 2D histogram.\n        \"\"\"\n        df = ms_file_to_df(fn)\n        mz_range, rt_range, rt_min, rt_max = None, None, None, None\n        mz_min, mz_max = None, None\n\n        if peak_label is not None:\n            target_data = self.mint.targets.loc[peak_label]\n            mz_mean, mz_width, rt_min, rt_max = target_data[\n                [\"mz_mean\", \"mz_width\", \"rt_min\", \"rt_max\"]\n            ]\n            mz_min, mz_max = mz_mean_width_to_min_max(mz_mean, mz_width)\n            mz_range = (mz_min - mz_margin, mz_max + mz_margin)\n            rt_range = (rt_min - rt_margin, rt_max + rt_margin)\n\n        fig = plot_metabolomics_hist2d(df, mz_range=mz_range, rt_range=rt_range, **kwargs)\n\n        if rt_min is not None and mz_min is not None:\n            plt.plot(\n                [rt_min, rt_max, rt_max, rt_min, rt_min],\n                [mz_min, mz_min, mz_max, mz_max, mz_min],\n                color=\"w\",\n                ls=\"--\",\n                lw=0.5,\n            )\n        if peak_label is None:\n            plt.title(f\"{P(fn).with_suffix('').name}\")\n        else:\n            plt.title(f\"{P(fn).with_suffix('').name}\\n{peak_label}\")\n        return fig\n\n    def chromatogram(\n        self,\n        fns: Optional[Union[str, List[str]]] = None,\n        peak_labels: Optional[Union[str, List[str]]] = None,\n        interactive: bool = False,\n        filters: Optional[List[Any]] = None,\n        ax: Optional[plt.Axes] = None,\n        **kwargs,\n    ) -&gt; Union[sns.axisgrid.FacetGrid, sns.axes._base.AxesBase, PlotlyFigure]:\n        \"\"\"Plot chromatograms extracted from one or more files.\n\n        Args:\n            fns: File name(s) to extract chromatograms from. If None, all files are used.\n            peak_labels: Target(s) from Mint.targets.peak_label to use for extraction parameters.\n                If None, all targets are used.\n            interactive: If True, returns an interactive Plotly figure instead of a static Matplotlib figure.\n            filters: List of filters to apply to the chromatograms before plotting.\n            ax: Matplotlib axes to plot on. If None, a new figure is created.\n            **kwargs: Additional keyword arguments passed to the underlying plotting functions.\n\n        Returns:\n            Either a seaborn FacetGrid, a single Axes, or a Plotly figure depending on\n            the 'interactive' parameter and whether an 'ax' is provided.\n        \"\"\"\n        if isinstance(fns, str):\n            fns = [fns]\n\n        if fns is not None:\n            fns = tuple(fns)\n\n        if isinstance(peak_labels, str):\n            peak_labels = [peak_labels]\n\n        if peak_labels is None:\n            peak_labels = self.mint.peak_labels\n\n        if peak_labels is not None:\n            peak_labels = tuple(peak_labels)\n\n        data = self.mint.get_chromatograms(fns=fns, peak_labels=peak_labels, filters=filters)\n\n        if not interactive:\n            params = dict(\n                x=\"scan_time\",\n                y=\"intensity\",\n                col=\"peak_label\",\n                col_wrap=1,\n                col_order=peak_labels,\n                height=1.5,\n                aspect=5,\n                hue=\"ms_file_label\",\n                facet_kws=dict(sharey=False),\n                marker=\".\",\n                linewidth=0,\n            )\n            params.update(kwargs)\n\n            if ax is None:\n                g = sns.relplot(data=data, **params)\n\n                for peak_label, ax in zip(peak_labels, g.axes.flatten()):\n                    _, _, rt_min, rt_max = self.mint.get_target_params(peak_label)\n                    if rt_min is not None and rt_max is not None:\n                        ax.axvspan(rt_min, rt_max, color=\"lightgreen\", alpha=0.5, zorder=-1)\n                    ax.ticklabel_format(style=\"sci\", axis=\"y\", useOffset=False, scilimits=(0, 0))\n                g.set_titles(template=\"{col_name}\")\n\n            else:\n                g = sns.lineplot(\n                    data=data, x=\"scan_time\", y=\"intensity\", hue=\"ms_file_label\", ax=ax, **kwargs\n                )\n            return g\n\n        else:\n            g = px.line(\n                data_frame=data,\n                x=\"scan_time\",\n                y=\"intensity\",\n                facet_col=\"peak_label\",\n                color=\"ms_file_label\",\n                height=700,\n                facet_col_wrap=1,\n            )\n            g.update_xaxes(matches=None)\n            g.update_yaxes(matches=None)\n            return g\n</code></pre>"},{"location":"api_reference/core/#ms_mint.MintPlotter.MintPlotter.__init__","title":"<code>__init__(mint)</code>","text":"<p>Initialize the MintPlotter with a Mint instance.</p> <p>Parameters:</p> Name Type Description Default <code>mint</code> <code>'ms_mint.Mint.Mint'</code> <p>Mint instance containing the data to visualize.</p> required Source code in <code>src/ms_mint/MintPlotter.py</code> <pre><code>def __init__(self, mint: \"ms_mint.Mint.Mint\") -&gt; None:\n    \"\"\"Initialize the MintPlotter with a Mint instance.\n\n    Args:\n        mint: Mint instance containing the data to visualize.\n    \"\"\"\n    self.mint = mint\n</code></pre>"},{"location":"api_reference/core/#ms_mint.MintPlotter.MintPlotter.hierarchical_clustering","title":"<code>hierarchical_clustering(data=None, peak_labels=None, ms_files=None, title=None, figsize=(8, 8), targets_var=None, var_name='peak_max', vmin=-3, vmax=3, xmaxticks=None, ymaxticks=None, apply='log2p1', metric='cosine', scaler='standard', groupby=None, transposed=False, **kwargs)</code>","text":"<p>Perform hierarchical clustering and plot a heatmap.</p> <p>If no data is provided, data is taken from self.mint.crosstab(var_name). The clustered non-transformed non-scaled data is stored in <code>self.mint.clustered</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Optional[DataFrame]</code> <p>DataFrame with data to be used for clustering. If None, crosstab of mint instance is used.</p> <code>None</code> <code>peak_labels</code> <code>Optional[List[str]]</code> <p>List of peak labels to include in the analysis.</p> <code>None</code> <code>ms_files</code> <code>Optional[List[str]]</code> <p>List of MS files to include in the analysis.</p> <code>None</code> <code>title</code> <code>Optional[str]</code> <p>Title for the plot.</p> <code>None</code> <code>figsize</code> <code>Tuple[int, int]</code> <p>Tuple of (width, height) in inches for the figure.</p> <code>(8, 8)</code> <code>targets_var</code> <code>Optional[str]</code> <p>Deprecated, use var_name instead.</p> <code>None</code> <code>var_name</code> <code>str</code> <p>Name of the column from data to be used for cell values in the heatmap.</p> <code>'peak_max'</code> <code>vmin</code> <code>int</code> <p>Minimum value for color scaling.</p> <code>-3</code> <code>vmax</code> <code>int</code> <p>Maximum value for color scaling.</p> <code>3</code> <code>xmaxticks</code> <code>Optional[int]</code> <p>Maximum number of ticks on x-axis.</p> <code>None</code> <code>ymaxticks</code> <code>Optional[int]</code> <p>Maximum number of ticks on y-axis.</p> <code>None</code> <code>apply</code> <code>str</code> <p>Transformation to be applied on the data. Can be \"log1p\", \"log2p1\", \"log10p1\" or None.</p> <code>'log2p1'</code> <code>metric</code> <code>str</code> <p>The distance metric to use for the tree. Can be any metric supported by scipy.spatial.distance.pdist.</p> <code>'cosine'</code> <code>scaler</code> <code>str</code> <p>Method to scale data along both axes. Can be \"standard\", \"robust\" or None.</p> <code>'standard'</code> <code>groupby</code> <code>Optional[str]</code> <p>Name of the column to group data before scaling. If None, scaling is applied to the whole data, not group-wise.</p> <code>None</code> <code>transposed</code> <code>bool</code> <p>Whether to transpose the figure or not.</p> <code>False</code> <code>**kwargs</code> <p>Additional keyword arguments passed to hierarchical_clustering.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Matplotlib figure representing the clustered heatmap.</p> Source code in <code>src/ms_mint/MintPlotter.py</code> <pre><code>def hierarchical_clustering(\n    self,\n    data: Optional[pd.DataFrame] = None,\n    peak_labels: Optional[List[str]] = None,\n    ms_files: Optional[List[str]] = None,\n    title: Optional[str] = None,\n    figsize: Tuple[int, int] = (8, 8),\n    targets_var: Optional[str] = None,\n    var_name: str = \"peak_max\",\n    vmin: int = -3,\n    vmax: int = 3,\n    xmaxticks: Optional[int] = None,\n    ymaxticks: Optional[int] = None,\n    apply: str = \"log2p1\",\n    metric: str = \"cosine\",\n    scaler: str = \"standard\",\n    groupby: Optional[str] = None,\n    transposed: bool = False,\n    **kwargs,\n) -&gt; matplotlib.figure.Figure:\n    \"\"\"Perform hierarchical clustering and plot a heatmap.\n\n    If no data is provided, data is taken from self.mint.crosstab(var_name).\n    The clustered non-transformed non-scaled data is stored in `self.mint.clustered`.\n\n    Args:\n        data: DataFrame with data to be used for clustering. If None, crosstab of\n            mint instance is used.\n        peak_labels: List of peak labels to include in the analysis.\n        ms_files: List of MS files to include in the analysis.\n        title: Title for the plot.\n        figsize: Tuple of (width, height) in inches for the figure.\n        targets_var: Deprecated, use var_name instead.\n        var_name: Name of the column from data to be used for cell values in the heatmap.\n        vmin: Minimum value for color scaling.\n        vmax: Maximum value for color scaling.\n        xmaxticks: Maximum number of ticks on x-axis.\n        ymaxticks: Maximum number of ticks on y-axis.\n        apply: Transformation to be applied on the data. Can be \"log1p\", \"log2p1\",\n            \"log10p1\" or None.\n        metric: The distance metric to use for the tree. Can be any metric supported\n            by scipy.spatial.distance.pdist.\n        scaler: Method to scale data along both axes. Can be \"standard\", \"robust\" or None.\n        groupby: Name of the column to group data before scaling. If None, scaling is\n            applied to the whole data, not group-wise.\n        transposed: Whether to transpose the figure or not.\n        **kwargs: Additional keyword arguments passed to hierarchical_clustering.\n\n    Returns:\n        Matplotlib figure representing the clustered heatmap.\n    \"\"\"\n    if targets_var is not None:\n        warnings.warn(\"targets_var is deprecated, use var_name instead\", DeprecationWarning)\n        var_name = targets_var\n\n    warnings.simplefilter(\"ignore\", ClusterWarning)\n    if data is None:\n        data = self.mint.crosstab(\n            var_name=var_name, apply=apply, scaler=scaler, groupby=groupby\n        )\n\n    if transposed:\n        data = data.T\n\n    _, fig, ndx_x, ndx_y = hierarchical_clustering(\n        data,\n        vmin=vmin,\n        vmax=vmax,\n        figsize=figsize,\n        xmaxticks=xmaxticks,\n        ymaxticks=ymaxticks,\n        metric=metric,\n        **kwargs,\n    )\n\n    self.mint.clustered = data.iloc[ndx_x, ndx_y]\n\n    return fig\n</code></pre>"},{"location":"api_reference/core/#ms_mint.MintPlotter.MintPlotter.peak_shapes","title":"<code>peak_shapes(fns=None, peak_labels=None, interactive=False, **kwargs)</code>","text":"<p>Plot peak shapes extracted from MS-MINT results.</p> <p>Parameters:</p> Name Type Description Default <code>fns</code> <code>Optional[Union[str, List[str]]]</code> <p>Filename(s) to include in the plot. If None, all files in results are used.</p> <code>None</code> <code>peak_labels</code> <code>Optional[Union[str, List[str]]]</code> <p>Peak label(s) to include in the plot. If None, all peaks are used.</p> <code>None</code> <code>interactive</code> <code>bool</code> <p>If True, returns an interactive Plotly figure instead of a static Matplotlib figure.</p> <code>False</code> <code>**kwargs</code> <p>Additional keyword arguments passed to the underlying plotting functions.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[FacetGrid, Figure]</code> <p>Either a seaborn FacetGrid or a Plotly figure depending on the 'interactive' parameter.</p> Source code in <code>src/ms_mint/MintPlotter.py</code> <pre><code>def peak_shapes(\n    self,\n    fns: Optional[Union[str, List[str]]] = None,\n    peak_labels: Optional[Union[str, List[str]]] = None,\n    interactive: bool = False,\n    **kwargs,\n) -&gt; Union[sns.axisgrid.FacetGrid, PlotlyFigure]:\n    \"\"\"Plot peak shapes extracted from MS-MINT results.\n\n    Args:\n        fns: Filename(s) to include in the plot. If None, all files in results are used.\n        peak_labels: Peak label(s) to include in the plot. If None, all peaks are used.\n        interactive: If True, returns an interactive Plotly figure instead of a static\n            Matplotlib figure.\n        **kwargs: Additional keyword arguments passed to the underlying plotting functions.\n\n    Returns:\n        Either a seaborn FacetGrid or a Plotly figure depending on the 'interactive' parameter.\n    \"\"\"\n    if peak_labels is None:\n        peak_labels = self.mint.peak_labels\n\n    if len(self.mint.results) &gt; 0:\n        if not interactive:\n            return plot_peak_shapes(\n                self.mint.results,\n                mint_metadata=self.mint.meta,\n                fns=fns,\n                peak_labels=peak_labels,\n                **kwargs,\n            )\n        else:\n            return plotly_peak_shapes(\n                self.mint.results,\n                mint_metadata=self.mint.meta,\n                fns=fns,\n                peak_labels=peak_labels,\n                **kwargs,\n            )\n</code></pre>"},{"location":"api_reference/core/#ms_mint.MintPlotter.MintPlotter.heatmap","title":"<code>heatmap(col_name='peak_max', normed_by_cols=True, transposed=False, clustered=False, add_dendrogram=False, name='', correlation=False, **kwargs)</code>","text":"<p>Create an interactive heatmap to explore the data.</p> <p>Calls mint.crosstab() and then visualizes the result using plotly_heatmap.</p> <p>Parameters:</p> Name Type Description Default <code>col_name</code> <code>str</code> <p>Name of the column in mint.results to be analyzed.</p> <code>'peak_max'</code> <code>normed_by_cols</code> <code>bool</code> <p>Whether or not to normalize the columns in the crosstab.</p> <code>True</code> <code>transposed</code> <code>bool</code> <p>If True, transpose matrix before plotting.</p> <code>False</code> <code>clustered</code> <code>bool</code> <p>Whether or not to cluster the rows.</p> <code>False</code> <code>add_dendrogram</code> <code>bool</code> <p>Whether or not to replace row labels with a dendrogram.</p> <code>False</code> <code>name</code> <code>str</code> <p>Label to use for the colorbar.</p> <code>''</code> <code>correlation</code> <code>bool</code> <p>If True, convert data to correlation matrix before plotting.</p> <code>False</code> <code>**kwargs</code> <p>Additional keyword arguments passed to plotly_heatmap.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Optional[Figure]</code> <p>Interactive Plotly heatmap figure, or None if no results are available.</p> Source code in <code>src/ms_mint/MintPlotter.py</code> <pre><code>def heatmap(\n    self,\n    col_name: str = \"peak_max\",\n    normed_by_cols: bool = True,\n    transposed: bool = False,\n    clustered: bool = False,\n    add_dendrogram: bool = False,\n    name: str = \"\",\n    correlation: bool = False,\n    **kwargs,\n) -&gt; Optional[PlotlyFigure]:\n    \"\"\"Create an interactive heatmap to explore the data.\n\n    Calls mint.crosstab() and then visualizes the result using plotly_heatmap.\n\n    Args:\n        col_name: Name of the column in mint.results to be analyzed.\n        normed_by_cols: Whether or not to normalize the columns in the crosstab.\n        transposed: If True, transpose matrix before plotting.\n        clustered: Whether or not to cluster the rows.\n        add_dendrogram: Whether or not to replace row labels with a dendrogram.\n        name: Label to use for the colorbar.\n        correlation: If True, convert data to correlation matrix before plotting.\n        **kwargs: Additional keyword arguments passed to plotly_heatmap.\n\n    Returns:\n        Interactive Plotly heatmap figure, or None if no results are available.\n    \"\"\"\n    data = self.mint.crosstab(col_name)\n\n    # Remove path and suffix from file name.\n    transform_filenames_func = lambda x: P(x).with_suffix(\"\").name\n    data.index = [transform_filenames_func(i) for i in data.index]\n\n    if len(self.mint.results) &gt; 0:\n        return plotly_heatmap(\n            data,\n            normed_by_cols=normed_by_cols,\n            transposed=transposed,\n            clustered=clustered,\n            add_dendrogram=add_dendrogram,\n            name=col_name if not name else name,\n            correlation=correlation,\n            **kwargs,\n        )\n    return None\n</code></pre>"},{"location":"api_reference/core/#ms_mint.MintPlotter.MintPlotter.histogram_2d","title":"<code>histogram_2d(fn, peak_label=None, rt_margin=0, mz_margin=0, **kwargs)</code>","text":"<p>Create a 2D histogram of an MS file.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>str</code> <p>File name of the MS file to visualize.</p> required <code>peak_label</code> <code>Optional[str]</code> <p>Target to focus. If provided, the plot will highlight the region defined by the target parameters.</p> <code>None</code> <code>rt_margin</code> <code>float</code> <p>Margin in retention time dimension to add around the target region.</p> <code>0</code> <code>mz_margin</code> <code>float</code> <p>Margin in m/z dimension to add around the target region.</p> <code>0</code> <code>**kwargs</code> <p>Additional keyword arguments passed to plot_metabolomics_hist2d.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Matplotlib Figure containing the 2D histogram.</p> Source code in <code>src/ms_mint/MintPlotter.py</code> <pre><code>def histogram_2d(\n    self,\n    fn: str,\n    peak_label: Optional[str] = None,\n    rt_margin: float = 0,\n    mz_margin: float = 0,\n    **kwargs,\n) -&gt; matplotlib.figure.Figure:\n    \"\"\"Create a 2D histogram of an MS file.\n\n    Args:\n        fn: File name of the MS file to visualize.\n        peak_label: Target to focus. If provided, the plot will highlight the region\n            defined by the target parameters.\n        rt_margin: Margin in retention time dimension to add around the target region.\n        mz_margin: Margin in m/z dimension to add around the target region.\n        **kwargs: Additional keyword arguments passed to plot_metabolomics_hist2d.\n\n    Returns:\n        Matplotlib Figure containing the 2D histogram.\n    \"\"\"\n    df = ms_file_to_df(fn)\n    mz_range, rt_range, rt_min, rt_max = None, None, None, None\n    mz_min, mz_max = None, None\n\n    if peak_label is not None:\n        target_data = self.mint.targets.loc[peak_label]\n        mz_mean, mz_width, rt_min, rt_max = target_data[\n            [\"mz_mean\", \"mz_width\", \"rt_min\", \"rt_max\"]\n        ]\n        mz_min, mz_max = mz_mean_width_to_min_max(mz_mean, mz_width)\n        mz_range = (mz_min - mz_margin, mz_max + mz_margin)\n        rt_range = (rt_min - rt_margin, rt_max + rt_margin)\n\n    fig = plot_metabolomics_hist2d(df, mz_range=mz_range, rt_range=rt_range, **kwargs)\n\n    if rt_min is not None and mz_min is not None:\n        plt.plot(\n            [rt_min, rt_max, rt_max, rt_min, rt_min],\n            [mz_min, mz_min, mz_max, mz_max, mz_min],\n            color=\"w\",\n            ls=\"--\",\n            lw=0.5,\n        )\n    if peak_label is None:\n        plt.title(f\"{P(fn).with_suffix('').name}\")\n    else:\n        plt.title(f\"{P(fn).with_suffix('').name}\\n{peak_label}\")\n    return fig\n</code></pre>"},{"location":"api_reference/core/#ms_mint.MintPlotter.MintPlotter.chromatogram","title":"<code>chromatogram(fns=None, peak_labels=None, interactive=False, filters=None, ax=None, **kwargs)</code>","text":"<p>Plot chromatograms extracted from one or more files.</p> <p>Parameters:</p> Name Type Description Default <code>fns</code> <code>Optional[Union[str, List[str]]]</code> <p>File name(s) to extract chromatograms from. If None, all files are used.</p> <code>None</code> <code>peak_labels</code> <code>Optional[Union[str, List[str]]]</code> <p>Target(s) from Mint.targets.peak_label to use for extraction parameters. If None, all targets are used.</p> <code>None</code> <code>interactive</code> <code>bool</code> <p>If True, returns an interactive Plotly figure instead of a static Matplotlib figure.</p> <code>False</code> <code>filters</code> <code>Optional[List[Any]]</code> <p>List of filters to apply to the chromatograms before plotting.</p> <code>None</code> <code>ax</code> <code>Optional[Axes]</code> <p>Matplotlib axes to plot on. If None, a new figure is created.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to the underlying plotting functions.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[FacetGrid, AxesBase, Figure]</code> <p>Either a seaborn FacetGrid, a single Axes, or a Plotly figure depending on</p> <code>Union[FacetGrid, AxesBase, Figure]</code> <p>the 'interactive' parameter and whether an 'ax' is provided.</p> Source code in <code>src/ms_mint/MintPlotter.py</code> <pre><code>def chromatogram(\n    self,\n    fns: Optional[Union[str, List[str]]] = None,\n    peak_labels: Optional[Union[str, List[str]]] = None,\n    interactive: bool = False,\n    filters: Optional[List[Any]] = None,\n    ax: Optional[plt.Axes] = None,\n    **kwargs,\n) -&gt; Union[sns.axisgrid.FacetGrid, sns.axes._base.AxesBase, PlotlyFigure]:\n    \"\"\"Plot chromatograms extracted from one or more files.\n\n    Args:\n        fns: File name(s) to extract chromatograms from. If None, all files are used.\n        peak_labels: Target(s) from Mint.targets.peak_label to use for extraction parameters.\n            If None, all targets are used.\n        interactive: If True, returns an interactive Plotly figure instead of a static Matplotlib figure.\n        filters: List of filters to apply to the chromatograms before plotting.\n        ax: Matplotlib axes to plot on. If None, a new figure is created.\n        **kwargs: Additional keyword arguments passed to the underlying plotting functions.\n\n    Returns:\n        Either a seaborn FacetGrid, a single Axes, or a Plotly figure depending on\n        the 'interactive' parameter and whether an 'ax' is provided.\n    \"\"\"\n    if isinstance(fns, str):\n        fns = [fns]\n\n    if fns is not None:\n        fns = tuple(fns)\n\n    if isinstance(peak_labels, str):\n        peak_labels = [peak_labels]\n\n    if peak_labels is None:\n        peak_labels = self.mint.peak_labels\n\n    if peak_labels is not None:\n        peak_labels = tuple(peak_labels)\n\n    data = self.mint.get_chromatograms(fns=fns, peak_labels=peak_labels, filters=filters)\n\n    if not interactive:\n        params = dict(\n            x=\"scan_time\",\n            y=\"intensity\",\n            col=\"peak_label\",\n            col_wrap=1,\n            col_order=peak_labels,\n            height=1.5,\n            aspect=5,\n            hue=\"ms_file_label\",\n            facet_kws=dict(sharey=False),\n            marker=\".\",\n            linewidth=0,\n        )\n        params.update(kwargs)\n\n        if ax is None:\n            g = sns.relplot(data=data, **params)\n\n            for peak_label, ax in zip(peak_labels, g.axes.flatten()):\n                _, _, rt_min, rt_max = self.mint.get_target_params(peak_label)\n                if rt_min is not None and rt_max is not None:\n                    ax.axvspan(rt_min, rt_max, color=\"lightgreen\", alpha=0.5, zorder=-1)\n                ax.ticklabel_format(style=\"sci\", axis=\"y\", useOffset=False, scilimits=(0, 0))\n            g.set_titles(template=\"{col_name}\")\n\n        else:\n            g = sns.lineplot(\n                data=data, x=\"scan_time\", y=\"intensity\", hue=\"ms_file_label\", ax=ax, **kwargs\n            )\n        return g\n\n    else:\n        g = px.line(\n            data_frame=data,\n            x=\"scan_time\",\n            y=\"intensity\",\n            facet_col=\"peak_label\",\n            color=\"ms_file_label\",\n            height=700,\n            facet_col_wrap=1,\n        )\n        g.update_xaxes(matches=None)\n        g.update_yaxes(matches=None)\n        return g\n</code></pre>"},{"location":"api_reference/core/#ms_mint.TargetOptimizer","title":"<code>ms_mint.TargetOptimizer</code>","text":""},{"location":"api_reference/core/#ms_mint.TargetOptimizer.TargetOptimizer","title":"<code>TargetOptimizer</code>","text":"<p>Optimizer for MS-MINT target lists.</p> <p>This class provides methods to optimize retention time parameters in target lists based on actual data from MS files.</p> <p>Attributes:</p> Name Type Description <code>mint</code> <p>Mint instance to optimize.</p> <code>results</code> <p>Results of the most recent optimization.</p> Source code in <code>src/ms_mint/TargetOptimizer.py</code> <pre><code>class TargetOptimizer:\n    \"\"\"Optimizer for MS-MINT target lists.\n\n    This class provides methods to optimize retention time parameters\n    in target lists based on actual data from MS files.\n\n    Attributes:\n        mint: Mint instance to optimize.\n        results: Results of the most recent optimization.\n    \"\"\"\n\n    def __init__(self, mint: Optional[\"ms_mint.Mint.Mint\"] = None) -&gt; None:\n        \"\"\"Initialize a TargetOptimizer instance.\n\n        Args:\n            mint: Mint instance to optimize.\n        \"\"\"\n        self.mint = mint\n        self.reset()\n\n    def reset(self) -&gt; \"TargetOptimizer\":\n        \"\"\"Reset the optimizer results.\n\n        Returns:\n            Self for method chaining.\n        \"\"\"\n        self.results: Optional[pd.DataFrame] = None\n        return self\n\n    def rt_min_max(\n        self,\n        fns: Optional[List[Union[str, P]]] = None,\n        targets: Optional[pd.DataFrame] = None,\n        peak_labels: Optional[List[str]] = None,\n        minimum_intensity: float = 1e4,\n        plot: bool = False,\n        sigma: float = 20,\n        filters: Optional[List[Any]] = None,\n        post_opt: bool = False,\n        post_opt_kwargs: Optional[Dict[str, Any]] = None,\n        rel_height: float = 0.9,\n        height: int = 3,\n        aspect: int = 2,\n        col_wrap: int = 3,\n        **kwargs,\n    ) -&gt; Union[Tuple[\"ms_mint.Mint.Mint\", Figure], \"ms_mint.Mint.Mint\"]:\n        \"\"\"Optimize rt_min and rt_max values based on expected retention times.\n\n        For this optimization all rt values in the target list must be present.\n        This method analyzes chromatograms to find peaks around expected retention\n        times and sets optimal rt_min and rt_max values.\n\n        Args:\n            fns: List of filenames to use for optimization. If None, uses all files in mint.\n            targets: Target list to optimize. If None, uses mint.targets.\n            peak_labels: Subset of peak_labels to optimize. If None, optimizes all targets.\n            minimum_intensity: Minimum intensity required, otherwise skip target.\n            plot: Whether to plot optimizations (up to 1000 plots).\n            sigma: Sigma value for peak selection (Gaussian weighting parameter).\n            filters: Filter instances to apply in respective order.\n            post_opt: Whether to optimize retention times after peak selection.\n            post_opt_kwargs: Parameters for post-optimization.\n            rel_height: Relative height for peak width determination.\n            height: Height of each subplot in inches.\n            aspect: Width-to-height ratio of each subplot.\n            col_wrap: Maximum number of columns in the plot.\n            **kwargs: Additional parameters passed to find_peaks method.\n\n        Returns:\n            If plot=True, returns a tuple of (mint instance, matplotlib figure).\n            If plot=False, returns only the mint instance.\n        \"\"\"\n        if targets is None:\n            targets = self.mint.targets.reset_index()\n\n        if fns is None:\n            fns = self.mint.ms_files\n\n        if peak_labels is None:\n            peak_labels = targets.peak_label.values\n\n        _targets = targets.set_index(\"peak_label\").copy()\n\n        ms1 = pd.concat(\n            [ms_file_to_df(fn) for fn in self.mint.tqdm(fns, desc=\"Reading files\")]\n        ).sort_values([\"scan_time\", \"mz\"])\n\n        if plot:\n            n_rows = int(np.ceil(len(peak_labels) / col_wrap))\n            fig = plt.figure(figsize=(col_wrap * height * aspect, n_rows * height))\n\n        i = 0\n        for peak_label, row in self.mint.tqdm(\n            _targets.iterrows(), total=len(targets), desc=\"Optimizing targets\"\n        ):\n            if peak_label not in peak_labels:\n                logging.warning(f\"{peak_label} not in {peak_labels}\")\n                continue\n\n            mz = row.mz_mean\n            rt = row.rt\n\n            _slice = extract_chromatogram_from_ms1(ms1, mz).groupby(\"scan_time\").sum()\n\n            chrom = Chromatogram(_slice.index, _slice.values, expected_rt=rt, filters=filters)\n\n            if chrom.x.max() &lt; minimum_intensity:\n                logging.warning(\n                    f\"Peak intensity for {peak_label} below threshold ({minimum_intensity})\"\n                )\n                continue\n\n            chrom.apply_filters()\n            chrom.find_peaks(rel_height=rel_height, **kwargs)\n            chrom.select_peak_with_gaussian_weight(rt, sigma)\n\n            if post_opt:\n                if post_opt_kwargs is None:\n                    post_opt_kwargs = {}\n                chrom.optimise_peak_times_with_diff(**post_opt_kwargs)\n\n            if chrom.selected_peak_ndxs is None or len(chrom.selected_peak_ndxs) == 0:\n                logging.warning(f\"No peaks detected for {peak_label}\")\n                continue\n\n            ndx = chrom.selected_peak_ndxs[0]\n            rt_min = chrom.peaks.at[ndx, \"rt_min\"]\n            rt_max = chrom.peaks.at[ndx, \"rt_max\"]\n\n            _targets.loc[peak_label, [\"rt_min\", \"rt_max\"]] = rt_min, rt_max\n\n            if plot:\n                i += 1\n\n                if i &lt;= 1000:\n                    plt.subplot(n_rows, col_wrap, i)\n                    chrom.plot()\n                    plt.gca().get_legend().remove()\n                    plt.title(f\"{peak_label}\\nm/z={mz:.3f}\")\n\n        self.results = _targets.reset_index()\n\n        if self.mint is not None:\n            self.mint.targets = self.results\n\n        if plot:\n            plt.tight_layout()\n            return self.mint, fig\n        else:\n            return self.mint\n\n    def detect_largest_peak_rt(\n        self,\n        fns: Optional[List[Union[str, P]]] = None,\n        targets: Optional[pd.DataFrame] = None,\n        peak_labels: Optional[List[str]] = None,\n        minimum_intensity: float = 1e4,\n        plot: bool = False,\n        height: int = 3,\n        aspect: int = 2,\n        col_wrap: int = 3,\n        **kwargs,\n    ) -&gt; Union[Tuple[\"ms_mint.Mint.Mint\", Figure], \"ms_mint.Mint.Mint\"]:\n        \"\"\"Detect the largest peak and set the RT value (not RT_min and RT_max).\n\n        Uses a simple maximum intensity approach rather than complex peak detection\n        to find the retention time of the most intense peak for each target.\n\n        Args:\n            fns: List of filenames to use for peak detection. If None, uses all files in mint.\n            targets: Target list to update. If None, uses mint.targets.\n            peak_labels: Subset of peak_labels to update. If None, updates all targets.\n            minimum_intensity: Minimum intensity required, otherwise skip target.\n            plot: Whether to plot results (up to 100 plots).\n            height: Height of each subplot in inches.\n            aspect: Width-to-height ratio of each subplot.\n            col_wrap: Maximum number of columns in the plot.\n            **kwargs: Additional parameters (not used but accepted for compatibility).\n\n        Returns:\n            If plot=True, returns a tuple of (mint instance, matplotlib figure).\n            If plot=False, returns only the mint instance.\n        \"\"\"\n        if targets is None:\n            targets = self.mint.targets.reset_index()\n\n        if fns is None:\n            fns = self.mint.ms_files\n\n        if peak_labels is None:\n            peak_labels = targets.peak_label.values\n\n        _targets = targets.set_index(\"peak_label\").copy()\n\n        ms1 = pd.concat(\n            [ms_file_to_df(fn) for fn in self.mint.tqdm(fns, desc=\"Reading files\")]\n        ).sort_values([\"scan_time\", \"mz\"])\n\n        if plot:\n            n_rows = int(np.ceil(min(len(peak_labels), 100) / col_wrap))\n            fig = plt.figure(figsize=(col_wrap * height * aspect, n_rows * height))\n\n        i = 0\n        for peak_label, row in self.mint.tqdm(\n            _targets.iterrows(), total=len(targets), desc=\"Detecting largest peaks\"\n        ):\n            if peak_label not in peak_labels:\n                logging.warning(f\"{peak_label} not in {peak_labels}\")\n                continue\n\n            mz = row.mz_mean\n            mz_width = row.mz_width if \"mz_width\" in row else 0.01  # Default width if not present\n\n            # Extract chromatogram\n            try:\n                _slice = extract_chromatogram_from_ms1(\n                    ms1, mz, mz_width if \"mz_width\" in row else None\n                )\n                if len(_slice) == 0:\n                    logging.warning(f\"No data points found for {peak_label}\")\n                    continue\n\n                chrom_data = _slice.groupby(\"scan_time\").sum()\n\n                # Simple approach: find the scan time with maximum intensity\n                if chrom_data.values.max() &lt; minimum_intensity:\n                    logging.warning(\n                        f\"Peak intensity for {peak_label} below threshold ({minimum_intensity})\"\n                    )\n                    continue\n\n                # Get the retention time with the maximum intensity\n                max_intensity_idx = chrom_data.values.argmax()\n                new_rt = chrom_data.index[max_intensity_idx]\n\n                # Update only the RT value\n                _targets.loc[peak_label, \"rt\"] = new_rt\n\n                if plot and i &lt; 100:  # Only plot first 100\n                    i += 1\n                    plt.subplot(n_rows, col_wrap, i)\n                    plt.plot(chrom_data.index, chrom_data.values)\n                    plt.axvline(new_rt, color=\"red\", linestyle=\"--\")\n                    plt.title(f\"{peak_label}\\nm/z={mz:.3f}\\nRT={new_rt:.1f}\")\n\n            except Exception as e:\n                logging.error(f\"Error processing {peak_label}: {str(e)}\")\n                continue\n\n        self.results = _targets.reset_index()\n\n        if self.mint is not None:\n            self.mint.targets = self.results\n\n        if plot:\n            plt.tight_layout()\n            return self.mint, fig\n        else:\n            return self.mint\n</code></pre>"},{"location":"api_reference/core/#ms_mint.TargetOptimizer.TargetOptimizer.__init__","title":"<code>__init__(mint=None)</code>","text":"<p>Initialize a TargetOptimizer instance.</p> <p>Parameters:</p> Name Type Description Default <code>mint</code> <code>Optional['ms_mint.Mint.Mint']</code> <p>Mint instance to optimize.</p> <code>None</code> Source code in <code>src/ms_mint/TargetOptimizer.py</code> <pre><code>def __init__(self, mint: Optional[\"ms_mint.Mint.Mint\"] = None) -&gt; None:\n    \"\"\"Initialize a TargetOptimizer instance.\n\n    Args:\n        mint: Mint instance to optimize.\n    \"\"\"\n    self.mint = mint\n    self.reset()\n</code></pre>"},{"location":"api_reference/core/#ms_mint.TargetOptimizer.TargetOptimizer.reset","title":"<code>reset()</code>","text":"<p>Reset the optimizer results.</p> <p>Returns:</p> Type Description <code>'TargetOptimizer'</code> <p>Self for method chaining.</p> Source code in <code>src/ms_mint/TargetOptimizer.py</code> <pre><code>def reset(self) -&gt; \"TargetOptimizer\":\n    \"\"\"Reset the optimizer results.\n\n    Returns:\n        Self for method chaining.\n    \"\"\"\n    self.results: Optional[pd.DataFrame] = None\n    return self\n</code></pre>"},{"location":"api_reference/core/#ms_mint.TargetOptimizer.TargetOptimizer.rt_min_max","title":"<code>rt_min_max(fns=None, targets=None, peak_labels=None, minimum_intensity=10000.0, plot=False, sigma=20, filters=None, post_opt=False, post_opt_kwargs=None, rel_height=0.9, height=3, aspect=2, col_wrap=3, **kwargs)</code>","text":"<p>Optimize rt_min and rt_max values based on expected retention times.</p> <p>For this optimization all rt values in the target list must be present. This method analyzes chromatograms to find peaks around expected retention times and sets optimal rt_min and rt_max values.</p> <p>Parameters:</p> Name Type Description Default <code>fns</code> <code>Optional[List[Union[str, Path]]]</code> <p>List of filenames to use for optimization. If None, uses all files in mint.</p> <code>None</code> <code>targets</code> <code>Optional[DataFrame]</code> <p>Target list to optimize. If None, uses mint.targets.</p> <code>None</code> <code>peak_labels</code> <code>Optional[List[str]]</code> <p>Subset of peak_labels to optimize. If None, optimizes all targets.</p> <code>None</code> <code>minimum_intensity</code> <code>float</code> <p>Minimum intensity required, otherwise skip target.</p> <code>10000.0</code> <code>plot</code> <code>bool</code> <p>Whether to plot optimizations (up to 1000 plots).</p> <code>False</code> <code>sigma</code> <code>float</code> <p>Sigma value for peak selection (Gaussian weighting parameter).</p> <code>20</code> <code>filters</code> <code>Optional[List[Any]]</code> <p>Filter instances to apply in respective order.</p> <code>None</code> <code>post_opt</code> <code>bool</code> <p>Whether to optimize retention times after peak selection.</p> <code>False</code> <code>post_opt_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Parameters for post-optimization.</p> <code>None</code> <code>rel_height</code> <code>float</code> <p>Relative height for peak width determination.</p> <code>0.9</code> <code>height</code> <code>int</code> <p>Height of each subplot in inches.</p> <code>3</code> <code>aspect</code> <code>int</code> <p>Width-to-height ratio of each subplot.</p> <code>2</code> <code>col_wrap</code> <code>int</code> <p>Maximum number of columns in the plot.</p> <code>3</code> <code>**kwargs</code> <p>Additional parameters passed to find_peaks method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[Tuple['ms_mint.Mint.Mint', Figure], 'ms_mint.Mint.Mint']</code> <p>If plot=True, returns a tuple of (mint instance, matplotlib figure).</p> <code>Union[Tuple['ms_mint.Mint.Mint', Figure], 'ms_mint.Mint.Mint']</code> <p>If plot=False, returns only the mint instance.</p> Source code in <code>src/ms_mint/TargetOptimizer.py</code> <pre><code>def rt_min_max(\n    self,\n    fns: Optional[List[Union[str, P]]] = None,\n    targets: Optional[pd.DataFrame] = None,\n    peak_labels: Optional[List[str]] = None,\n    minimum_intensity: float = 1e4,\n    plot: bool = False,\n    sigma: float = 20,\n    filters: Optional[List[Any]] = None,\n    post_opt: bool = False,\n    post_opt_kwargs: Optional[Dict[str, Any]] = None,\n    rel_height: float = 0.9,\n    height: int = 3,\n    aspect: int = 2,\n    col_wrap: int = 3,\n    **kwargs,\n) -&gt; Union[Tuple[\"ms_mint.Mint.Mint\", Figure], \"ms_mint.Mint.Mint\"]:\n    \"\"\"Optimize rt_min and rt_max values based on expected retention times.\n\n    For this optimization all rt values in the target list must be present.\n    This method analyzes chromatograms to find peaks around expected retention\n    times and sets optimal rt_min and rt_max values.\n\n    Args:\n        fns: List of filenames to use for optimization. If None, uses all files in mint.\n        targets: Target list to optimize. If None, uses mint.targets.\n        peak_labels: Subset of peak_labels to optimize. If None, optimizes all targets.\n        minimum_intensity: Minimum intensity required, otherwise skip target.\n        plot: Whether to plot optimizations (up to 1000 plots).\n        sigma: Sigma value for peak selection (Gaussian weighting parameter).\n        filters: Filter instances to apply in respective order.\n        post_opt: Whether to optimize retention times after peak selection.\n        post_opt_kwargs: Parameters for post-optimization.\n        rel_height: Relative height for peak width determination.\n        height: Height of each subplot in inches.\n        aspect: Width-to-height ratio of each subplot.\n        col_wrap: Maximum number of columns in the plot.\n        **kwargs: Additional parameters passed to find_peaks method.\n\n    Returns:\n        If plot=True, returns a tuple of (mint instance, matplotlib figure).\n        If plot=False, returns only the mint instance.\n    \"\"\"\n    if targets is None:\n        targets = self.mint.targets.reset_index()\n\n    if fns is None:\n        fns = self.mint.ms_files\n\n    if peak_labels is None:\n        peak_labels = targets.peak_label.values\n\n    _targets = targets.set_index(\"peak_label\").copy()\n\n    ms1 = pd.concat(\n        [ms_file_to_df(fn) for fn in self.mint.tqdm(fns, desc=\"Reading files\")]\n    ).sort_values([\"scan_time\", \"mz\"])\n\n    if plot:\n        n_rows = int(np.ceil(len(peak_labels) / col_wrap))\n        fig = plt.figure(figsize=(col_wrap * height * aspect, n_rows * height))\n\n    i = 0\n    for peak_label, row in self.mint.tqdm(\n        _targets.iterrows(), total=len(targets), desc=\"Optimizing targets\"\n    ):\n        if peak_label not in peak_labels:\n            logging.warning(f\"{peak_label} not in {peak_labels}\")\n            continue\n\n        mz = row.mz_mean\n        rt = row.rt\n\n        _slice = extract_chromatogram_from_ms1(ms1, mz).groupby(\"scan_time\").sum()\n\n        chrom = Chromatogram(_slice.index, _slice.values, expected_rt=rt, filters=filters)\n\n        if chrom.x.max() &lt; minimum_intensity:\n            logging.warning(\n                f\"Peak intensity for {peak_label} below threshold ({minimum_intensity})\"\n            )\n            continue\n\n        chrom.apply_filters()\n        chrom.find_peaks(rel_height=rel_height, **kwargs)\n        chrom.select_peak_with_gaussian_weight(rt, sigma)\n\n        if post_opt:\n            if post_opt_kwargs is None:\n                post_opt_kwargs = {}\n            chrom.optimise_peak_times_with_diff(**post_opt_kwargs)\n\n        if chrom.selected_peak_ndxs is None or len(chrom.selected_peak_ndxs) == 0:\n            logging.warning(f\"No peaks detected for {peak_label}\")\n            continue\n\n        ndx = chrom.selected_peak_ndxs[0]\n        rt_min = chrom.peaks.at[ndx, \"rt_min\"]\n        rt_max = chrom.peaks.at[ndx, \"rt_max\"]\n\n        _targets.loc[peak_label, [\"rt_min\", \"rt_max\"]] = rt_min, rt_max\n\n        if plot:\n            i += 1\n\n            if i &lt;= 1000:\n                plt.subplot(n_rows, col_wrap, i)\n                chrom.plot()\n                plt.gca().get_legend().remove()\n                plt.title(f\"{peak_label}\\nm/z={mz:.3f}\")\n\n    self.results = _targets.reset_index()\n\n    if self.mint is not None:\n        self.mint.targets = self.results\n\n    if plot:\n        plt.tight_layout()\n        return self.mint, fig\n    else:\n        return self.mint\n</code></pre>"},{"location":"api_reference/core/#ms_mint.TargetOptimizer.TargetOptimizer.detect_largest_peak_rt","title":"<code>detect_largest_peak_rt(fns=None, targets=None, peak_labels=None, minimum_intensity=10000.0, plot=False, height=3, aspect=2, col_wrap=3, **kwargs)</code>","text":"<p>Detect the largest peak and set the RT value (not RT_min and RT_max).</p> <p>Uses a simple maximum intensity approach rather than complex peak detection to find the retention time of the most intense peak for each target.</p> <p>Parameters:</p> Name Type Description Default <code>fns</code> <code>Optional[List[Union[str, Path]]]</code> <p>List of filenames to use for peak detection. If None, uses all files in mint.</p> <code>None</code> <code>targets</code> <code>Optional[DataFrame]</code> <p>Target list to update. If None, uses mint.targets.</p> <code>None</code> <code>peak_labels</code> <code>Optional[List[str]]</code> <p>Subset of peak_labels to update. If None, updates all targets.</p> <code>None</code> <code>minimum_intensity</code> <code>float</code> <p>Minimum intensity required, otherwise skip target.</p> <code>10000.0</code> <code>plot</code> <code>bool</code> <p>Whether to plot results (up to 100 plots).</p> <code>False</code> <code>height</code> <code>int</code> <p>Height of each subplot in inches.</p> <code>3</code> <code>aspect</code> <code>int</code> <p>Width-to-height ratio of each subplot.</p> <code>2</code> <code>col_wrap</code> <code>int</code> <p>Maximum number of columns in the plot.</p> <code>3</code> <code>**kwargs</code> <p>Additional parameters (not used but accepted for compatibility).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[Tuple['ms_mint.Mint.Mint', Figure], 'ms_mint.Mint.Mint']</code> <p>If plot=True, returns a tuple of (mint instance, matplotlib figure).</p> <code>Union[Tuple['ms_mint.Mint.Mint', Figure], 'ms_mint.Mint.Mint']</code> <p>If plot=False, returns only the mint instance.</p> Source code in <code>src/ms_mint/TargetOptimizer.py</code> <pre><code>def detect_largest_peak_rt(\n    self,\n    fns: Optional[List[Union[str, P]]] = None,\n    targets: Optional[pd.DataFrame] = None,\n    peak_labels: Optional[List[str]] = None,\n    minimum_intensity: float = 1e4,\n    plot: bool = False,\n    height: int = 3,\n    aspect: int = 2,\n    col_wrap: int = 3,\n    **kwargs,\n) -&gt; Union[Tuple[\"ms_mint.Mint.Mint\", Figure], \"ms_mint.Mint.Mint\"]:\n    \"\"\"Detect the largest peak and set the RT value (not RT_min and RT_max).\n\n    Uses a simple maximum intensity approach rather than complex peak detection\n    to find the retention time of the most intense peak for each target.\n\n    Args:\n        fns: List of filenames to use for peak detection. If None, uses all files in mint.\n        targets: Target list to update. If None, uses mint.targets.\n        peak_labels: Subset of peak_labels to update. If None, updates all targets.\n        minimum_intensity: Minimum intensity required, otherwise skip target.\n        plot: Whether to plot results (up to 100 plots).\n        height: Height of each subplot in inches.\n        aspect: Width-to-height ratio of each subplot.\n        col_wrap: Maximum number of columns in the plot.\n        **kwargs: Additional parameters (not used but accepted for compatibility).\n\n    Returns:\n        If plot=True, returns a tuple of (mint instance, matplotlib figure).\n        If plot=False, returns only the mint instance.\n    \"\"\"\n    if targets is None:\n        targets = self.mint.targets.reset_index()\n\n    if fns is None:\n        fns = self.mint.ms_files\n\n    if peak_labels is None:\n        peak_labels = targets.peak_label.values\n\n    _targets = targets.set_index(\"peak_label\").copy()\n\n    ms1 = pd.concat(\n        [ms_file_to_df(fn) for fn in self.mint.tqdm(fns, desc=\"Reading files\")]\n    ).sort_values([\"scan_time\", \"mz\"])\n\n    if plot:\n        n_rows = int(np.ceil(min(len(peak_labels), 100) / col_wrap))\n        fig = plt.figure(figsize=(col_wrap * height * aspect, n_rows * height))\n\n    i = 0\n    for peak_label, row in self.mint.tqdm(\n        _targets.iterrows(), total=len(targets), desc=\"Detecting largest peaks\"\n    ):\n        if peak_label not in peak_labels:\n            logging.warning(f\"{peak_label} not in {peak_labels}\")\n            continue\n\n        mz = row.mz_mean\n        mz_width = row.mz_width if \"mz_width\" in row else 0.01  # Default width if not present\n\n        # Extract chromatogram\n        try:\n            _slice = extract_chromatogram_from_ms1(\n                ms1, mz, mz_width if \"mz_width\" in row else None\n            )\n            if len(_slice) == 0:\n                logging.warning(f\"No data points found for {peak_label}\")\n                continue\n\n            chrom_data = _slice.groupby(\"scan_time\").sum()\n\n            # Simple approach: find the scan time with maximum intensity\n            if chrom_data.values.max() &lt; minimum_intensity:\n                logging.warning(\n                    f\"Peak intensity for {peak_label} below threshold ({minimum_intensity})\"\n                )\n                continue\n\n            # Get the retention time with the maximum intensity\n            max_intensity_idx = chrom_data.values.argmax()\n            new_rt = chrom_data.index[max_intensity_idx]\n\n            # Update only the RT value\n            _targets.loc[peak_label, \"rt\"] = new_rt\n\n            if plot and i &lt; 100:  # Only plot first 100\n                i += 1\n                plt.subplot(n_rows, col_wrap, i)\n                plt.plot(chrom_data.index, chrom_data.values)\n                plt.axvline(new_rt, color=\"red\", linestyle=\"--\")\n                plt.title(f\"{peak_label}\\nm/z={mz:.3f}\\nRT={new_rt:.1f}\")\n\n        except Exception as e:\n            logging.error(f\"Error processing {peak_label}: {str(e)}\")\n            continue\n\n    self.results = _targets.reset_index()\n\n    if self.mint is not None:\n        self.mint.targets = self.results\n\n    if plot:\n        plt.tight_layout()\n        return self.mint, fig\n    else:\n        return self.mint\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Chromatogram","title":"<code>ms_mint.Chromatogram</code>","text":""},{"location":"api_reference/core/#ms_mint.Chromatogram.Chromatogram","title":"<code>Chromatogram</code>","text":"<p>A class for handling chromatogram data extraction and processing.</p> <p>This class provides functionality to extract, process, and analyze chromatogram data from mass spectrometry files, including peak detection and visualization capabilities.</p> <p>Attributes:</p> Name Type Description <code>t</code> <code>ndarray</code> <p>Array of scan times.</p> <code>x</code> <code>ndarray</code> <p>Array of intensity values.</p> <code>noise_level</code> <code>Optional[float]</code> <p>Estimated noise level of the chromatogram.</p> <code>filters</code> <code>List[Filter]</code> <p>List of filters to be applied to the chromatogram.</p> <code>peaks</code> <code>Optional[DataFrame]</code> <p>DataFrame containing detected peaks information.</p> <code>selected_peak_ndxs</code> <code>Optional[List[int]]</code> <p>Indices of selected peaks.</p> <code>expected_rt</code> <code>Optional[float]</code> <p>Expected retention time.</p> <code>weights</code> <code>Optional[ndarray]</code> <p>Weighting values for peak selection.</p> Source code in <code>src/ms_mint/Chromatogram.py</code> <pre><code>class Chromatogram:\n    \"\"\"A class for handling chromatogram data extraction and processing.\n\n    This class provides functionality to extract, process, and analyze chromatogram data\n    from mass spectrometry files, including peak detection and visualization capabilities.\n\n    Attributes:\n        t: Array of scan times.\n        x: Array of intensity values.\n        noise_level: Estimated noise level of the chromatogram.\n        filters: List of filters to be applied to the chromatogram.\n        peaks: DataFrame containing detected peaks information.\n        selected_peak_ndxs: Indices of selected peaks.\n        expected_rt: Expected retention time.\n        weights: Weighting values for peak selection.\n    \"\"\"\n\n    def __init__(\n        self,\n        scan_times: Optional[Union[List[float], np.ndarray]] = None,\n        intensities: Optional[Union[List[float], np.ndarray]] = None,\n        filters: Optional[List[Filter]] = None,\n        expected_rt: Optional[float] = None,\n    ) -&gt; None:\n        \"\"\"Initialize a Chromatogram object.\n\n        Args:\n            scan_times: Array-like object containing the scan times.\n            intensities: Array-like object containing the intensities.\n            filters: List of filters to be applied.\n            expected_rt: Expected retention time in seconds.\n        \"\"\"\n        # Initialize empty arrays for scan_times and intensities\n        self.t: np.ndarray = (\n            np.array([]) if scan_times is None or 0 in scan_times else np.array([0])\n        )\n        self.x: np.ndarray = (\n            np.array([]) if intensities is None or 0 in scan_times else np.array([0])\n        )\n\n        # Update scan_times and intensities if provided\n        if scan_times is not None:\n            self.t = np.append(self.t, scan_times)\n        if intensities is not None:\n            self.x = np.append(self.x, intensities)\n\n        # Initialize other attributes\n        self.noise_level: Optional[float] = None\n        self.filters: List[Filter] = filters or [Resampler(), GaussFilter(), Smoother()]\n        self.peaks: Optional[pd.DataFrame] = None\n        self.selected_peak_ndxs: Optional[List[int]] = None\n        self.expected_rt: Optional[float] = expected_rt\n        self.weights: Optional[np.ndarray] = None\n\n    def from_file(\n        self, fn: str, mz_mean: float, mz_width: float = 10, expected_rt: Optional[float] = None\n    ) -&gt; None:\n        \"\"\"Load chromatogram data from a mass spectrometry file.\n\n        Args:\n            fn: Filename of the mass spectrometry file.\n            mz_mean: Mean m/z value to extract.\n            mz_width: Width of the m/z window to extract.\n            expected_rt: Expected retention time in seconds.\n        \"\"\"\n        chrom = get_chromatogram_from_ms_file(fn, mz_mean=mz_mean, mz_width=mz_width)\n        self.t = np.append(self.t, chrom.index)\n        self.x = np.append(self.x, chrom.values)\n        if expected_rt is not None:\n            self.expected_rt = expected_rt\n\n    def estimate_noise_level(self, window: int = 20) -&gt; None:\n        \"\"\"Estimate the noise level of the chromatogram.\n\n        Uses a rolling window standard deviation approach to estimate the baseline noise.\n\n        Args:\n            window: Size of the rolling window for noise estimation.\n        \"\"\"\n        data = pd.Series(index=self.t, data=self.x)\n        self.noise_level = data.rolling(window, center=True).std().median()\n\n    def apply_filters(self) -&gt; None:\n        \"\"\"Apply all filters in the filter list to the chromatogram data.\"\"\"\n        for filt in self.filters:\n            self.t, self.x = filt.transform(self.t, self.x)\n\n    def find_peaks(\n        self, prominence: Optional[float] = None, rel_height: float = 0.9, **kwargs\n    ) -&gt; None:\n        \"\"\"Find peaks in the chromatogram.\n\n        Args:\n            prominence: Minimum prominence of peaks. If None, estimated from noise level.\n            rel_height: Relative height for determining peak width.\n            **kwargs: Additional keyword arguments to pass to the peak finding function.\n        \"\"\"\n        self.estimate_noise_level()\n        if prominence is None:\n            prominence = self.noise_level * 5\n        self.peaks = find_peaks_in_timeseries(\n            self.data.intensity, prominence=prominence, rel_height=rel_height, **kwargs\n        )\n\n    def optimise_peak_times_with_diff(self, rolling_window: int = 20, plot: bool = False) -&gt; None:\n        \"\"\"Optimize peak start and end times using the derivative.\n\n        Uses the first derivative of the chromatogram to more accurately determine\n        peak start and end times.\n\n        Args:\n            rolling_window: Window size for rolling mean calculation of the derivative.\n            plot: Whether to plot the results of peak detection on the derivative.\n        \"\"\"\n        peaks = self.peaks\n        diff = (\n            (self.data - self.data.shift(1)).rolling(rolling_window, center=True).mean().fillna(0)\n        )\n        prominence = 0\n\n        peak_startings = find_peaks_in_timeseries(\n            diff.fillna(0).intensity, prominence=prominence, plot=plot\n        )\n        if plot:\n            plt.show()\n\n        peak_endings = find_peaks_in_timeseries(\n            -diff.fillna(0).intensity, prominence=prominence, plot=plot\n        )\n        if plot:\n            plt.show()\n\n        for ndx, row in peaks.iterrows():\n            new_rt_min = row.rt_min\n            new_rt_max = row.rt_max\n\n            candidates_rt_min = peak_startings[peak_startings.rt &lt;= new_rt_min]\n            candidates_rt_max = peak_endings[peak_endings.rt &gt;= new_rt_max]\n\n            if len(candidates_rt_min) &gt; 0:\n                new_rt_min = candidates_rt_min.tail(1).rt.values[0]\n\n            if len(candidates_rt_max) &gt; 0:\n                new_rt_max = candidates_rt_max.head(1).rt.values[0]\n\n            peaks.loc[ndx, [\"rt_min\", \"rt_max\"]] = new_rt_min, new_rt_max\n\n    def select_peak_by_rt(self, expected_rt: Optional[float] = None) -&gt; pd.DataFrame:\n        \"\"\"Select the peak closest to the expected retention time.\n\n        Args:\n            expected_rt: Expected retention time in seconds. If None, uses the stored expected_rt.\n\n        Returns:\n            DataFrame containing the selected peak information.\n        \"\"\"\n        peaks = self.peaks\n        if expected_rt is None:\n            expected_rt = self.expected_rt\n        else:\n            self.expected_rt = expected_rt\n        selected_ndx = (peaks.rt - expected_rt).abs().sort_values().index[0]\n        self.selected_peak_ndxs = [selected_ndx]\n        return self.selected_peaks\n\n    def select_peak_by_highest_intensity(self) -&gt; pd.DataFrame:\n        \"\"\"Select the peak with the highest intensity.\n\n        Returns:\n            DataFrame containing the selected peak information.\n        \"\"\"\n        peaks = self.peaks\n        selected_ndx = peaks.sort_values(\"peak_height\", ascending=False).index.values[0]\n        self.selected_peak_ndxs = [selected_ndx]\n        return self.selected_peaks\n\n    def select_peak_with_gaussian_weight(\n        self, expected_rt: Optional[float] = None, sigma: float = 50\n    ) -&gt; Optional[pd.DataFrame]:\n        \"\"\"Select peak using Gaussian weighting around expected retention time.\n\n        This method applies a Gaussian weighting centered at the expected retention time\n        to favor peaks close to the expected time while still considering peak height.\n\n        Args:\n            expected_rt: Expected retention time in seconds. If None, uses the stored expected_rt.\n            sigma: Standard deviation of the Gaussian weight function in seconds.\n\n        Returns:\n            DataFrame containing the selected peak information, or None if no peaks available.\n        \"\"\"\n        peaks = self.peaks\n        if expected_rt is None:\n            expected_rt = self.expected_rt\n        else:\n            self.expected_rt = expected_rt\n        if peaks is None or len(peaks) == 0:\n            logging.warning(\"No peaks available to select.\")\n            return None\n        weights = gaussian(peaks.rt, expected_rt, sigma)\n        weighted_peaks = weights * peaks.peak_height\n        x = np.arange(int(self.t.min()), int(self.t.max()))\n        self.weights = max(peaks.peak_height) * gaussian(x, expected_rt, sigma)\n        selected_ndx = weighted_peaks.sort_values(ascending=False).index.values[0]\n        self.selected_peak_ndxs = [selected_ndx]\n        return self.selected_peaks\n\n    @property\n    def selected_peaks(self) -&gt; pd.DataFrame:\n        \"\"\"Get DataFrame of the currently selected peaks.\n\n        Returns:\n            DataFrame containing information about the selected peaks.\n        \"\"\"\n        return self.peaks.loc[self.selected_peak_ndxs]\n\n    @property\n    def data(self) -&gt; pd.DataFrame:\n        \"\"\"Get chromatogram data as a DataFrame.\n\n        Returns:\n            DataFrame with scan times as index and intensity as a column.\n        \"\"\"\n        df = pd.DataFrame(index=self.t, data={\"intensity\": self.x})\n        df.index.name = \"scan_time\"\n        return df\n\n    def plot(self, label: Optional[str] = None, **kwargs) -&gt; Figure:\n        \"\"\"Plot the chromatogram with detected peaks.\n\n        Args:\n            label: Label for the plot.\n            **kwargs: Additional keyword arguments to pass to the plotting function.\n\n        Returns:\n            Matplotlib Figure object.\n        \"\"\"\n        series = self.data\n        peaks = self.peaks\n        selected_peak_ndxs = self.selected_peak_ndxs\n        weights = self.weights\n        fig = plot_peaks(\n            series,\n            peaks,\n            label=label,\n            highlight=selected_peak_ndxs,\n            expected_rt=self.expected_rt,\n            weights=weights,\n            **kwargs,\n        )\n        return fig\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Chromatogram.Chromatogram.selected_peaks","title":"<code>selected_peaks: pd.DataFrame</code>  <code>property</code>","text":"<p>Get DataFrame of the currently selected peaks.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing information about the selected peaks.</p>"},{"location":"api_reference/core/#ms_mint.Chromatogram.Chromatogram.data","title":"<code>data: pd.DataFrame</code>  <code>property</code>","text":"<p>Get chromatogram data as a DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with scan times as index and intensity as a column.</p>"},{"location":"api_reference/core/#ms_mint.Chromatogram.Chromatogram.__init__","title":"<code>__init__(scan_times=None, intensities=None, filters=None, expected_rt=None)</code>","text":"<p>Initialize a Chromatogram object.</p> <p>Parameters:</p> Name Type Description Default <code>scan_times</code> <code>Optional[Union[List[float], ndarray]]</code> <p>Array-like object containing the scan times.</p> <code>None</code> <code>intensities</code> <code>Optional[Union[List[float], ndarray]]</code> <p>Array-like object containing the intensities.</p> <code>None</code> <code>filters</code> <code>Optional[List[Filter]]</code> <p>List of filters to be applied.</p> <code>None</code> <code>expected_rt</code> <code>Optional[float]</code> <p>Expected retention time in seconds.</p> <code>None</code> Source code in <code>src/ms_mint/Chromatogram.py</code> <pre><code>def __init__(\n    self,\n    scan_times: Optional[Union[List[float], np.ndarray]] = None,\n    intensities: Optional[Union[List[float], np.ndarray]] = None,\n    filters: Optional[List[Filter]] = None,\n    expected_rt: Optional[float] = None,\n) -&gt; None:\n    \"\"\"Initialize a Chromatogram object.\n\n    Args:\n        scan_times: Array-like object containing the scan times.\n        intensities: Array-like object containing the intensities.\n        filters: List of filters to be applied.\n        expected_rt: Expected retention time in seconds.\n    \"\"\"\n    # Initialize empty arrays for scan_times and intensities\n    self.t: np.ndarray = (\n        np.array([]) if scan_times is None or 0 in scan_times else np.array([0])\n    )\n    self.x: np.ndarray = (\n        np.array([]) if intensities is None or 0 in scan_times else np.array([0])\n    )\n\n    # Update scan_times and intensities if provided\n    if scan_times is not None:\n        self.t = np.append(self.t, scan_times)\n    if intensities is not None:\n        self.x = np.append(self.x, intensities)\n\n    # Initialize other attributes\n    self.noise_level: Optional[float] = None\n    self.filters: List[Filter] = filters or [Resampler(), GaussFilter(), Smoother()]\n    self.peaks: Optional[pd.DataFrame] = None\n    self.selected_peak_ndxs: Optional[List[int]] = None\n    self.expected_rt: Optional[float] = expected_rt\n    self.weights: Optional[np.ndarray] = None\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Chromatogram.Chromatogram.from_file","title":"<code>from_file(fn, mz_mean, mz_width=10, expected_rt=None)</code>","text":"<p>Load chromatogram data from a mass spectrometry file.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>str</code> <p>Filename of the mass spectrometry file.</p> required <code>mz_mean</code> <code>float</code> <p>Mean m/z value to extract.</p> required <code>mz_width</code> <code>float</code> <p>Width of the m/z window to extract.</p> <code>10</code> <code>expected_rt</code> <code>Optional[float]</code> <p>Expected retention time in seconds.</p> <code>None</code> Source code in <code>src/ms_mint/Chromatogram.py</code> <pre><code>def from_file(\n    self, fn: str, mz_mean: float, mz_width: float = 10, expected_rt: Optional[float] = None\n) -&gt; None:\n    \"\"\"Load chromatogram data from a mass spectrometry file.\n\n    Args:\n        fn: Filename of the mass spectrometry file.\n        mz_mean: Mean m/z value to extract.\n        mz_width: Width of the m/z window to extract.\n        expected_rt: Expected retention time in seconds.\n    \"\"\"\n    chrom = get_chromatogram_from_ms_file(fn, mz_mean=mz_mean, mz_width=mz_width)\n    self.t = np.append(self.t, chrom.index)\n    self.x = np.append(self.x, chrom.values)\n    if expected_rt is not None:\n        self.expected_rt = expected_rt\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Chromatogram.Chromatogram.estimate_noise_level","title":"<code>estimate_noise_level(window=20)</code>","text":"<p>Estimate the noise level of the chromatogram.</p> <p>Uses a rolling window standard deviation approach to estimate the baseline noise.</p> <p>Parameters:</p> Name Type Description Default <code>window</code> <code>int</code> <p>Size of the rolling window for noise estimation.</p> <code>20</code> Source code in <code>src/ms_mint/Chromatogram.py</code> <pre><code>def estimate_noise_level(self, window: int = 20) -&gt; None:\n    \"\"\"Estimate the noise level of the chromatogram.\n\n    Uses a rolling window standard deviation approach to estimate the baseline noise.\n\n    Args:\n        window: Size of the rolling window for noise estimation.\n    \"\"\"\n    data = pd.Series(index=self.t, data=self.x)\n    self.noise_level = data.rolling(window, center=True).std().median()\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Chromatogram.Chromatogram.apply_filters","title":"<code>apply_filters()</code>","text":"<p>Apply all filters in the filter list to the chromatogram data.</p> Source code in <code>src/ms_mint/Chromatogram.py</code> <pre><code>def apply_filters(self) -&gt; None:\n    \"\"\"Apply all filters in the filter list to the chromatogram data.\"\"\"\n    for filt in self.filters:\n        self.t, self.x = filt.transform(self.t, self.x)\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Chromatogram.Chromatogram.find_peaks","title":"<code>find_peaks(prominence=None, rel_height=0.9, **kwargs)</code>","text":"<p>Find peaks in the chromatogram.</p> <p>Parameters:</p> Name Type Description Default <code>prominence</code> <code>Optional[float]</code> <p>Minimum prominence of peaks. If None, estimated from noise level.</p> <code>None</code> <code>rel_height</code> <code>float</code> <p>Relative height for determining peak width.</p> <code>0.9</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the peak finding function.</p> <code>{}</code> Source code in <code>src/ms_mint/Chromatogram.py</code> <pre><code>def find_peaks(\n    self, prominence: Optional[float] = None, rel_height: float = 0.9, **kwargs\n) -&gt; None:\n    \"\"\"Find peaks in the chromatogram.\n\n    Args:\n        prominence: Minimum prominence of peaks. If None, estimated from noise level.\n        rel_height: Relative height for determining peak width.\n        **kwargs: Additional keyword arguments to pass to the peak finding function.\n    \"\"\"\n    self.estimate_noise_level()\n    if prominence is None:\n        prominence = self.noise_level * 5\n    self.peaks = find_peaks_in_timeseries(\n        self.data.intensity, prominence=prominence, rel_height=rel_height, **kwargs\n    )\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Chromatogram.Chromatogram.optimise_peak_times_with_diff","title":"<code>optimise_peak_times_with_diff(rolling_window=20, plot=False)</code>","text":"<p>Optimize peak start and end times using the derivative.</p> <p>Uses the first derivative of the chromatogram to more accurately determine peak start and end times.</p> <p>Parameters:</p> Name Type Description Default <code>rolling_window</code> <code>int</code> <p>Window size for rolling mean calculation of the derivative.</p> <code>20</code> <code>plot</code> <code>bool</code> <p>Whether to plot the results of peak detection on the derivative.</p> <code>False</code> Source code in <code>src/ms_mint/Chromatogram.py</code> <pre><code>def optimise_peak_times_with_diff(self, rolling_window: int = 20, plot: bool = False) -&gt; None:\n    \"\"\"Optimize peak start and end times using the derivative.\n\n    Uses the first derivative of the chromatogram to more accurately determine\n    peak start and end times.\n\n    Args:\n        rolling_window: Window size for rolling mean calculation of the derivative.\n        plot: Whether to plot the results of peak detection on the derivative.\n    \"\"\"\n    peaks = self.peaks\n    diff = (\n        (self.data - self.data.shift(1)).rolling(rolling_window, center=True).mean().fillna(0)\n    )\n    prominence = 0\n\n    peak_startings = find_peaks_in_timeseries(\n        diff.fillna(0).intensity, prominence=prominence, plot=plot\n    )\n    if plot:\n        plt.show()\n\n    peak_endings = find_peaks_in_timeseries(\n        -diff.fillna(0).intensity, prominence=prominence, plot=plot\n    )\n    if plot:\n        plt.show()\n\n    for ndx, row in peaks.iterrows():\n        new_rt_min = row.rt_min\n        new_rt_max = row.rt_max\n\n        candidates_rt_min = peak_startings[peak_startings.rt &lt;= new_rt_min]\n        candidates_rt_max = peak_endings[peak_endings.rt &gt;= new_rt_max]\n\n        if len(candidates_rt_min) &gt; 0:\n            new_rt_min = candidates_rt_min.tail(1).rt.values[0]\n\n        if len(candidates_rt_max) &gt; 0:\n            new_rt_max = candidates_rt_max.head(1).rt.values[0]\n\n        peaks.loc[ndx, [\"rt_min\", \"rt_max\"]] = new_rt_min, new_rt_max\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Chromatogram.Chromatogram.select_peak_by_rt","title":"<code>select_peak_by_rt(expected_rt=None)</code>","text":"<p>Select the peak closest to the expected retention time.</p> <p>Parameters:</p> Name Type Description Default <code>expected_rt</code> <code>Optional[float]</code> <p>Expected retention time in seconds. If None, uses the stored expected_rt.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing the selected peak information.</p> Source code in <code>src/ms_mint/Chromatogram.py</code> <pre><code>def select_peak_by_rt(self, expected_rt: Optional[float] = None) -&gt; pd.DataFrame:\n    \"\"\"Select the peak closest to the expected retention time.\n\n    Args:\n        expected_rt: Expected retention time in seconds. If None, uses the stored expected_rt.\n\n    Returns:\n        DataFrame containing the selected peak information.\n    \"\"\"\n    peaks = self.peaks\n    if expected_rt is None:\n        expected_rt = self.expected_rt\n    else:\n        self.expected_rt = expected_rt\n    selected_ndx = (peaks.rt - expected_rt).abs().sort_values().index[0]\n    self.selected_peak_ndxs = [selected_ndx]\n    return self.selected_peaks\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Chromatogram.Chromatogram.select_peak_by_highest_intensity","title":"<code>select_peak_by_highest_intensity()</code>","text":"<p>Select the peak with the highest intensity.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing the selected peak information.</p> Source code in <code>src/ms_mint/Chromatogram.py</code> <pre><code>def select_peak_by_highest_intensity(self) -&gt; pd.DataFrame:\n    \"\"\"Select the peak with the highest intensity.\n\n    Returns:\n        DataFrame containing the selected peak information.\n    \"\"\"\n    peaks = self.peaks\n    selected_ndx = peaks.sort_values(\"peak_height\", ascending=False).index.values[0]\n    self.selected_peak_ndxs = [selected_ndx]\n    return self.selected_peaks\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Chromatogram.Chromatogram.select_peak_with_gaussian_weight","title":"<code>select_peak_with_gaussian_weight(expected_rt=None, sigma=50)</code>","text":"<p>Select peak using Gaussian weighting around expected retention time.</p> <p>This method applies a Gaussian weighting centered at the expected retention time to favor peaks close to the expected time while still considering peak height.</p> <p>Parameters:</p> Name Type Description Default <code>expected_rt</code> <code>Optional[float]</code> <p>Expected retention time in seconds. If None, uses the stored expected_rt.</p> <code>None</code> <code>sigma</code> <code>float</code> <p>Standard deviation of the Gaussian weight function in seconds.</p> <code>50</code> <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>DataFrame containing the selected peak information, or None if no peaks available.</p> Source code in <code>src/ms_mint/Chromatogram.py</code> <pre><code>def select_peak_with_gaussian_weight(\n    self, expected_rt: Optional[float] = None, sigma: float = 50\n) -&gt; Optional[pd.DataFrame]:\n    \"\"\"Select peak using Gaussian weighting around expected retention time.\n\n    This method applies a Gaussian weighting centered at the expected retention time\n    to favor peaks close to the expected time while still considering peak height.\n\n    Args:\n        expected_rt: Expected retention time in seconds. If None, uses the stored expected_rt.\n        sigma: Standard deviation of the Gaussian weight function in seconds.\n\n    Returns:\n        DataFrame containing the selected peak information, or None if no peaks available.\n    \"\"\"\n    peaks = self.peaks\n    if expected_rt is None:\n        expected_rt = self.expected_rt\n    else:\n        self.expected_rt = expected_rt\n    if peaks is None or len(peaks) == 0:\n        logging.warning(\"No peaks available to select.\")\n        return None\n    weights = gaussian(peaks.rt, expected_rt, sigma)\n    weighted_peaks = weights * peaks.peak_height\n    x = np.arange(int(self.t.min()), int(self.t.max()))\n    self.weights = max(peaks.peak_height) * gaussian(x, expected_rt, sigma)\n    selected_ndx = weighted_peaks.sort_values(ascending=False).index.values[0]\n    self.selected_peak_ndxs = [selected_ndx]\n    return self.selected_peaks\n</code></pre>"},{"location":"api_reference/core/#ms_mint.Chromatogram.Chromatogram.plot","title":"<code>plot(label=None, **kwargs)</code>","text":"<p>Plot the chromatogram with detected peaks.</p> <p>Parameters:</p> Name Type Description Default <code>label</code> <code>Optional[str]</code> <p>Label for the plot.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the plotting function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Matplotlib Figure object.</p> Source code in <code>src/ms_mint/Chromatogram.py</code> <pre><code>def plot(self, label: Optional[str] = None, **kwargs) -&gt; Figure:\n    \"\"\"Plot the chromatogram with detected peaks.\n\n    Args:\n        label: Label for the plot.\n        **kwargs: Additional keyword arguments to pass to the plotting function.\n\n    Returns:\n        Matplotlib Figure object.\n    \"\"\"\n    series = self.data\n    peaks = self.peaks\n    selected_peak_ndxs = self.selected_peak_ndxs\n    weights = self.weights\n    fig = plot_peaks(\n        series,\n        peaks,\n        label=label,\n        highlight=selected_peak_ndxs,\n        expected_rt=self.expected_rt,\n        weights=weights,\n        **kwargs,\n    )\n    return fig\n</code></pre>"},{"location":"api_reference/io/","title":"Io","text":"<p>Functions to read and write MS-MINT files.</p> <p>options:   show_root_heading: true   show_root_full_path: true   show_submodules: true   members_order: source</p>"},{"location":"api_reference/io/#ms_mint.io.convert_ms_file_to_feather","title":"<code>convert_ms_file_to_feather(fn, fn_out=None)</code>","text":"<p>Convert MS file to feather format.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Union[str, Path]</code> <p>Filename or path to the MS file to convert.</p> required <code>fn_out</code> <code>Optional[Union[str, Path]]</code> <p>Output filename or path. If None, uses the same path with '.feather' extension.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Path to the generated feather file.</p> Source code in <code>src/ms_mint/io.py</code> <pre><code>def convert_ms_file_to_feather(fn: Union[str, P], fn_out: Optional[Union[str, P]] = None) -&gt; str:\n    \"\"\"Convert MS file to feather format.\n\n    Args:\n        fn: Filename or path to the MS file to convert.\n        fn_out: Output filename or path. If None, uses the same path with '.feather' extension.\n\n    Returns:\n        Path to the generated feather file.\n    \"\"\"\n    fn = P(fn)\n    if fn_out is None:\n        fn_out = fn.with_suffix(\".feather\")\n    df = ms_file_to_df(fn)\n    if df is not None:\n        df = df.reset_index(drop=True)\n        df.to_feather(fn_out)\n    return str(fn_out)\n</code></pre>"},{"location":"api_reference/io/#ms_mint.io.convert_ms_file_to_parquet","title":"<code>convert_ms_file_to_parquet(fn, fn_out=None)</code>","text":"<p>Convert MS file to parquet format.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Union[str, Path]</code> <p>Filename or path to the MS file to convert.</p> required <code>fn_out</code> <code>Optional[Union[str, Path]]</code> <p>Output filename or path. If None, uses the same path with '.parquet' extension.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Path to the generated parquet file.</p> Source code in <code>src/ms_mint/io.py</code> <pre><code>def convert_ms_file_to_parquet(fn: Union[str, P], fn_out: Optional[Union[str, P]] = None) -&gt; str:\n    \"\"\"Convert MS file to parquet format.\n\n    Args:\n        fn: Filename or path to the MS file to convert.\n        fn_out: Output filename or path. If None, uses the same path with '.parquet' extension.\n\n    Returns:\n        Path to the generated parquet file.\n    \"\"\"\n    fn = P(fn)\n    if fn_out is None:\n        fn_out = fn.with_suffix(\".parquet\")\n    df = ms_file_to_df(fn)\n    if df is not None:\n        df = df.reset_index(drop=True)\n        df.to_parquet(fn_out)\n    return str(fn_out)\n</code></pre>"},{"location":"api_reference/io/#ms_mint.io.df_to_numeric","title":"<code>df_to_numeric(df)</code>","text":"<p>Convert dataframe columns to numeric types where possible.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame to convert. Modified in-place.</p> required Source code in <code>src/ms_mint/io.py</code> <pre><code>def df_to_numeric(df: pd.DataFrame) -&gt; None:\n    \"\"\"Convert dataframe columns to numeric types where possible.\n\n    Args:\n        df: DataFrame to convert. Modified in-place.\n    \"\"\"\n    for col in df.columns:\n        df.loc[:, col] = pd.to_numeric(df[col], errors=\"ignore\")\n</code></pre>"},{"location":"api_reference/io/#ms_mint.io.export_to_excel","title":"<code>export_to_excel(mint, fn=None)</code>","text":"<p>Export MINT state to Excel file.</p> <p>Parameters:</p> Name Type Description Default <code>mint</code> <code>'ms_mint.Mint.Mint'</code> <p>Mint instance containing data to export.</p> required <code>fn</code> <code>Optional[Union[str, Path]]</code> <p>Output filename. If None, returns a file buffer instead of writing to disk.</p> <code>None</code> <p>Returns:</p> Type Description <code>Optional[BytesIO]</code> <p>BytesIO buffer if fn is None, otherwise None.</p> Source code in <code>src/ms_mint/io.py</code> <pre><code>def export_to_excel(\n    mint: \"ms_mint.Mint.Mint\", fn: Optional[Union[str, P]] = None\n) -&gt; Optional[io.BytesIO]:\n    \"\"\"Export MINT state to Excel file.\n\n    Args:\n        mint: Mint instance containing data to export.\n        fn: Output filename. If None, returns a file buffer instead of writing to disk.\n\n    Returns:\n        BytesIO buffer if fn is None, otherwise None.\n    \"\"\"\n    date_string = str(date.today())\n    if fn is None:\n        file_buffer = io.BytesIO()\n        writer = pd.ExcelWriter(file_buffer)\n    else:\n        writer = pd.ExcelWriter(fn)\n    # Write into file\n    mint.targets.to_excel(writer, sheet_name=\"Targets\", index=False)\n    mint.results.to_excel(writer, sheet_name=\"Results\", index=False)\n    meta = pd.DataFrame({\"MINT_version\": [mint.version], \"Date\": [date_string]}).T[0]\n    meta.to_excel(writer, sheet_name=\"Metadata\", index=True, header=False)\n    # Close writer and maybe return file buffer\n    writer.close()\n    if fn is None:\n        file_buffer.seek(0)\n        return file_buffer\n    return None\n</code></pre>"},{"location":"api_reference/io/#ms_mint.io.format_thermo_raw_file_reader_parquet","title":"<code>format_thermo_raw_file_reader_parquet(df)</code>","text":"<p>Format DataFrame from Thermo Raw File Reader to MS-MINT standard format.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame from Thermo Raw File Reader.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Formatted DataFrame in MS-MINT standard format.</p> Source code in <code>src/ms_mint/io.py</code> <pre><code>def format_thermo_raw_file_reader_parquet(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Format DataFrame from Thermo Raw File Reader to MS-MINT standard format.\n\n    Args:\n        df: DataFrame from Thermo Raw File Reader.\n\n    Returns:\n        Formatted DataFrame in MS-MINT standard format.\n    \"\"\"\n    df = (\n        df[[\"ScanNumber\", \"MsOrder\", \"RetentionTime\", \"Intensities\", \"Masses\"]]\n        .set_index(\n            [\n                \"ScanNumber\",\n                \"MsOrder\",\n                \"RetentionTime\",\n            ]\n        )\n        .apply(pd.Series.explode)\n        .reset_index()\n        .rename(\n            columns={\n                \"ScanNumber\": \"scan_id\",\n                \"MsOrder\": \"ms_level\",\n                \"RetentionTime\": \"scan_time\",\n                \"Masses\": \"mz\",\n                \"Intensities\": \"intensity\",\n            }\n        )\n    )\n    df[\"scan_time\"] = df[\"scan_time\"] * 60\n    df[\"polarity\"] = None\n    df[\"intensity\"] = df.intensity.astype(np.float64)\n    df = df[MS_FILE_COLUMNS]\n    return df\n</code></pre>"},{"location":"api_reference/io/#ms_mint.io.ms_file_to_df","title":"<code>ms_file_to_df(fn, read_only=False)</code>","text":"<p>Read MS file and convert it to a pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Union[str, Path]</code> <p>Filename or path to the MS file.</p> required <code>read_only</code> <code>bool</code> <p>Whether to only read the file without converting to DataFrame (for testing purposes). Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>DataFrame containing MS data, or None if the file cannot be read.</p> Source code in <code>src/ms_mint/io.py</code> <pre><code>def ms_file_to_df(fn: Union[str, P], read_only: bool = False) -&gt; Optional[pd.DataFrame]:\n    \"\"\"Read MS file and convert it to a pandas DataFrame.\n\n    Args:\n        fn: Filename or path to the MS file.\n        read_only: Whether to only read the file without converting to DataFrame\n            (for testing purposes). Default is False.\n\n    Returns:\n        DataFrame containing MS data, or None if the file cannot be read.\n    \"\"\"\n    fn = str(fn)\n\n    try:\n        if fn.lower().endswith(\".mzxml\"):\n            df = mzxml_to_df(fn, read_only=read_only)\n        elif fn.lower().endswith(\".mzml\"):\n            df = mzml_to_df(fn, read_only=read_only)\n        elif fn.lower().endswith(\"hdf\"):\n            df = pd.read_hdf(fn)\n        elif fn.lower().endswith(\".feather\"):\n            df = pd.read_feather(fn)\n        elif fn.lower().endswith(\".parquet\"):\n            df = read_parquet(fn, read_only=read_only)\n        elif fn.lower().endswith(\".mzmlb\"):\n            df = mzmlb_to_df__pyteomics(fn, read_only=read_only)\n        else:\n            logging.error(f\"Cannot read file {fn} of type {type(fn)}\")\n            return None\n    except IndexError as e:\n        logging.warning(f\"{e}: {fn}\")\n        return None\n\n    if read_only:\n        return df\n    else:\n        # Compatibility with old schema\n        df = df.rename(\n            columns={\n                \"retentionTime\": \"scan_time\",\n                \"intensity array\": \"intensity\",\n                \"m/z array\": \"mz\",\n            }\n        )\n        if \"scan_id\" not in df.columns:\n            df[\"scan_id\"] = 0\n        if \"ms_level\" not in df.columns:\n            df[\"ms_level\"] = 1\n        # Set datatypes\n        set_dtypes(df)\n    return df\n</code></pre>"},{"location":"api_reference/io/#ms_mint.io.mzml_to_df","title":"<code>mzml_to_df(fn, read_only=False)</code>","text":"<p>Read mzML file and convert it to pandas DataFrame using the mzML library.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Union[str, Path]</code> <p>Filename or path to the mzML file.</p> required <code>read_only</code> <code>bool</code> <p>Whether to only read the file without converting to DataFrame (for testing purposes). Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>DataFrame containing MS data, or None if read_only is True.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the filename does not end with '.mzml'.</p> Source code in <code>src/ms_mint/io.py</code> <pre><code>def mzml_to_df(fn: Union[str, P], read_only: bool = False) -&gt; Optional[pd.DataFrame]:\n    \"\"\"Read mzML file and convert it to pandas DataFrame using the mzML library.\n\n    Args:\n        fn: Filename or path to the mzML file.\n        read_only: Whether to only read the file without converting to DataFrame\n            (for testing purposes). Default is False.\n\n    Returns:\n        DataFrame containing MS data, or None if read_only is True.\n\n    Raises:\n        AssertionError: If the filename does not end with '.mzml'.\n    \"\"\"\n    assert str(fn).lower().endswith(\".mzml\"), fn\n\n    # Read mzML file using pyteomics\n    with mzml.read(str(fn)) as reader:\n        # Initialize empty lists for the slices and the attributes\n        slices = []\n        # Loop through the spectra and extract the data\n        for spectrum in reader:\n            time_unit = spectrum[\"scanList\"][\"scan\"][0][\"scan start time\"].unit_info\n            if read_only:\n                continue\n            # Extract the scan ID, retention time, m/z values, and intensity values\n            scan_id = int(spectrum[\"id\"].split(\"=\")[-1])\n            rt = spectrum[\"scanList\"][\"scan\"][0][\"scan start time\"]\n            if time_unit == \"minute\":\n                rt = rt * 60.0\n            mz = np.array(spectrum[\"m/z array\"], dtype=np.float64)\n            intensity = np.array(spectrum[\"intensity array\"], dtype=np.float64)\n            if \"positive scan\" in spectrum.keys():\n                polarity = \"+\"\n            elif \"negative scan\" in spectrum.keys():\n                polarity = \"-\"\n            else:\n                polarity = None\n            ms_level = spectrum[\"ms level\"]\n            slices.append(\n                pd.DataFrame(\n                    {\n                        \"scan_id\": scan_id,\n                        \"mz\": mz,\n                        \"intensity\": intensity,\n                        \"polarity\": polarity,\n                        \"ms_level\": ms_level,\n                        \"scan_time\": rt,\n                    }\n                )\n            )\n    if read_only:\n        return None\n    df = pd.concat(slices)\n    df[\"intensity\"] = df[\"intensity\"].astype(int)\n    df = df[MS_FILE_COLUMNS].reset_index(drop=True)\n    set_dtypes(df)\n    return df\n</code></pre>"},{"location":"api_reference/io/#ms_mint.io.mzml_to_pandas_df_pyteomics","title":"<code>mzml_to_pandas_df_pyteomics(fn, **kwargs)</code>","text":"<p>Deprecated function to read mzML files.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Union[str, Path]</code> <p>Filename or path to the mzML file.</p> required <code>**kwargs</code> <p>Additional arguments passed to mzml_to_df.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>DataFrame containing MS data, or None if read_only is True.</p> Source code in <code>src/ms_mint/io.py</code> <pre><code>def mzml_to_pandas_df_pyteomics(fn: Union[str, P], **kwargs) -&gt; Optional[pd.DataFrame]:\n    \"\"\"Deprecated function to read mzML files.\n\n    Args:\n        fn: Filename or path to the mzML file.\n        **kwargs: Additional arguments passed to mzml_to_df.\n\n    Returns:\n        DataFrame containing MS data, or None if read_only is True.\n    \"\"\"\n    # warnings.warn(\"mzml_to_pandas_df_pyteomics() is deprecated use mzxml_to_df() instead\", DeprecationWarning)\n    return mzml_to_df(fn, **kwargs)\n</code></pre>"},{"location":"api_reference/io/#ms_mint.io.mzmlb_to_df__pyteomics","title":"<code>mzmlb_to_df__pyteomics(fn, read_only=False)</code>","text":"<p>Read mzMLb file and convert it to pandas DataFrame using the pyteomics library.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Union[str, Path]</code> <p>Filename or path to the mzMLb file.</p> required <code>read_only</code> <code>bool</code> <p>Whether to only read the file without converting to DataFrame (for testing purposes). Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>DataFrame containing MS data, or None if read_only is True.</p> Source code in <code>src/ms_mint/io.py</code> <pre><code>def mzmlb_to_df__pyteomics(fn: Union[str, P], read_only: bool = False) -&gt; Optional[pd.DataFrame]:\n    \"\"\"Read mzMLb file and convert it to pandas DataFrame using the pyteomics library.\n\n    Args:\n        fn: Filename or path to the mzMLb file.\n        read_only: Whether to only read the file without converting to DataFrame\n            (for testing purposes). Default is False.\n\n    Returns:\n        DataFrame containing MS data, or None if read_only is True.\n    \"\"\"\n    if not MZMLB_AVAILABLE:\n        logging.error(\"mzmlb support is not available\")\n        return None\n\n    with mzmlb.MzMLb(fn) as ms_data:\n        data = [x for x in ms_data]\n\n    if read_only:\n        return None\n\n    data = list(extract_mzmlb(data))\n    df = (\n        pd.DataFrame.from_dict(data)\n        .set_index([\"index\", \"retentionTime\", \"polarity\"])\n        .apply(pd.Series.explode)\n        .reset_index()\n        .rename(\n            columns={\n                \"index\": \"scan_id\",\n                \"retentionTime\": \"scan_time\",\n                \"m/z array\": \"mz\",\n                \"ms level\": \"ms_level\",\n                \"intensity array\": \"intensity\",\n            }\n        )\n    )\n\n    # mzMLb starts scan index with 0\n    df[\"scan_id\"] = df[\"scan_id\"] + 1\n\n    df = df[MS_FILE_COLUMNS]\n    return df\n</code></pre>"},{"location":"api_reference/io/#ms_mint.io.mzxml_to_df","title":"<code>mzxml_to_df(fn, read_only=False, time_unit_in_file='min')</code>","text":"<p>Read mzXML file and convert it to pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Union[str, Path]</code> <p>Filename or path to the mzXML file.</p> required <code>read_only</code> <code>bool</code> <p>Whether to only read the file without converting to DataFrame (for testing purposes). Default is False.</p> <code>False</code> <code>time_unit_in_file</code> <code>Literal['min', 'sec']</code> <p>The time unit used in the mzXML file. Must be either 'sec' or 'min'. Default is 'min'.</p> <code>'min'</code> <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>DataFrame containing MS data, or None if read_only is True.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the filename does not end with '.mzxml'.</p> Source code in <code>src/ms_mint/io.py</code> <pre><code>def mzxml_to_df(\n    fn: Union[str, pathlib.Path],\n    read_only: bool = False,\n    time_unit_in_file: Literal[\"min\", \"sec\"] = \"min\",\n) -&gt; Optional[pd.DataFrame]:\n    \"\"\"Read mzXML file and convert it to pandas DataFrame.\n\n    Args:\n        fn: Filename or path to the mzXML file.\n        read_only: Whether to only read the file without converting to DataFrame\n            (for testing purposes). Default is False.\n        time_unit_in_file: The time unit used in the mzXML file.\n            Must be either 'sec' or 'min'. Default is 'min'.\n\n    Returns:\n        DataFrame containing MS data, or None if read_only is True.\n\n    Raises:\n        AssertionError: If the filename does not end with '.mzxml'.\n    \"\"\"\n    assert str(fn).lower().endswith(\".mzxml\"), fn\n\n    with mzxml.MzXML(fn) as ms_data:\n        data = [x for x in ms_data]\n\n    if read_only:\n        return None\n\n    data = [_extract_mzxml(x) for x in data]\n    df = pd.json_normalize(data, sep=\"_\")\n\n    # Convert retention time to seconds\n    if time_unit_in_file == \"min\":\n        df[\"scan_time\"] = df[\"scan_time\"].astype(np.float64) * 60.0\n\n    df = df.explode([\"mz\", \"intensity\"])\n    set_dtypes(df)\n    return df.reset_index(drop=True)[MS_FILE_COLUMNS]\n</code></pre>"},{"location":"api_reference/io/#ms_mint.io.read_parquet","title":"<code>read_parquet(fn, read_only=False)</code>","text":"<p>Read parquet file and return a pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Union[str, Path]</code> <p>Filename or path to the parquet file.</p> required <code>read_only</code> <code>bool</code> <p>Whether to return the DataFrame as-is without formatting. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing MS data.</p> Source code in <code>src/ms_mint/io.py</code> <pre><code>def read_parquet(fn: Union[str, P], read_only: bool = False) -&gt; pd.DataFrame:\n    \"\"\"Read parquet file and return a pandas DataFrame.\n\n    Args:\n        fn: Filename or path to the parquet file.\n        read_only: Whether to return the DataFrame as-is without formatting.\n            Default is False.\n\n    Returns:\n        DataFrame containing MS data.\n    \"\"\"\n    df = pd.read_parquet(fn)\n    if read_only or (\n        len(df.columns) == len(MS_FILE_COLUMNS) and all(df.columns == MS_FILE_COLUMNS)\n    ):\n        return df\n    else:\n        return format_thermo_raw_file_reader_parquet(df)\n</code></pre>"},{"location":"api_reference/io/#ms_mint.io.set_dtypes","title":"<code>set_dtypes(df)</code>","text":"<p>Set appropriate data types for MS data columns.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing MS data.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with appropriate data types.</p> Source code in <code>src/ms_mint/io.py</code> <pre><code>def set_dtypes(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Set appropriate data types for MS data columns.\n\n    Args:\n        df: DataFrame containing MS data.\n\n    Returns:\n        DataFrame with appropriate data types.\n    \"\"\"\n    dtypes = dict(\n        mz=np.float32,\n        scan_id=np.int64,\n        ms_level=np.int8,\n        scan_time=np.float32,\n        intensity=np.int64,\n    )\n\n    for var, dtype in dtypes.items():\n        if var in df.columns and not df[var].dtype == dtype:\n            df[var] = df[var].astype(dtype)\n\n    return df\n</code></pre>"},{"location":"api_reference/processing/","title":"Processing utilities","text":"<p>options:   show_root_heading: true   show_root_full_path: true   show_submodules: true   members_order: source</p>"},{"location":"api_reference/processing/#ms_mint.processing.append_results","title":"<code>append_results(results, fn)</code>","text":"<p>Append results to a CSV file with file locking for thread safety.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>DataFrame</code> <p>Results DataFrame to append.</p> required <code>fn</code> <code>str</code> <p>Filename to append to.</p> required Source code in <code>src/ms_mint/processing.py</code> <pre><code>def append_results(results: pd.DataFrame, fn: str) -&gt; None:\n    \"\"\"Append results to a CSV file with file locking for thread safety.\n\n    Args:\n        results: Results DataFrame to append.\n        fn: Filename to append to.\n    \"\"\"\n    with lock(fn):\n        results.to_csv(fn, mode=\"a\", header=False, index=False)\n</code></pre>"},{"location":"api_reference/processing/#ms_mint.processing.extract_chromatogram_from_ms1","title":"<code>extract_chromatogram_from_ms1(df, mz_mean, mz_width=10)</code>","text":"<p>Extract single chromatogram of specific m/z value from MS-data.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>MS-data with columns ['scan_time', 'mz', 'intensity'].</p> required <code>mz_mean</code> <code>float</code> <p>Target m/z value.</p> required <code>mz_width</code> <code>float</code> <p>m/z width in ppm. Default is 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>Series</code> <p>Chromatogram as a pandas Series with scan_time as index and intensity as values.</p> Source code in <code>src/ms_mint/processing.py</code> <pre><code>def extract_chromatogram_from_ms1(\n    df: pd.DataFrame, mz_mean: float, mz_width: float = 10\n) -&gt; pd.Series:\n    \"\"\"Extract single chromatogram of specific m/z value from MS-data.\n\n    Args:\n        df: MS-data with columns ['scan_time', 'mz', 'intensity'].\n        mz_mean: Target m/z value.\n        mz_width: m/z width in ppm. Default is 10.\n\n    Returns:\n        Chromatogram as a pandas Series with scan_time as index and intensity as values.\n    \"\"\"\n    mz_min, mz_max = mz_mean_width_to_min_max(mz_mean, mz_width)\n    chrom = df[(df.mz &gt;= mz_min) &amp; (df.mz &lt;= mz_max)].copy()\n    chrom[\"scan_time\"] = chrom[\"scan_time\"].round(3)\n    chrom = chrom.groupby(\"scan_time\").max()\n    return chrom[\"intensity\"]\n</code></pre>"},{"location":"api_reference/processing/#ms_mint.processing.extract_ms1_properties","title":"<code>extract_ms1_properties(array, mz_mean)</code>","text":"<p>Extract peak properties from an MS-1 data slice.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray</code> <p>MS-1 data slice array with columns [scan_time, mz, intensity].</p> required <code>mz_mean</code> <code>float</code> <p>Mean m/z value for calculating mass accuracy.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary of extracted peak properties.</p> Source code in <code>src/ms_mint/processing.py</code> <pre><code>def extract_ms1_properties(array: np.ndarray, mz_mean: float) -&gt; Dict[str, Any]:\n    \"\"\"Extract peak properties from an MS-1 data slice.\n\n    Args:\n        array: MS-1 data slice array with columns [scan_time, mz, intensity].\n        mz_mean: Mean m/z value for calculating mass accuracy.\n\n    Returns:\n        Dictionary of extracted peak properties.\n    \"\"\"\n    float_list_to_comma_sep_str = lambda x: \",\".join([str(np.round(i, 4)) for i in x])\n    int_list_to_comma_sep_str = lambda x: \",\".join([str(int(i)) for i in x])\n\n    projection = pd.DataFrame(array[:, [0, 2]], columns=[\"rt\", \"int\"])\n\n    projection[\"rt\"] = projection[\"rt\"].round(2)\n    projection[\"int\"] = projection[\"int\"].astype(int)\n    projection = projection.groupby(\"rt\").max().reset_index().values\n\n    times = array[:, 0]\n    masses = array[:, 1]\n    intensities = array[:, 2]\n    peak_n_datapoints = len(array)\n\n    if peak_n_datapoints == 0:\n        return dict(\n            peak_area=0,\n            peak_area_top3=0,\n            peak_max=0,\n            peak_min=0,\n            peak_mean=None,\n            peak_rt_of_max=None,\n            peak_median=None,\n            peak_delta_int=None,\n            peak_n_datapoints=0,\n            peak_mass_diff_25pc=None,\n            peak_mass_diff_50pc=None,\n            peak_mass_diff_75pc=None,\n            peak_shape_rt=\"\",\n            peak_shape_int=\"\",\n            peak_score=None,\n        )\n\n    peak_area = intensities.sum()\n\n    # Like El-Maven peakAreaTop\n    # Alternative approach to calculate peak_area_top3\n    ndx_max = np.argmax(projection[:, 1])\n    peak_area_top3 = projection[:, 1][max(0, ndx_max - 1) : ndx_max + 2].sum() // 3\n\n    peak_mean = intensities.mean()\n    peak_max = intensities.max()\n    peak_min = intensities.min()\n    peak_median = np.median(intensities)\n\n    peak_rt_of_max = times[intensities.argmax()]\n\n    peak_delta_int = np.abs(intensities[0] - intensities[-1])\n\n    peak_mass_diff_25pc, peak_mass_diff_50pc, peak_mass_diff_75pc = np.quantile(\n        masses, [0.25, 0.5, 0.75]\n    )\n\n    peak_mass_diff_25pc -= mz_mean\n    peak_mass_diff_50pc -= mz_mean\n    peak_mass_diff_75pc -= mz_mean\n\n    peak_mass_diff_25pc /= 1e-6 * mz_mean\n    peak_mass_diff_50pc /= 1e-6 * mz_mean\n    peak_mass_diff_75pc /= 1e-6 * mz_mean\n\n    peak_shape_rt = float_list_to_comma_sep_str(projection[:, 0])\n    peak_shape_int = int_list_to_comma_sep_str(projection[:, 1])\n\n    # Check that peak projection arrays (rt, int) have same number of elements\n    assert len(peak_shape_rt.split(\",\")) == len(peak_shape_int.split(\",\"))\n\n    return dict(\n        peak_area=peak_area,\n        peak_area_top3=peak_area_top3,\n        peak_max=peak_max,\n        peak_min=peak_min,\n        peak_mean=peak_mean,\n        peak_rt_of_max=peak_rt_of_max,\n        peak_median=peak_median,\n        peak_delta_int=peak_delta_int,\n        peak_n_datapoints=peak_n_datapoints,\n        peak_mass_diff_25pc=peak_mass_diff_25pc,\n        peak_mass_diff_50pc=peak_mass_diff_50pc,\n        peak_mass_diff_75pc=peak_mass_diff_75pc,\n        peak_shape_rt=peak_shape_rt,\n        peak_shape_int=peak_shape_int,\n        peak_score=None,\n    )\n</code></pre>"},{"location":"api_reference/processing/#ms_mint.processing.get_chromatogram_from_ms_file","title":"<code>get_chromatogram_from_ms_file(ms_file, mz_mean, mz_width=10)</code>","text":"<p>Get chromatogram data from an MS file.</p> <p>Parameters:</p> Name Type Description Default <code>ms_file</code> <code>Union[str, Path]</code> <p>Path to the MS file.</p> required <code>mz_mean</code> <code>float</code> <p>Mean m/z value to extract.</p> required <code>mz_width</code> <code>float</code> <p>Width around the mean m/z in ppm to extract.</p> <code>10</code> <p>Returns:</p> Type Description <code>Series</code> <p>Chromatogram data as a pandas Series with scan_time as index</p> <code>Series</code> <p>and intensity as values.</p> Source code in <code>src/ms_mint/processing.py</code> <pre><code>def get_chromatogram_from_ms_file(\n    ms_file: Union[str, P], mz_mean: float, mz_width: float = 10\n) -&gt; pd.Series:\n    \"\"\"Get chromatogram data from an MS file.\n\n    Args:\n        ms_file: Path to the MS file.\n        mz_mean: Mean m/z value to extract.\n        mz_width: Width around the mean m/z in ppm to extract.\n\n    Returns:\n        Chromatogram data as a pandas Series with scan_time as index\n        and intensity as values.\n    \"\"\"\n    df = ms_file_to_df(ms_file)\n    chrom = extract_chromatogram_from_ms1(df, mz_mean, mz_width=mz_width)\n    return chrom\n</code></pre>"},{"location":"api_reference/processing/#ms_mint.processing.process_ms1","title":"<code>process_ms1(df, targets)</code>","text":"<p>Process MS-1 data with a target list.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>MS-1 data with columns ['scan_time', 'mz', 'intensity'].</p> required <code>targets</code> <code>DataFrame</code> <p>Target list DataFrame with required columns.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with peak integration results.</p> Source code in <code>src/ms_mint/processing.py</code> <pre><code>def process_ms1(df: pd.DataFrame, targets: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Process MS-1 data with a target list.\n\n    Args:\n        df: MS-1 data with columns ['scan_time', 'mz', 'intensity'].\n        targets: Target list DataFrame with required columns.\n\n    Returns:\n        DataFrame with peak integration results.\n    \"\"\"\n    results = _process_ms1_from_df_(df, targets)\n    results = pd.DataFrame(results, columns=[\"peak_label\"] + RESULTS_COLUMNS)\n    results = pd.merge(targets, results, on=[\"peak_label\"])\n    results = results.reset_index(drop=True)\n    return results\n</code></pre>"},{"location":"api_reference/processing/#ms_mint.processing.process_ms1_file","title":"<code>process_ms1_file(filename, targets)</code>","text":"<p>Perform peak integration using a filename as input.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Union[str, Path]</code> <p>Path to mzxml or mzml file.</p> required <code>targets</code> <code>DataFrame</code> <p>DataFrame in target list format.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with processed peak intensities.</p> Source code in <code>src/ms_mint/processing.py</code> <pre><code>def process_ms1_file(filename: Union[str, P], targets: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Perform peak integration using a filename as input.\n\n    Args:\n        filename: Path to mzxml or mzml file.\n        targets: DataFrame in target list format.\n\n    Returns:\n        DataFrame with processed peak intensities.\n    \"\"\"\n    df = ms_file_to_df(filename)\n    results = process_ms1(df, targets)\n    results[\"total_intensity\"] = df[\"intensity\"].sum()\n    results[\"ms_file\"] = str(filename)\n    results[\"ms_file_label\"] = P(filename).with_suffix(\"\").name\n    results[\"ms_file_size_MB\"] = os.path.getsize(filename) / 1024 / 1024\n    results[\"peak_score\"] = 0  # score_peaks(results)\n    return results[MINT_RESULTS_COLUMNS]\n</code></pre>"},{"location":"api_reference/processing/#ms_mint.processing.process_ms1_files_in_parallel","title":"<code>process_ms1_files_in_parallel(args)</code>","text":"<p>Process MS files in parallel using the provided arguments.</p> <p>This is a pickleable function for parallel peak integration that can be used with multiprocessing.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Dict[str, Any]</code> <p>Dictionary containing the following keys: - filename: Path to the MS file to process. - targets: DataFrame with target compounds information. - output_fn: Optional output filename to save results. - queue: Optional queue for progress reporting.</p> required <p>Returns:</p> Type Description <code>Optional[DataFrame]</code> <p>DataFrame with processing results, or None if results were saved to a file.</p> Source code in <code>src/ms_mint/processing.py</code> <pre><code>def process_ms1_files_in_parallel(args: Dict[str, Any]) -&gt; Optional[pd.DataFrame]:\n    \"\"\"Process MS files in parallel using the provided arguments.\n\n    This is a pickleable function for parallel peak integration that can be used\n    with multiprocessing.\n\n    Args:\n        args: Dictionary containing the following keys:\n            - filename: Path to the MS file to process.\n            - targets: DataFrame with target compounds information.\n            - output_fn: Optional output filename to save results.\n            - queue: Optional queue for progress reporting.\n\n    Returns:\n        DataFrame with processing results, or None if results were saved to a file.\n    \"\"\"\n    filename = args[\"filename\"]\n    targets = args[\"targets\"]\n    output_fn = args[\"output_fn\"]\n\n    if \"queue\" in args.keys():\n        q = args[\"queue\"]\n        q.put(\"filename\")\n\n    try:\n        results = process_ms1_file(filename=filename, targets=targets)\n    except Exception as e:\n        logging.error(f\"process_ms1_files_in_parallel(): {e}\")\n        results = pd.DataFrame()\n\n    if (output_fn is not None) and (len(results) &gt; 0):\n        append_results(results, output_fn)\n        return None\n\n    return results\n</code></pre>"},{"location":"api_reference/processing/#ms_mint.processing.process_ms1_from_numpy","title":"<code>process_ms1_from_numpy(array, peaks)</code>","text":"<p>Process MS1 data in numpy array format.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray</code> <p>Input data array with columns [scan_time, mz, intensity].</p> required <code>peaks</code> <code>ndarray</code> <p>Peak data array with columns [mz_mean, mz_width, rt_min, rt_max, intensity_threshold, peak_label].</p> required <p>Returns:</p> Type Description <code>List[List[Any]]</code> <p>List of extracted data for each peak.</p> Source code in <code>src/ms_mint/processing.py</code> <pre><code>def process_ms1_from_numpy(array: np.ndarray, peaks: np.ndarray) -&gt; List[List[Any]]:\n    \"\"\"Process MS1 data in numpy array format.\n\n    Args:\n        array: Input data array with columns [scan_time, mz, intensity].\n        peaks: Peak data array with columns [mz_mean, mz_width, rt_min, rt_max,\n            intensity_threshold, peak_label].\n\n    Returns:\n        List of extracted data for each peak.\n    \"\"\"\n    results = []\n    for mz_mean, mz_width, rt_min, rt_max, intensity_threshold, peak_label in peaks:\n        props = _process_ms1_from_numpy(\n            array,\n            mz_mean=mz_mean,\n            mz_width=mz_width,\n            rt_min=rt_min,\n            rt_max=rt_max,\n            intensity_threshold=intensity_threshold,\n            peak_label=peak_label,\n        )\n        if props is None:\n            continue\n        results.append([props[col] for col in [\"peak_label\"] + RESULTS_COLUMNS])\n    return results\n</code></pre>"},{"location":"api_reference/processing/#ms_mint.processing.score_peaks","title":"<code>score_peaks(mint_results)</code>","text":"<p>Score the peak quality (experimental).</p> <p>Calculates a score from 0 to 1 where: - 1 means a good peak shape - 0 means a bad peak shape</p> <p>Parameters:</p> Name Type Description Default <code>mint_results</code> <code>DataFrame</code> <p>DataFrame in ms_mint results format.</p> required <p>Returns:</p> Type Description <code>Series</code> <p>Series of scores for each peak.</p> Source code in <code>src/ms_mint/processing.py</code> <pre><code>def score_peaks(mint_results: pd.DataFrame) -&gt; pd.Series:\n    \"\"\"Score the peak quality (experimental).\n\n    Calculates a score from 0 to 1 where:\n    - 1 means a good peak shape\n    - 0 means a bad peak shape\n\n    Args:\n        mint_results: DataFrame in ms_mint results format.\n\n    Returns:\n        Series of scores for each peak.\n    \"\"\"\n    R = mint_results.copy()\n    scores = (\n        (1 - R.peak_delta_int.apply(abs) / R.peak_max)\n        * (np.tanh(R.peak_n_datapoints / 20))\n        * (1 / (1 + abs(R.peak_rt_of_max - R[[\"rt_min\", \"rt_max\"]].mean(axis=1))))\n    )\n    return scores\n</code></pre>"},{"location":"api_reference/processing/#ms_mint.processing.slice_ms1_array","title":"<code>slice_ms1_array(array, rt_min, rt_max, mz_mean, mz_width, intensity_threshold)</code>","text":"<p>Slice MS1 data by m/z, retention time, and intensity threshold.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray</code> <p>Input MS-1 data array with columns [scan_time, mz, intensity].</p> required <code>rt_min</code> <code>float</code> <p>Minimum retention time for slice.</p> required <code>rt_max</code> <code>float</code> <p>Maximum retention time for slice.</p> required <code>mz_mean</code> <code>float</code> <p>Mean m/z value for slice.</p> required <code>mz_width</code> <code>float</code> <p>Width of slice in ppm of mz_mean.</p> required <code>intensity_threshold</code> <code>float</code> <p>Noise filter value.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Filtered numpy array containing only data points meeting the criteria.</p> Source code in <code>src/ms_mint/processing.py</code> <pre><code>def slice_ms1_array(\n    array: np.ndarray,\n    rt_min: float,\n    rt_max: float,\n    mz_mean: float,\n    mz_width: float,\n    intensity_threshold: float,\n) -&gt; np.ndarray:\n    \"\"\"Slice MS1 data by m/z, retention time, and intensity threshold.\n\n    Args:\n        array: Input MS-1 data array with columns [scan_time, mz, intensity].\n        rt_min: Minimum retention time for slice.\n        rt_max: Maximum retention time for slice.\n        mz_mean: Mean m/z value for slice.\n        mz_width: Width of slice in ppm of mz_mean.\n        intensity_threshold: Noise filter value.\n\n    Returns:\n        Filtered numpy array containing only data points meeting the criteria.\n    \"\"\"\n    delta_mass = mz_width * mz_mean * 1e-6\n    array = array[(array[:, 0] &gt;= rt_min)]\n    array = array[(array[:, 0] &lt;= rt_max)]\n    array = array[(np.abs(array[:, 1] - mz_mean) &lt;= delta_mass)]\n    array = array[(array[:, 2] &gt;= intensity_threshold)]\n    return array\n</code></pre>"},{"location":"api_reference/targets/","title":"Target list utilities","text":"<p>Everything related to target lists.</p> <p>options:   show_root_heading: true   show_root_full_path: true   show_submodules: true   members_order: source</p>"},{"location":"api_reference/targets/#ms_mint.targets.check_targets","title":"<code>check_targets(targets)</code>","text":"<p>Check if targets are formatted correctly.</p> <p>Parameters:</p> Name Type Description Default <code>targets</code> <code>DataFrame</code> <p>Target list DataFrame to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if all checks pass, else False.</p> Source code in <code>src/ms_mint/targets.py</code> <pre><code>def check_targets(targets: pd.DataFrame) -&gt; bool:\n    \"\"\"Check if targets are formatted correctly.\n\n    Args:\n        targets: Target list DataFrame to check.\n\n    Returns:\n        True if all checks pass, else False.\n    \"\"\"\n    results = (\n        isinstance(targets, pd.DataFrame),\n        _check_target_list_columns_(targets),\n        _check_labels_are_strings_(targets),\n        _check_duplicated_labels_(targets),\n    )\n    result = all(results)\n    if not result:\n        print(results)\n    return all(results)\n</code></pre>"},{"location":"api_reference/targets/#ms_mint.targets.convert_to_seconds","title":"<code>convert_to_seconds(targets)</code>","text":"<p>Convert retention time units to seconds.</p> <p>Parameters:</p> Name Type Description Default <code>targets</code> <code>DataFrame</code> <p>Mint target list to modify in-place.</p> required Source code in <code>src/ms_mint/targets.py</code> <pre><code>def convert_to_seconds(targets: pd.DataFrame) -&gt; None:\n    \"\"\"Convert retention time units to seconds.\n\n    Args:\n        targets: Mint target list to modify in-place.\n    \"\"\"\n    for ndx, row in targets.iterrows():\n        if row.rt_unit == \"min\":\n            targets.loc[ndx, \"rt_unit\"] = \"s\"\n            if targets.loc[ndx, \"rt\"]:\n                targets.loc[ndx, \"rt\"] *= 60.0\n            if targets.loc[ndx, \"rt_min\"]:\n                targets.loc[ndx, \"rt_min\"] *= 60.0\n            if targets.loc[ndx, \"rt_max\"]:\n                targets.loc[ndx, \"rt_max\"] *= 60.0\n</code></pre>"},{"location":"api_reference/targets/#ms_mint.targets.diff_targets","title":"<code>diff_targets(old_pklist, new_pklist)</code>","text":"<p>Get the difference between two target lists.</p> <p>Parameters:</p> Name Type Description Default <code>old_pklist</code> <code>DataFrame</code> <p>Original target list.</p> required <code>new_pklist</code> <code>DataFrame</code> <p>New target list to compare against the original.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing only the targets that are new or changed.</p> Source code in <code>src/ms_mint/targets.py</code> <pre><code>def diff_targets(old_pklist: pd.DataFrame, new_pklist: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Get the difference between two target lists.\n\n    Args:\n        old_pklist: Original target list.\n        new_pklist: New target list to compare against the original.\n\n    Returns:\n        DataFrame containing only the targets that are new or changed.\n    \"\"\"\n    df = df_diff(old_pklist, new_pklist)\n    df = df[df[\"_merge\"] == \"right_only\"]\n    return df.drop(\"_merge\", axis=1)\n</code></pre>"},{"location":"api_reference/targets/#ms_mint.targets.fill_missing_rt_values","title":"<code>fill_missing_rt_values(targets)</code>","text":"<p>Fill missing rt values with mean of rt_min and rt_max.</p> <p>Parameters:</p> Name Type Description Default <code>targets</code> <code>DataFrame</code> <p>Mint target list to modify in-place.</p> required Source code in <code>src/ms_mint/targets.py</code> <pre><code>def fill_missing_rt_values(targets: pd.DataFrame) -&gt; None:\n    \"\"\"Fill missing rt values with mean of rt_min and rt_max.\n\n    Args:\n        targets: Mint target list to modify in-place.\n    \"\"\"\n    for ndx, row in targets.iterrows():\n        if (not row.rt) and (row.rt_min and row.rt_max):\n            targets.loc[ndx, \"rt\"] = np.mean([row.rt_min, row.rt_max])\n</code></pre>"},{"location":"api_reference/targets/#ms_mint.targets.gen_target_grid","title":"<code>gen_target_grid(masses, dt, rt_max=10, mz_ppm=10, intensity_threshold=0)</code>","text":"<p>Create a target grid from a list of masses.</p> <p>Generates a grid of targets by combining each mass with a series of retention time windows spanning from 0 to rt_max.</p> <p>Parameters:</p> Name Type Description Default <code>masses</code> <code>List[float]</code> <p>List of target m/z values.</p> required <code>dt</code> <code>float</code> <p>Size of peak windows in time dimension [min].</p> required <code>rt_max</code> <code>float</code> <p>Maximum retention time to include.</p> <code>10</code> <code>mz_ppm</code> <code>float</code> <p>Width of peak window in m/z dimension [ppm].</p> <code>10</code> <code>intensity_threshold</code> <code>float</code> <p>Minimum intensity threshold for peaks.</p> <code>0</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing generated target list.</p> Source code in <code>src/ms_mint/targets.py</code> <pre><code>def gen_target_grid(\n    masses: List[float],\n    dt: float,\n    rt_max: float = 10,\n    mz_ppm: float = 10,\n    intensity_threshold: float = 0,\n) -&gt; pd.DataFrame:\n    \"\"\"Create a target grid from a list of masses.\n\n    Generates a grid of targets by combining each mass with a series of\n    retention time windows spanning from 0 to rt_max.\n\n    Args:\n        masses: List of target m/z values.\n        dt: Size of peak windows in time dimension [min].\n        rt_max: Maximum retention time to include.\n        mz_ppm: Width of peak window in m/z dimension [ppm].\n        intensity_threshold: Minimum intensity threshold for peaks.\n\n    Returns:\n        DataFrame containing generated target list.\n    \"\"\"\n    rt_cuts = np.arange(0, rt_max + dt, dt)\n    targets = pd.DataFrame(index=rt_cuts, columns=masses).unstack().reset_index()\n    del targets[0]\n    targets.columns = [\"mz_mean\", \"rt_min\"]\n    targets[\"rt_max\"] = targets.rt_min + (1 * dt)\n    targets[\"peak_label\"] = (\n        targets.mz_mean.apply(\"{:.3f}\".format) + \"__\" + targets.rt_min.apply(\"{:2.2f}\".format)\n    )\n    targets[\"mz_width\"] = mz_ppm\n    targets[\"intensity_threshold\"] = intensity_threshold\n    targets[\"targets_name\"] = \"gen_target_grid\"\n    return targets\n</code></pre>"},{"location":"api_reference/targets/#ms_mint.targets.read_targets","title":"<code>read_targets(fns, ms_mode='negative')</code>","text":"<p>Extract peak data from files containing peak definitions.</p> <p>Parameters:</p> Name Type Description Default <code>fns</code> <code>Union[str, List[str]]</code> <p>List of filenames of target lists or a single filename.</p> required <code>ms_mode</code> <code>str</code> <p>Mass spectrometry ionization mode, either \"negative\" or \"positive\".</p> <code>'negative'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing standardized target information from all input files.</p> Source code in <code>src/ms_mint/targets.py</code> <pre><code>def read_targets(fns: Union[str, List[str]], ms_mode: str = \"negative\") -&gt; pd.DataFrame:\n    \"\"\"Extract peak data from files containing peak definitions.\n\n    Args:\n        fns: List of filenames of target lists or a single filename.\n        ms_mode: Mass spectrometry ionization mode, either \"negative\" or \"positive\".\n\n    Returns:\n        DataFrame containing standardized target information from all input files.\n    \"\"\"\n    if isinstance(fns, str):\n        fns = [fns]\n    targets = []\n\n    for fn in fns:\n        fn = str(fn)\n        if fn.endswith(\".csv\"):\n            df = pd.read_csv(fn)\n        elif fn.endswith(\".xlsx\"):\n            df = pd.read_excel(fn)\n        df = standardize_targets(df)\n        df[\"target_filename\"] = P(fn).name\n        targets.append(df)\n\n    targets = pd.concat(targets)\n    return targets\n</code></pre>"},{"location":"api_reference/targets/#ms_mint.targets.standardize_targets","title":"<code>standardize_targets(targets, ms_mode='neutral')</code>","text":"<p>Standardize target list format and units.</p> <p>This function: - Updates the target lists to newest format - Ensures peak labels are strings - Replaces np.nan with None - Converts retention times to seconds - Fills missing values with reasonable defaults</p> <p>Parameters:</p> Name Type Description Default <code>targets</code> <code>DataFrame</code> <p>DataFrame in target-list format.</p> required <code>ms_mode</code> <code>str</code> <p>Ionization mode. Options are \"neutral\", \"positive\", or \"negative\".</p> <code>'neutral'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame in standardized target-list format.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If there are duplicate column names in the input DataFrame.</p> Source code in <code>src/ms_mint/targets.py</code> <pre><code>def standardize_targets(targets: pd.DataFrame, ms_mode: str = \"neutral\") -&gt; pd.DataFrame:\n    \"\"\"Standardize target list format and units.\n\n    This function:\n    - Updates the target lists to newest format\n    - Ensures peak labels are strings\n    - Replaces np.nan with None\n    - Converts retention times to seconds\n    - Fills missing values with reasonable defaults\n\n    Args:\n        targets: DataFrame in target-list format.\n        ms_mode: Ionization mode. Options are \"neutral\", \"positive\", or \"negative\".\n\n    Returns:\n        DataFrame in standardized target-list format.\n\n    Raises:\n        AssertionError: If there are duplicate column names in the input DataFrame.\n    \"\"\"\n    targets = targets.rename(columns=DEPRECATED_LABELS)\n    if targets.index.name == \"peak_label\":\n        targets = targets.reset_index()\n\n    assert pd.Series(targets.columns).value_counts().max() == 1, pd.Series(targets.columns).value_counts()\n\n    cols = targets.columns\n    if \"formula\" in targets.columns and not \"mz_mean\" in targets.columns:\n        targets[\"mz_mean\"] = formula_to_mass(targets[\"formula\"], ms_mode)\n    if \"intensity_threshold\" not in cols:\n        targets[\"intensity_threshold\"] = 0\n    if \"mz_width\" not in cols:\n        targets[\"mz_width\"] = 10\n    if \"target_filename\" not in cols:\n        targets[\"target_filename\"] = \"unknown\"\n    if \"rt_unit\" not in targets.columns:\n        targets[\"rt_unit\"] = \"min\"\n\n    # Standardize time units use SI abbreviations\n    targets[\"rt_unit\"] = targets[\"rt_unit\"].replace(\"m\", \"min\")\n    targets[\"rt_unit\"] = targets[\"rt_unit\"].replace(\"minute\", \"min\")\n    targets[\"rt_unit\"] = targets[\"rt_unit\"].replace(\"minutes\", \"min\")\n    targets[\"rt_unit\"] = targets[\"rt_unit\"].replace(\"sec\", \"s\")\n    targets[\"rt_unit\"] = targets[\"rt_unit\"].replace(\"second\", \"s\")\n    targets[\"rt_unit\"] = targets[\"rt_unit\"].replace(\"seconds\", \"s\")\n\n    for c in [\"rt\", \"rt_min\", \"rt_max\"]:\n        if c not in cols:\n            targets[c] = None\n            targets[c] = targets[c].astype(float)\n\n    if \"peak_label\" not in cols:\n        logging.warning(f'\"peak_label\" not in cols, assigning new labels:\\n{targets}')\n        targets[\"peak_label\"] = [f\"C_{i}\" for i in range(len(targets))]\n\n    targets[\"intensity_threshold\"] = targets[\"intensity_threshold\"].fillna(0)\n    targets[\"peak_label\"] = targets[\"peak_label\"].astype(str)\n\n    targets.index = range(len(targets))\n    targets = targets[targets.mz_mean.notna()]\n    targets = targets.replace(np.nan, None)\n    fill_missing_rt_values(targets)\n    convert_to_seconds(targets)\n\n    if \"rt\" in targets.columns:\n        targets[\"rt\"] = targets[\"rt\"].astype(float)\n\n    return targets[TARGETS_COLUMNS]\n</code></pre>"},{"location":"api_reference/tools/","title":"Helper tools","text":"<p>options:   show_root_heading: true   show_root_full_path: true   show_submodules: true   members_order: source</p>"},{"location":"api_reference/tools/#ms_mint.tools.df_diff","title":"<code>df_diff(df1, df2, which='both')</code>","text":"<p>Find differences between two dataframes.</p> <p>Parameters:</p> Name Type Description Default <code>df1</code> <code>DataFrame</code> <p>Reference DataFrame.</p> required <code>df2</code> <code>DataFrame</code> <p>DataFrame to compare.</p> required <code>which</code> <code>str</code> <p>Direction in which to compare. Options are \"both\", \"left_only\", \"right_only\".</p> <code>'both'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing only the rows that differ according to the specified direction.</p> Source code in <code>src/ms_mint/tools.py</code> <pre><code>def df_diff(df1: pd.DataFrame, df2: pd.DataFrame, which: str = \"both\") -&gt; pd.DataFrame:\n    \"\"\"Find differences between two dataframes.\n\n    Args:\n        df1: Reference DataFrame.\n        df2: DataFrame to compare.\n        which: Direction in which to compare. Options are \"both\", \"left_only\", \"right_only\".\n\n    Returns:\n        DataFrame containing only the rows that differ according to the specified direction.\n    \"\"\"\n    _df = df1.merge(df2, indicator=True, how=\"outer\")\n    diff_df = _df[_df[\"_merge\"] != which]\n    return diff_df.reset_index(drop=True)\n</code></pre>"},{"location":"api_reference/tools/#ms_mint.tools.find_peaks_in_timeseries","title":"<code>find_peaks_in_timeseries(series, prominence=None, plot=False, rel_height=0.9, **kwargs)</code>","text":"<p>Find peaks in a time series using scipy's peak finding algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>Time series data to find peaks in.</p> required <code>prominence</code> <code>Optional[float]</code> <p>Minimum prominence of peaks. If None, all peaks are detected.</p> <code>None</code> <code>plot</code> <code>bool</code> <p>Whether to generate a plot of the detected peaks.</p> <code>False</code> <code>rel_height</code> <code>float</code> <p>Relative height from the peak at which to determine peak width.</p> <code>0.9</code> <code>**kwargs</code> <p>Additional arguments passed to scipy.signal.find_peaks.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing peak properties including retention times and heights.</p> Source code in <code>src/ms_mint/tools.py</code> <pre><code>def find_peaks_in_timeseries(\n    series: pd.Series,\n    prominence: Optional[float] = None,\n    plot: bool = False,\n    rel_height: float = 0.9,\n    **kwargs,\n) -&gt; pd.DataFrame:\n    \"\"\"Find peaks in a time series using scipy's peak finding algorithm.\n\n    Args:\n        series: Time series data to find peaks in.\n        prominence: Minimum prominence of peaks. If None, all peaks are detected.\n        plot: Whether to generate a plot of the detected peaks.\n        rel_height: Relative height from the peak at which to determine peak width.\n        **kwargs: Additional arguments passed to scipy.signal.find_peaks.\n\n    Returns:\n        DataFrame containing peak properties including retention times and heights.\n    \"\"\"\n    t = series.index\n    x = series.values\n    peak_ndxs, _ = find_peaks(x, prominence=prominence, rel_height=rel_height, **kwargs)\n    widths, heights, left_ips, right_ips = peak_widths(x, peak_ndxs, rel_height=rel_height)\n    times = series.iloc[peak_ndxs].index\n\n    t_start = _map_ndxs_to_time(left_ips, min(t), max(t), 0, len(t))\n    t_end = _map_ndxs_to_time(right_ips, min(t), max(t), 0, len(t))\n\n    data = dict(\n        ndxs=peak_ndxs,\n        rt=times,\n        rt_span=widths,\n        peak_base_height=heights,\n        peak_height=series.iloc[peak_ndxs].values,\n        rt_min=t_start,\n        rt_max=t_end,\n    )\n\n    peaks = pd.DataFrame(data)\n\n    if plot:\n        plot_peaks(series, peaks)\n\n    return peaks\n</code></pre>"},{"location":"api_reference/tools/#ms_mint.tools.fn_to_label","title":"<code>fn_to_label(fn)</code>","text":"<p>Convert a filename to a label by removing the file extension.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Union[str, Path]</code> <p>Filename or path.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Filename without extension.</p> Source code in <code>src/ms_mint/tools.py</code> <pre><code>def fn_to_label(fn: Union[str, P]) -&gt; str:\n    \"\"\"Convert a filename to a label by removing the file extension.\n\n    Args:\n        fn: Filename or path.\n\n    Returns:\n        Filename without extension.\n    \"\"\"\n    return P(fn).with_suffix(\"\").name\n</code></pre>"},{"location":"api_reference/tools/#ms_mint.tools.formula_to_mass","title":"<code>formula_to_mass(formulas, ms_mode=None)</code>","text":"<p>Calculate m/z values from molecular formulas for specific ionization mode.</p> <p>Parameters:</p> Name Type Description Default <code>formulas</code> <code>Union[str, List[str]]</code> <p>List of molecular formulas (e.g., ['H2O']) or a single formula.</p> required <code>ms_mode</code> <code>Optional[Literal['negative', 'positive', 'neutral']]</code> <p>Ionization mode. One of \"negative\", \"positive\", \"neutral\", or None.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Optional[float]]</code> <p>List of calculated masses. None values are included for invalid formulas.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If ms_mode is not one of the allowed values.</p> Source code in <code>src/ms_mint/tools.py</code> <pre><code>def formula_to_mass(\n    formulas: Union[str, List[str]],\n    ms_mode: Optional[Literal[\"negative\", \"positive\", \"neutral\"]] = None,\n) -&gt; List[Optional[float]]:\n    \"\"\"Calculate m/z values from molecular formulas for specific ionization mode.\n\n    Args:\n        formulas: List of molecular formulas (e.g., ['H2O']) or a single formula.\n        ms_mode: Ionization mode. One of \"negative\", \"positive\", \"neutral\", or None.\n\n    Returns:\n        List of calculated masses. None values are included for invalid formulas.\n\n    Raises:\n        AssertionError: If ms_mode is not one of the allowed values.\n    \"\"\"\n    masses = []\n    assert ms_mode in [None, \"negative\", \"positive\", \"neutral\"], ms_mode\n    if isinstance(formulas, str):\n        formulas = [formulas]\n    for formula in formulas:\n        try:\n            mass = Formula(formula).isotope.mass\n            if ms_mode == \"positive\":\n                mass += M_PROTON\n            elif ms_mode == \"negative\":\n                mass -= M_PROTON\n            mass = np.round(mass, 4)\n            masses.append(mass)\n        except FormulaError as e:\n            masses.append(None)\n            logging.warning(e)  # Fixed typo: waringin \u2192 warning\n    return masses\n</code></pre>"},{"location":"api_reference/tools/#ms_mint.tools.gaussian","title":"<code>gaussian(x, mu, sig)</code>","text":"<p>Generate values for a Gaussian function.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Union[List[float], ndarray]</code> <p>x-values to generate function values.</p> required <code>mu</code> <code>float</code> <p>Mean of the Gaussian.</p> required <code>sig</code> <code>float</code> <p>Standard deviation of the Gaussian.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of Gaussian function values at the input x-values.</p> Source code in <code>src/ms_mint/tools.py</code> <pre><code>def gaussian(x: Union[List[float], np.ndarray], mu: float, sig: float) -&gt; np.ndarray:\n    \"\"\"Generate values for a Gaussian function.\n\n    Args:\n        x: x-values to generate function values.\n        mu: Mean of the Gaussian.\n        sig: Standard deviation of the Gaussian.\n\n    Returns:\n        Array of Gaussian function values at the input x-values.\n    \"\"\"\n    x = np.array(x)\n    return np.exp(-np.power(x - mu, 2.0) / (2 * np.power(sig, 2.0)))\n</code></pre>"},{"location":"api_reference/tools/#ms_mint.tools.get_ms_files_from_results","title":"<code>get_ms_files_from_results(results)</code>","text":"<p>Extract MS filenames from Mint results.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>DataFrame</code> <p>DataFrame in Mint results format.</p> required <p>Returns:</p> Type Description <code>List[Union[str, Path]]</code> <p>List of MS filenames.</p> Source code in <code>src/ms_mint/tools.py</code> <pre><code>def get_ms_files_from_results(results: pd.DataFrame) -&gt; List[Union[str, P]]:\n    \"\"\"Extract MS filenames from Mint results.\n\n    Args:\n        results: DataFrame in Mint results format.\n\n    Returns:\n        List of MS filenames.\n    \"\"\"\n    # Old schema\n    if \"ms_path\" in results.columns:\n        ms_files = results[[\"ms_path\", \"ms_file\"]].drop_duplicates()\n        ms_files = [P(ms_path) / ms_file for ms_path, ms_file in ms_files.values]\n    else:\n        ms_files = results.ms_file.unique()\n    return ms_files\n</code></pre>"},{"location":"api_reference/tools/#ms_mint.tools.get_targets_from_results","title":"<code>get_targets_from_results(results)</code>","text":"<p>Extract targets DataFrame from MS-MINT results table.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>DataFrame</code> <p>Mint results table.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing target information extracted from results.</p> Source code in <code>src/ms_mint/tools.py</code> <pre><code>def get_targets_from_results(results: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Extract targets DataFrame from MS-MINT results table.\n\n    Args:\n        results: Mint results table.\n\n    Returns:\n        DataFrame containing target information extracted from results.\n    \"\"\"\n    return results[[col for col in TARGETS_COLUMNS if col in results.columns]].drop_duplicates()\n</code></pre>"},{"location":"api_reference/tools/#ms_mint.tools.init_metadata","title":"<code>init_metadata()</code>","text":"<p>Initialize an empty metadata DataFrame with the standard columns.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Empty DataFrame with standard metadata columns and 'ms_file_label' as index.</p> Source code in <code>src/ms_mint/tools.py</code> <pre><code>def init_metadata() -&gt; pd.DataFrame:\n    \"\"\"Initialize an empty metadata DataFrame with the standard columns.\n\n    Returns:\n        Empty DataFrame with standard metadata columns and 'ms_file_label' as index.\n    \"\"\"\n    cols = MINT_METADATA_COLUMNS\n    return pd.DataFrame(columns=cols).set_index(\"ms_file_label\")\n</code></pre>"},{"location":"api_reference/tools/#ms_mint.tools.is_ms_file","title":"<code>is_ms_file(fn)</code>","text":"<p>Check if a file is a recognized MS file format based on its extension.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Union[str, Path]</code> <p>Filename or path to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the file has a recognized MS file extension, False otherwise.</p> Source code in <code>src/ms_mint/tools.py</code> <pre><code>def is_ms_file(fn: Union[str, P]) -&gt; bool:\n    \"\"\"Check if a file is a recognized MS file format based on its extension.\n\n    Args:\n        fn: Filename or path to check.\n\n    Returns:\n        True if the file has a recognized MS file extension, False otherwise.\n    \"\"\"\n    fn = str(fn)\n    if (\n        (fn.lower().endswith(\".mzxml\"))\n        or (fn.lower().endswith(\".mzml\"))\n        or (fn.lower().endswith(\".mzmlb\"))\n        or (fn.lower().endswith(\".mzhdf\"))\n        or (fn.lower().endswith(\".raw\"))\n        or (fn.lower().endswith(\".parquet\"))\n        or (fn.lower().endswith(\".feather\"))\n    ):\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"api_reference/tools/#ms_mint.tools.lock","title":"<code>lock(fn)</code>","text":"<p>Create a file lock to ensure safe writing to file.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Union[str, Path]</code> <p>Filename to lock.</p> required <p>Returns:</p> Type Description <code>FileLock</code> <p>File lock object.</p> Source code in <code>src/ms_mint/tools.py</code> <pre><code>def lock(fn: Union[str, P]) -&gt; FileLock:\n    \"\"\"Create a file lock to ensure safe writing to file.\n\n    Args:\n        fn: Filename to lock.\n\n    Returns:\n        File lock object.\n    \"\"\"\n    return FileLock(f\"{fn}.lock\", timeout=1)\n</code></pre>"},{"location":"api_reference/tools/#ms_mint.tools.log2p1","title":"<code>log2p1(x)</code>","text":"<p>Apply log2(x+1) transformation to numeric data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Union[float, ndarray, Series]</code> <p>Numeric value or array to transform.</p> required <p>Returns:</p> Type Description <code>Union[float, ndarray, Series]</code> <p>Transformed value(s).</p> Source code in <code>src/ms_mint/tools.py</code> <pre><code>def log2p1(x: Union[float, np.ndarray, pd.Series]) -&gt; Union[float, np.ndarray, pd.Series]:\n    \"\"\"Apply log2(x+1) transformation to numeric data.\n\n    Args:\n        x: Numeric value or array to transform.\n\n    Returns:\n        Transformed value(s).\n    \"\"\"\n    return np.log2(x + 1)\n</code></pre>"},{"location":"api_reference/tools/#ms_mint.tools.mz_mean_width_to_min_max","title":"<code>mz_mean_width_to_min_max(mz_mean, mz_width)</code>","text":"<p>Convert m/z mean and width (in ppm) to min and max m/z values.</p> <p>Parameters:</p> Name Type Description Default <code>mz_mean</code> <code>float</code> <p>Mean m/z value.</p> required <code>mz_width</code> <code>float</code> <p>Width in parts-per-million (ppm).</p> required <p>Returns:</p> Type Description <code>Tuple[float, float]</code> <p>Tuple of (mz_min, mz_max) defining the m/z range.</p> Source code in <code>src/ms_mint/tools.py</code> <pre><code>def mz_mean_width_to_min_max(mz_mean: float, mz_width: float) -&gt; Tuple[float, float]:\n    \"\"\"Convert m/z mean and width (in ppm) to min and max m/z values.\n\n    Args:\n        mz_mean: Mean m/z value.\n        mz_width: Width in parts-per-million (ppm).\n\n    Returns:\n        Tuple of (mz_min, mz_max) defining the m/z range.\n    \"\"\"\n    delta_mass = mz_width * mz_mean * 1e-6\n    mz_min = mz_mean - delta_mass\n    mz_max = mz_mean + delta_mass\n    return mz_min, mz_max\n</code></pre>"},{"location":"api_reference/tools/#ms_mint.tools.scale_dataframe","title":"<code>scale_dataframe(df, scaler='standard', **kwargs)</code>","text":"<p>Scale all columns in a dense dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame to scale.</p> required <code>scaler</code> <code>Union[str, Any]</code> <p>Scaler to use. Either a string ('robust', 'standard', 'minmax') or a scikit-learn scaler instance.</p> <code>'standard'</code> <code>**kwargs</code> <p>Additional arguments passed to the scaler constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Scaled DataFrame with the same shape as the input.</p> Source code in <code>src/ms_mint/tools.py</code> <pre><code>def scale_dataframe(\n    df: pd.DataFrame, scaler: Union[str, Any] = \"standard\", **kwargs\n) -&gt; pd.DataFrame:\n    \"\"\"Scale all columns in a dense dataframe.\n\n    Args:\n        df: DataFrame to scale.\n        scaler: Scaler to use. Either a string ('robust', 'standard', 'minmax')\n            or a scikit-learn scaler instance.\n        **kwargs: Additional arguments passed to the scaler constructor.\n\n    Returns:\n        Scaled DataFrame with the same shape as the input.\n    \"\"\"\n    df = df.copy()\n    if isinstance(scaler, str):\n        if scaler == \"standard\":\n            scaler = StandardScaler(**kwargs)\n        elif scaler == \"robust\":\n            scaler = RobustScaler(**kwargs)\n        elif scaler == \"minmax\":\n            scaler = MinMaxScaler(**kwargs)\n    df.loc[:, :] = scaler.fit_transform(df)\n    return df\n</code></pre>"},{"location":"api_reference/visualization/","title":"Visualization tools","text":"<p>options:   show_root_heading: true   show_root_full_path: true   show_submodules: true   members_order: source</p> <p>options:   show_root_heading: true   show_root_full_path: true   show_submodules: true   members_order: source</p> <p>options:   show_root_heading: true   show_root_full_path: true   show_submodules: true   members_order: source</p>"},{"location":"api_reference/visualization/#ms_mint.matplotlib_tools.hierarchical_clustering","title":"<code>hierarchical_clustering(df, vmin=None, vmax=None, figsize=(8, 8), top_height=2, left_width=2, xmaxticks=None, ymaxticks=None, metric='cosine', cmap=None)</code>","text":"<p>Perform and plot hierarchical clustering on a dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input data in DataFrame format.</p> required <code>vmin</code> <code>Optional[float]</code> <p>Minimum value to anchor the colormap. If None, inferred from data.</p> <code>None</code> <code>vmax</code> <code>Optional[float]</code> <p>Maximum value to anchor the colormap. If None, inferred from data.</p> <code>None</code> <code>figsize</code> <code>Tuple[int, int]</code> <p>Size of the main figure in inches.</p> <code>(8, 8)</code> <code>top_height</code> <code>int</code> <p>Height of the top dendrogram.</p> <code>2</code> <code>left_width</code> <code>int</code> <p>Width of the left dendrogram.</p> <code>2</code> <code>xmaxticks</code> <code>Optional[int]</code> <p>Maximum number of x-ticks to display.</p> <code>None</code> <code>ymaxticks</code> <code>Optional[int]</code> <p>Maximum number of y-ticks to display.</p> <code>None</code> <code>metric</code> <code>Union[str, Tuple[str, str]]</code> <p>Distance metric to use. Either a string to use the same metric for both axes, or a tuple of two strings for different metrics for each axis.</p> <code>'cosine'</code> <code>cmap</code> <code>Optional[str]</code> <p>Matplotlib colormap name. If None, uses \"coolwarm\".</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[DataFrame, Figure, List[int], List[int]]</code> <p>A tuple containing: - The clustered DataFrame (reordered according to clustering) - The matplotlib Figure object - The indices of rows in their clustered order - The indices of columns in their clustered order</p> Source code in <code>src/ms_mint/matplotlib_tools.py</code> <pre><code>def hierarchical_clustering(\n    df: pd.DataFrame,\n    vmin: Optional[float] = None,\n    vmax: Optional[float] = None,\n    figsize: Tuple[int, int] = (8, 8),\n    top_height: int = 2,\n    left_width: int = 2,\n    xmaxticks: Optional[int] = None,\n    ymaxticks: Optional[int] = None,\n    metric: Union[str, Tuple[str, str]] = \"cosine\",\n    cmap: Optional[str] = None,\n) -&gt; Tuple[pd.DataFrame, Figure, List[int], List[int]]:\n    \"\"\"Perform and plot hierarchical clustering on a dataframe.\n\n    Args:\n        df: Input data in DataFrame format.\n        vmin: Minimum value to anchor the colormap. If None, inferred from data.\n        vmax: Maximum value to anchor the colormap. If None, inferred from data.\n        figsize: Size of the main figure in inches.\n        top_height: Height of the top dendrogram.\n        left_width: Width of the left dendrogram.\n        xmaxticks: Maximum number of x-ticks to display.\n        ymaxticks: Maximum number of y-ticks to display.\n        metric: Distance metric to use. Either a string to use the same metric for\n            both axes, or a tuple of two strings for different metrics for each axis.\n        cmap: Matplotlib colormap name. If None, uses \"coolwarm\".\n\n    Returns:\n        A tuple containing:\n            - The clustered DataFrame (reordered according to clustering)\n            - The matplotlib Figure object\n            - The indices of rows in their clustered order\n            - The indices of columns in their clustered order\n    \"\"\"\n    if isinstance(metric, str):\n        metric_x, metric_y = metric, metric\n    elif (\n        isinstance(metric, tuple)\n        and len(metric) == 2\n        and isinstance(metric[0], str)\n        and isinstance(metric[1], str)\n    ):\n        metric_x, metric_y = metric\n    elif metric is None:\n        metric_x, metric_y = None, None\n    else:\n        raise ValueError(\"Metric must be a string or a tuple of two strings\")\n\n    df = df.copy()\n\n    # Subplot sizes\n    total_width, total_height = figsize\n\n    main_h = 1 - (top_height / total_height)\n    main_w = 1 - (left_width / total_width)\n\n    gap_x = 0.1 / total_width\n    gap_y = 0.1 / total_height\n\n    left_h = main_h\n    left_w = 1 - main_w\n\n    top_h = 1 - main_h\n    top_w = main_w\n\n    if xmaxticks is None:\n        xmaxticks = int(5 * main_w * total_width)\n    if ymaxticks is None:\n        ymaxticks = int(5 * main_h * total_height)\n\n    dm = df.fillna(0).values\n    D1 = squareform(pdist(dm, metric=metric_y))\n    D2 = squareform(pdist(dm.T, metric=metric_x))\n\n    fig = plt.figure(figsize=figsize)\n    fig.set_layout_engine('tight')\n\n    # add left dendrogram\n    ax1 = fig.add_axes([0, 0, left_w - gap_x, left_h], frameon=False)\n    Y = linkage(D1, method=\"complete\")\n    Z1 = dendrogram(Y, orientation=\"left\", color_threshold=0, above_threshold_color=\"k\")\n    ax1.set_xticks([])\n    ax1.set_yticks([])\n    # add top dendrogram\n    ax2 = fig.add_axes([left_w, main_h + gap_y, top_w, top_h - gap_y], frameon=False)\n    Y = linkage(D2, method=\"complete\")\n    Z2 = dendrogram(Y, color_threshold=0, above_threshold_color=\"k\")\n    ax2.set_xticks([])\n    ax2.set_yticks([])\n    # add matrix plot\n    axmatrix = fig.add_axes([left_w, 0, main_w, main_h])\n    idx1 = Z1[\"leaves\"]\n    idx2 = Z2[\"leaves\"]\n    D = dm[idx1, :]\n    D = D[:, idx2]\n\n    if cmap is None:\n        cmap = \"coolwarm\"\n    im = axmatrix.matshow(D[::-1], aspect=\"auto\", cmap=cmap, vmin=vmin, vmax=vmax)\n\n    axmatrix.set_xticks([])\n    axmatrix.set_yticks([])\n\n    ax = plt.gca()\n    ax.yaxis.tick_right()\n    ax.xaxis.tick_bottom()\n\n    clustered = df.iloc[Z1[\"leaves\"][::-1], Z2[\"leaves\"]]\n\n    ndx_y = np.linspace(0, len(clustered.index) - 1, ymaxticks)\n    ndx_x = np.linspace(0, len(clustered.columns) - 1, xmaxticks)\n    ndx_y = [int(i) for i in ndx_y]\n    ndx_x = [int(i) for i in ndx_x]\n\n    _ = plt.yticks(ndx_y, clustered.iloc[ndx_y].index)\n    _ = plt.xticks(ndx_x, clustered.columns[ndx_x], rotation=90)\n\n    ndx_leaves = Z1[\"leaves\"][::-1]\n    col_leaves = Z2[\"leaves\"]\n\n    return clustered, fig, ndx_leaves, col_leaves\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.matplotlib_tools.plot_metabolomics_hist2d","title":"<code>plot_metabolomics_hist2d(df, figsize=(4, 2.5), dpi=300, set_dim=True, cmap='jet', rt_range=None, mz_range=None, mz_bins=100, **kwargs)</code>","text":"<p>Create a 2D histogram of metabolomics data.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing metabolomics data with scan_time, mz, and intensity columns.</p> required <code>figsize</code> <code>Tuple[float, float]</code> <p>Size of the figure in inches (width, height).</p> <code>(4, 2.5)</code> <code>dpi</code> <code>int</code> <p>Resolution of the figure in dots per inch.</p> <code>300</code> <code>set_dim</code> <code>bool</code> <p>Whether to set figure dimensions.</p> <code>True</code> <code>cmap</code> <code>str</code> <p>Colormap name to use for the plot.</p> <code>'jet'</code> <code>rt_range</code> <code>Optional[Tuple[float, float]]</code> <p>Retention time range (min, max) to display. If None, uses data range.</p> <code>None</code> <code>mz_range</code> <code>Optional[Tuple[float, float]]</code> <p>M/Z range (min, max) to display. If None, uses data range.</p> <code>None</code> <code>mz_bins</code> <code>int</code> <p>Number of bins to use for the m/z axis.</p> <code>100</code> <code>**kwargs</code> <p>Additional keyword arguments passed to plt.hist2d.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray, Any]</code> <p>The result of plt.hist2d, which is a tuple containing: - The histogram array - The edges of the bins along the x-axis - The edges of the bins along the y-axis - The Axes object</p> Source code in <code>src/ms_mint/matplotlib_tools.py</code> <pre><code>def plot_metabolomics_hist2d(\n    df: pd.DataFrame,\n    figsize: Tuple[float, float] = (4, 2.5),\n    dpi: int = 300,\n    set_dim: bool = True,\n    cmap: str = \"jet\",\n    rt_range: Optional[Tuple[float, float]] = None,\n    mz_range: Optional[Tuple[float, float]] = None,\n    mz_bins: int = 100,\n    **kwargs,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, Any]:\n    \"\"\"Create a 2D histogram of metabolomics data.\n\n    Args:\n        df: DataFrame containing metabolomics data with scan_time, mz, and intensity columns.\n        figsize: Size of the figure in inches (width, height).\n        dpi: Resolution of the figure in dots per inch.\n        set_dim: Whether to set figure dimensions.\n        cmap: Colormap name to use for the plot.\n        rt_range: Retention time range (min, max) to display. If None, uses data range.\n        mz_range: M/Z range (min, max) to display. If None, uses data range.\n        mz_bins: Number of bins to use for the m/z axis.\n        **kwargs: Additional keyword arguments passed to plt.hist2d.\n\n    Returns:\n        The result of plt.hist2d, which is a tuple containing:\n            - The histogram array\n            - The edges of the bins along the x-axis\n            - The edges of the bins along the y-axis\n            - The Axes object\n    \"\"\"\n    if set_dim:\n        plt.figure(figsize=figsize, dpi=dpi)\n\n    if mz_range is None:\n        mz_range = (df.mz.min(), df.mz.max())\n\n    if rt_range is None:\n        rt_range = (df.scan_time.min(), df.scan_time.max())\n\n    rt_bins = int((rt_range[1] - rt_range[0]) / 2)\n\n    params = dict(vmin=1, vmax=1e3, cmap=cmap, range=(rt_range, mz_range))\n    params.update(kwargs)\n\n    fig = plt.hist2d(\n        df[\"scan_time\"],\n        df[\"mz\"],\n        weights=df[\"intensity\"].apply(np.log1p),\n        bins=[rt_bins, mz_bins],\n        **params,\n    )\n\n    plt.xlabel(\"Scan time [s]\")\n    plt.ylabel(\"m/z\")\n    plt.gca().ticklabel_format(useOffset=False, style=\"plain\")\n    return fig\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.matplotlib_tools.plot_peak_shapes","title":"<code>plot_peak_shapes(mint_results, mint_metadata=None, fns=None, peak_labels=None, height=3, aspect=1.5, legend=False, col_wrap=4, hue='ms_file_label', title=None, dpi=None, sharex=False, sharey=False, kind='line', **kwargs)</code>","text":"<p>Plot peak shapes from MS-MINT results.</p> <p>Parameters:</p> Name Type Description Default <code>mint_results</code> <code>DataFrame</code> <p>DataFrame in Mint results format.</p> required <code>mint_metadata</code> <code>Optional[DataFrame]</code> <p>DataFrame in Mint metadata format for additional sample information.</p> <code>None</code> <code>fns</code> <code>Optional[List[str]]</code> <p>Filenames to include. If None, includes all files.</p> <code>None</code> <code>peak_labels</code> <code>Optional[Union[str, List[str]]]</code> <p>Peak label(s) to include. If None, includes all peak labels.</p> <code>None</code> <code>height</code> <code>int</code> <p>Height of each figure facet in inches.</p> <code>3</code> <code>aspect</code> <code>float</code> <p>Aspect ratio (width/height) of each figure facet.</p> <code>1.5</code> <code>legend</code> <code>bool</code> <p>Whether to display a legend.</p> <code>False</code> <code>col_wrap</code> <code>int</code> <p>Number of columns for subplots.</p> <code>4</code> <code>hue</code> <code>str</code> <p>Column name to use for color grouping.</p> <code>'ms_file_label'</code> <code>title</code> <code>Optional[str]</code> <p>Title to add to the figure.</p> <code>None</code> <code>dpi</code> <code>Optional[int]</code> <p>Resolution of generated image.</p> <code>None</code> <code>sharex</code> <code>bool</code> <p>Whether to share x-axis range between subplots.</p> <code>False</code> <code>sharey</code> <code>bool</code> <p>Whether to share y-axis range between subplots.</p> <code>False</code> <code>kind</code> <code>str</code> <p>Type of seaborn relplot ('line', 'scatter', etc.).</p> <code>'line'</code> <code>**kwargs</code> <p>Additional keyword arguments passed to seaborn's relplot.</p> <code>{}</code> <p>Returns:</p> Type Description <code>FacetGrid</code> <p>A seaborn FacetGrid object containing the plot.</p> Source code in <code>src/ms_mint/matplotlib_tools.py</code> <pre><code>def plot_peak_shapes(\n    mint_results: pd.DataFrame,\n    mint_metadata: Optional[pd.DataFrame] = None,\n    fns: Optional[List[str]] = None,\n    peak_labels: Optional[Union[str, List[str]]] = None,\n    height: int = 3,\n    aspect: float = 1.5,\n    legend: bool = False,\n    col_wrap: int = 4,\n    hue: str = \"ms_file_label\",\n    title: Optional[str] = None,\n    dpi: Optional[int] = None,\n    sharex: bool = False,\n    sharey: bool = False,\n    kind: str = \"line\",\n    **kwargs,\n) -&gt; sns.FacetGrid:\n    \"\"\"Plot peak shapes from MS-MINT results.\n\n    Args:\n        mint_results: DataFrame in Mint results format.\n        mint_metadata: DataFrame in Mint metadata format for additional sample information.\n        fns: Filenames to include. If None, includes all files.\n        peak_labels: Peak label(s) to include. If None, includes all peak labels.\n        height: Height of each figure facet in inches.\n        aspect: Aspect ratio (width/height) of each figure facet.\n        legend: Whether to display a legend.\n        col_wrap: Number of columns for subplots.\n        hue: Column name to use for color grouping.\n        title: Title to add to the figure.\n        dpi: Resolution of generated image.\n        sharex: Whether to share x-axis range between subplots.\n        sharey: Whether to share y-axis range between subplots.\n        kind: Type of seaborn relplot ('line', 'scatter', etc.).\n        **kwargs: Additional keyword arguments passed to seaborn's relplot.\n\n    Returns:\n        A seaborn FacetGrid object containing the plot.\n    \"\"\"\n    R = mint_results.copy()\n    R = R[R.peak_area &gt; 0]\n    R[\"peak_label\"] = R[\"peak_label\"]\n\n    if peak_labels is not None:\n        if isinstance(peak_labels, str):\n            peak_labels = [peak_labels]\n        R = R[R.peak_label.isin(peak_labels)]\n    else:\n        peak_labels = R.peak_label.drop_duplicates().values\n\n    if fns is not None:\n        R = R[R.ms_file.isin(fns)]\n\n    dfs = []\n    for peak_label in peak_labels:\n        for _, row in R[(R.peak_label == peak_label) &amp; (R.peak_n_datapoints &gt; 1)].iterrows():\n            peak_rt = [float(i) for i in row.peak_shape_rt.split(\",\")]\n            peak_int = [float(i) for i in row.peak_shape_int.split(\",\")]\n            ms_file_label = row.ms_file_label\n            mz = row.mz_mean\n            rt = row.rt\n\n            df = pd.DataFrame(\n                {\n                    \"Scan time [s]\": peak_rt,\n                    \"Intensity\": peak_int,\n                    \"ms_file_label\": ms_file_label,\n                    \"peak_label\": peak_label,\n                    \"Expected Scan time [s]\": rt,\n                }\n            )\n            dfs.append(df)\n\n    if not dfs:\n        return None\n\n    df = pd.concat(dfs, ignore_index=True).reset_index(drop=True)\n\n    # Add metadata\n    if mint_metadata is not None:\n        df = pd.merge(df, mint_metadata, left_on=\"ms_file_label\", right_index=True, how=\"left\")\n\n    _facet_kws = dict(sharex=sharex, sharey=sharey)\n    if \"facet_kws\" in kwargs.keys():\n        _facet_kws.update(kwargs.pop(\"facet_kws\"))\n\n    g = sns.relplot(\n        data=df,\n        x=\"Scan time [s]\",\n        y=\"Intensity\",\n        hue=hue,\n        col=\"peak_label\",\n        col_order=peak_labels,\n        kind=kind,\n        col_wrap=col_wrap,\n        height=height,\n        aspect=aspect,\n        facet_kws=_facet_kws,\n        legend=legend,\n        **kwargs,\n    )\n\n    g.set_titles(row_template=\"{row_name}\", col_template=\"{col_name}\")\n\n    for ax in g.axes.flatten():\n        ax.ticklabel_format(style=\"sci\", scilimits=(0, 0), axis=\"y\")\n\n    if title is not None:\n        g.fig.suptitle(title, y=1.01)\n\n    return g\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.matplotlib_tools.plot_peaks","title":"<code>plot_peaks(series, peaks=None, highlight=None, expected_rt=None, weights=None, legend=True, label=None, **kwargs)</code>","text":"<p>Plot time series data with peak annotations.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>Time series data with time as index and intensity as values.</p> required <code>peaks</code> <code>Optional[DataFrame]</code> <p>DataFrame containing peak information.</p> <code>None</code> <code>highlight</code> <code>Optional[List[int]]</code> <p>List of peak indices to highlight.</p> <code>None</code> <code>expected_rt</code> <code>Optional[float]</code> <p>Expected retention time to mark on the plot.</p> <code>None</code> <code>weights</code> <code>Optional[ndarray]</code> <p>Array of weight values (e.g., for Gaussian weighting).</p> <code>None</code> <code>legend</code> <code>bool</code> <p>Whether to display the legend.</p> <code>True</code> <code>label</code> <code>Optional[str]</code> <p>Label for the time series data.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to the plot function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Matplotlib Figure containing the plot.</p> Source code in <code>src/ms_mint/matplotlib_tools.py</code> <pre><code>def plot_peaks(\n    series: pd.Series,\n    peaks: Optional[pd.DataFrame] = None,\n    highlight: Optional[List[int]] = None,\n    expected_rt: Optional[float] = None,\n    weights: Optional[np.ndarray] = None,\n    legend: bool = True,\n    label: Optional[str] = None,\n    **kwargs,\n) -&gt; Figure:\n    \"\"\"Plot time series data with peak annotations.\n\n    Args:\n        series: Time series data with time as index and intensity as values.\n        peaks: DataFrame containing peak information.\n        highlight: List of peak indices to highlight.\n        expected_rt: Expected retention time to mark on the plot.\n        weights: Array of weight values (e.g., for Gaussian weighting).\n        legend: Whether to display the legend.\n        label: Label for the time series data.\n        **kwargs: Additional keyword arguments passed to the plot function.\n\n    Returns:\n        Matplotlib Figure containing the plot.\n    \"\"\"\n    if highlight is None:\n        highlight = []\n    ax = plt.gca()\n    ax.plot(\n        series.index,\n        series.values,\n        label=label if label is not None else \"Intensity\",\n        **kwargs,\n    )\n    if peaks is not None:\n        series.iloc[peaks.ndxs].plot(label=\"Peaks\", marker=\"x\", y=\"intensity\", lw=0, ax=ax)\n        for i, (\n            ndx,\n            (_, _, _, peak_base_height, _, rt_min, rt_max),\n        ) in enumerate(peaks.iterrows()):\n            if ndx in highlight:\n                plt.axvspan(rt_min, rt_max, color=\"green\", alpha=0.25, label=\"Selected\")\n            plt.hlines(\n                peak_base_height,\n                rt_min,\n                rt_max,\n                color=\"orange\",\n                label=\"Peak width\" if i == 0 else None,\n            )\n    if expected_rt is not None:\n        plt.axvspan(expected_rt, expected_rt + 1, color=\"blue\", alpha=1, label=\"Expected Rt\")\n    if weights is not None:\n        plt.plot(weights, linestyle=\"--\", label=\"Gaussian weight\")\n    plt.ylabel(\"Intensity\")\n    plt.xlabel(\"Scan time [s]\")\n    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n    if not legend:\n        ax.get_legend().remove()\n    return plt.gcf()\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.plotly_tools.get_palette_colors","title":"<code>get_palette_colors(palette_name, num_colors)</code>","text":"<p>Get a list of colors from a specific colorlover palette.</p> <p>Parameters:</p> Name Type Description Default <code>palette_name</code> <code>str</code> <p>Name of the color palette.</p> required <code>num_colors</code> <code>int</code> <p>Number of colors to extract.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of color strings in the requested palette.</p> Source code in <code>src/ms_mint/plotly_tools.py</code> <pre><code>def get_palette_colors(palette_name: str, num_colors: int) -&gt; List[str]:\n    \"\"\"Get a list of colors from a specific colorlover palette.\n\n    Args:\n        palette_name: Name of the color palette.\n        num_colors: Number of colors to extract.\n\n    Returns:\n        List of color strings in the requested palette.\n    \"\"\"\n    # Categories in the colorlover package\n    categories = [\"qual\", \"seq\", \"div\"]\n\n    num_colors = max(num_colors, 3)\n    # Check in which category our palette resides\n    for category in categories:\n        if palette_name in cl.scales[f\"{num_colors}\"][category]:\n            return cl.scales[f\"{num_colors}\"][category][palette_name]\n\n    # If palette not found in any category, return a default one\n    return cl.scales[f\"{num_colors}\"][\"qual\"][\"Paired\"]\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.plotly_tools.plotly_heatmap","title":"<code>plotly_heatmap(df, normed_by_cols=False, transposed=False, clustered=False, add_dendrogram=False, name='', x_tick_colors=None, height=None, width=None, correlation=False, call_show=False, verbose=False)</code>","text":"<p>Create an interactive heatmap from a dense-formatted dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input data in DataFrame format.</p> required <code>normed_by_cols</code> <code>bool</code> <p>Whether to normalize column vectors.</p> <code>False</code> <code>transposed</code> <code>bool</code> <p>Whether to transpose the generated image.</p> <code>False</code> <code>clustered</code> <code>bool</code> <p>Whether to apply hierarchical clustering on rows.</p> <code>False</code> <code>add_dendrogram</code> <code>bool</code> <p>Whether to show a dendrogram (only when clustered=True).</p> <code>False</code> <code>name</code> <code>str</code> <p>Name to use in figure title.</p> <code>''</code> <code>x_tick_colors</code> <code>Optional[str]</code> <p>Color of x-ticks.</p> <code>None</code> <code>height</code> <code>Optional[int]</code> <p>Image height in pixels.</p> <code>None</code> <code>width</code> <code>Optional[int]</code> <p>Image width in pixels.</p> <code>None</code> <code>correlation</code> <code>bool</code> <p>Whether to convert the table to a correlation matrix.</p> <code>False</code> <code>call_show</code> <code>bool</code> <p>Whether to display the figure immediately.</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>Whether to print additional information.</p> <code>False</code> <p>Returns:</p> Type Description <code>Optional[Figure]</code> <p>A Plotly Figure object, or None if call_show is True.</p> Source code in <code>src/ms_mint/plotly_tools.py</code> <pre><code>def plotly_heatmap(\n    df: pd.DataFrame,\n    normed_by_cols: bool = False,\n    transposed: bool = False,\n    clustered: bool = False,\n    add_dendrogram: bool = False,\n    name: str = \"\",\n    x_tick_colors: Optional[str] = None,\n    height: Optional[int] = None,\n    width: Optional[int] = None,\n    correlation: bool = False,\n    call_show: bool = False,\n    verbose: bool = False,\n) -&gt; Optional[PlotlyFigure]:\n    \"\"\"Create an interactive heatmap from a dense-formatted dataframe.\n\n    Args:\n        df: Input data in DataFrame format.\n        normed_by_cols: Whether to normalize column vectors.\n        transposed: Whether to transpose the generated image.\n        clustered: Whether to apply hierarchical clustering on rows.\n        add_dendrogram: Whether to show a dendrogram (only when clustered=True).\n        name: Name to use in figure title.\n        x_tick_colors: Color of x-ticks.\n        height: Image height in pixels.\n        width: Image width in pixels.\n        correlation: Whether to convert the table to a correlation matrix.\n        call_show: Whether to display the figure immediately.\n        verbose: Whether to print additional information.\n\n    Returns:\n        A Plotly Figure object, or None if call_show is True.\n    \"\"\"\n    max_is_not_zero = df.max(axis=1) != 0\n    non_zero_labels = max_is_not_zero[max_is_not_zero].index\n    df = df.loc[non_zero_labels]\n\n    colorscale = \"Bluered\"\n    plot_attributes = []\n\n    if normed_by_cols:\n        df = df.divide(df.max()).fillna(0)\n        plot_attributes.append(\"normalized\")\n\n    if transposed:\n        df = df.T\n\n    if correlation:\n        plot_type = \"Correlation\"\n        df = df.corr()\n        colorscale = [\n            [0.0, \"rgb(165,0,38)\"],\n            [0.1111111111111111, \"rgb(215,48,39)\"],\n            [0.2222222222222222, \"rgb(244,109,67)\"],\n            [0.3333333333333333, \"rgb(253,174,97)\"],\n            [0.4444444444444444, \"rgb(254,224,144)\"],\n            [0.5555555555555556, \"rgb(224,243,248)\"],\n            [0.6666666666666666, \"rgb(171,217,233)\"],\n            [0.7777777777777778, \"rgb(116,173,209)\"],\n            [0.8888888888888888, \"rgb(69,117,180)\"],\n            [1.0, \"rgb(49,54,149)\"],\n        ]\n    else:\n        plot_type = \"Heatmap\"\n\n    if clustered:\n        dendro_side = ff.create_dendrogram(\n            df,\n            orientation=\"right\",\n            labels=df.index.to_list(),\n            color_threshold=0,\n            colorscale=[\"black\"] * 8,\n        )\n        dendro_leaves = dendro_side[\"layout\"][\"yaxis\"][\"ticktext\"]\n        df = df.loc[dendro_leaves, :]\n        if correlation:\n            df = df[df.index]\n\n    x = df.columns\n    if clustered:\n        y = dendro_leaves\n    else:\n        y = df.index.to_list()\n    z = df.values\n\n    heatmap = go.Heatmap(x=x, y=y, z=z, colorscale=colorscale)\n\n    if name == \"\":\n        title = \"\"\n    else:\n        title = f\"{plot_type} of {','.join(plot_attributes)} {name}\"\n\n    # Figure without side-dendrogram\n    if (not add_dendrogram) or (not clustered):\n        fig = go.Figure(heatmap)\n        fig.update_layout(\n            {\"title_x\": 0.5},\n            title={\"text\": title},\n            yaxis={\"title\": \"\", \"tickmode\": \"array\", \"automargin\": True},\n        )\n\n        fig.update_layout({\"height\": height, \"width\": width, \"hovermode\": \"closest\"})\n\n    else:  # Figure with side-dendrogram\n        fig = go.Figure()\n\n        for i in range(len(dendro_side[\"data\"])):\n            dendro_side[\"data\"][i][\"xaxis\"] = \"x2\"\n\n        for data in dendro_side[\"data\"]:\n            fig.add_trace(data)\n\n        y_labels = heatmap[\"y\"]\n        heatmap[\"y\"] = dendro_side[\"layout\"][\"yaxis\"][\"tickvals\"]\n\n        fig.add_trace(heatmap)\n\n        fig.update_layout(\n            {\n                \"height\": height,\n                \"width\": width,\n                \"showlegend\": False,\n                \"hovermode\": \"closest\",\n                \"paper_bgcolor\": \"white\",\n                \"plot_bgcolor\": \"white\",\n                \"title_x\": 0.5,\n            },\n            title={\"text\": title},\n            # X-axis of main figure\n            xaxis={\n                \"domain\": [0.11, 1],\n                \"mirror\": False,\n                \"showgrid\": False,\n                \"showline\": False,\n                \"zeroline\": False,\n                \"showticklabels\": True,\n                \"ticks\": \"\",\n            },\n            # X-axis of side-dendrogram\n            xaxis2={\n                \"domain\": [0, 0.1],\n                \"mirror\": False,\n                \"showgrid\": True,\n                \"showline\": False,\n                \"zeroline\": False,\n                \"showticklabels\": False,\n                \"ticks\": \"\",\n            },\n            # Y-axis of main figure\n            yaxis={\n                \"domain\": [0, 1],\n                \"mirror\": False,\n                \"showgrid\": False,\n                \"showline\": False,\n                \"zeroline\": False,\n                \"showticklabels\": False,\n            },\n        )\n\n        fig[\"layout\"][\"yaxis\"][\"ticktext\"] = np.asarray(y_labels)\n        fig[\"layout\"][\"yaxis\"][\"tickvals\"] = np.asarray(dendro_side[\"layout\"][\"yaxis\"][\"tickvals\"])\n\n    fig.update_layout(\n        autosize=True,\n        hovermode=\"closest\",\n    )\n\n    fig.update_yaxes(automargin=True)\n    fig.update_xaxes(automargin=True)\n\n    if call_show:\n        fig.show(config={\"displaylogo\": False})\n        return None\n    else:\n        return fig\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.plotly_tools.plotly_peak_shapes","title":"<code>plotly_peak_shapes(mint_results, mint_metadata=None, color='ms_file_label', fns=None, col_wrap=1, peak_labels=None, legend=True, verbose=False, legend_orientation='v', call_show=False, palette='Plasma')</code>","text":"<p>Plot peak shapes from mint results as interactive Plotly figure.</p> <p>Parameters:</p> Name Type Description Default <code>mint_results</code> <code>DataFrame</code> <p>DataFrame in Mint results format.</p> required <code>mint_metadata</code> <code>Optional[DataFrame]</code> <p>DataFrame in Mint metadata format.</p> <code>None</code> <code>color</code> <code>str</code> <p>Column name determining color-coding of plots.</p> <code>'ms_file_label'</code> <code>fns</code> <code>Optional[List[str]]</code> <p>Filenames to include. If None, all files are used.</p> <code>None</code> <code>col_wrap</code> <code>int</code> <p>Maximum number of subplot columns.</p> <code>1</code> <code>peak_labels</code> <code>Optional[Union[str, List[str]]]</code> <p>Peak-labels to include. If None, all peaks are used.</p> <code>None</code> <code>legend</code> <code>bool</code> <p>Whether to display legend.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>If True, prints additional details.</p> <code>False</code> <code>legend_orientation</code> <code>str</code> <p>Legend orientation ('v' for vertical, 'h' for horizontal).</p> <code>'v'</code> <code>call_show</code> <code>bool</code> <p>If True, displays the plot immediately.</p> <code>False</code> <code>palette</code> <code>str</code> <p>Color palette to use.</p> <code>'Plasma'</code> <p>Returns:</p> Type Description <code>Optional[Figure]</code> <p>A Plotly Figure object, or None if call_show is True.</p> Source code in <code>src/ms_mint/plotly_tools.py</code> <pre><code>def plotly_peak_shapes(\n    mint_results: pd.DataFrame,\n    mint_metadata: Optional[pd.DataFrame] = None,\n    color: str = \"ms_file_label\",\n    fns: Optional[List[str]] = None,\n    col_wrap: int = 1,\n    peak_labels: Optional[Union[str, List[str]]] = None,\n    legend: bool = True,\n    verbose: bool = False,\n    legend_orientation: str = \"v\",\n    call_show: bool = False,\n    palette: str = \"Plasma\",\n) -&gt; Optional[PlotlyFigure]:\n    \"\"\"Plot peak shapes from mint results as interactive Plotly figure.\n\n    Args:\n        mint_results: DataFrame in Mint results format.\n        mint_metadata: DataFrame in Mint metadata format.\n        color: Column name determining color-coding of plots.\n        fns: Filenames to include. If None, all files are used.\n        col_wrap: Maximum number of subplot columns.\n        peak_labels: Peak-labels to include. If None, all peaks are used.\n        legend: Whether to display legend.\n        verbose: If True, prints additional details.\n        legend_orientation: Legend orientation ('v' for vertical, 'h' for horizontal).\n        call_show: If True, displays the plot immediately.\n        palette: Color palette to use.\n\n    Returns:\n        A Plotly Figure object, or None if call_show is True.\n    \"\"\"\n    mint_results = mint_results.copy()\n\n    # Merge with metadata if provided\n    if mint_metadata is not None:\n        mint_results = pd.merge(\n            mint_results, mint_metadata, left_on=\"ms_file_label\", right_index=True\n        )\n\n    # Filter by filenames\n    if fns is not None:\n        fns = [fn_to_label(fn) for fn in fns]\n        mint_results = mint_results[mint_results.ms_file_label.isin(fns)]\n    else:\n        fns = mint_results.ms_file_label.unique()\n\n    # Filter by peak_labels\n    if peak_labels is not None:\n        if isinstance(peak_labels, str):\n            peak_labels = [peak_labels]\n        mint_results = mint_results[mint_results.peak_label.isin(peak_labels)]\n    else:\n        peak_labels = mint_results.peak_label.unique()\n\n    # Handle colors based on metadata or fall back to default behavior\n    colors = None\n    if color:\n        unique_hues = mint_results[color].unique()\n\n        colors = get_palette_colors(palette, len(unique_hues))\n\n        color_mapping = dict(zip(unique_hues, colors))\n\n        if color == \"ms_file_label\":\n            hue_column = [color_mapping[fn] for fn in fns]\n        else:\n            # Existing logic remains the same for the else part\n            hue_column = (\n                mint_results.drop_duplicates(\"ms_file_label\")\n                .set_index(\"ms_file_label\")[color]\n                .map(color_mapping)\n                .reindex(fns)\n                .tolist()\n            )\n\n    else:\n        hue_column = colors\n\n    # Rest of the plotting process\n    res = mint_results[mint_results.peak_max &gt; 0]\n    labels = mint_results.peak_label.unique()\n    res = res.set_index([\"peak_label\", \"ms_file_label\"]).sort_index()\n\n    # Calculate necessary number of rows\n    n_rows = max(1, len(labels) // col_wrap)\n    if n_rows * col_wrap &lt; len(labels):\n        n_rows += 1\n\n    fig = make_subplots(rows=max(1, n_rows), cols=max(1, col_wrap), subplot_titles=peak_labels)\n\n    for label_i, label in enumerate(peak_labels):\n        for file_i, fn in enumerate(fns):\n            try:\n                x, y = res.loc[(label, fn), [\"peak_shape_rt\", \"peak_shape_int\"]]\n            except KeyError as e:\n                logging.warning(e)\n                continue\n\n            if not isinstance(x, Iterable):\n                continue\n            if isinstance(x, str):\n                x = x.split(\",\")\n                y = y.split(\",\")\n\n            ndx_r = (label_i // col_wrap) + 1\n            ndx_c = label_i % col_wrap + 1\n\n            trace_color = hue_column[file_i]\n\n            fig.add_trace(\n                go.Scattergl(\n                    x=x,\n                    y=y,\n                    name=P(fn).name,\n                    mode=\"markers\",\n                    legendgroup=file_i,\n                    showlegend=(label_i == 0),\n                    marker_color=trace_color,\n                    text=fn,\n                    fill=\"tozeroy\",\n                    marker=dict(size=3),\n                ),\n                row=ndx_r,\n                col=ndx_c,\n            )\n\n            fig.update_xaxes(title_text=\"Scan time [s]\", row=ndx_r, col=ndx_c)\n            fig.update_yaxes(title_text=\"Intensity\", row=ndx_r, col=ndx_c)\n\n    # Layout updates\n    if legend:\n        fig.update_layout(legend_orientation=legend_orientation)\n\n    fig.update_layout(showlegend=legend)\n    fig.update_layout(height=400 * n_rows, title_text=\"Peak Shapes\")\n\n    if call_show:\n        fig.show(config={\"displaylogo\": False})\n        return None\n    else:\n        return fig\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.plotly_tools.set_template","title":"<code>set_template()</code>","text":"<p>Set a default template for plotly figures.</p> <p>Creates a \"draft\" template with smaller font size and sets it as the default template for all plotly figures.</p> Source code in <code>src/ms_mint/plotly_tools.py</code> <pre><code>def set_template() -&gt; None:\n    \"\"\"Set a default template for plotly figures.\n\n    Creates a \"draft\" template with smaller font size and sets it as the default\n    template for all plotly figures.\n    \"\"\"\n    pio.templates[\"draft\"] = go.layout.Template(\n        layout=dict(font={\"size\": 10}),\n    )\n\n    pio.templates.default = \"draft\"\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.pca.PCA_Plotter","title":"<code>PCA_Plotter</code>","text":"<p>Class for visualizing PCA results from MS-MINT analysis.</p> <p>This class provides methods to create various plots of PCA results, including cumulative variance plots, pairplots, and loading plots.</p> <p>Attributes:</p> Name Type Description <code>pca</code> <p>The PrincipalComponentsAnalyser instance containing results to visualize.</p> Source code in <code>src/ms_mint/pca.py</code> <pre><code>class PCA_Plotter:\n    \"\"\"Class for visualizing PCA results from MS-MINT analysis.\n\n    This class provides methods to create various plots of PCA results,\n    including cumulative variance plots, pairplots, and loading plots.\n\n    Attributes:\n        pca: The PrincipalComponentsAnalyser instance containing results to visualize.\n    \"\"\"\n\n    def __init__(self, pca: PrincipalComponentsAnalyser) -&gt; None:\n        \"\"\"Initialize a PCA_Plotter instance.\n\n        Args:\n            pca: PrincipalComponentsAnalyser instance with results to visualize.\n        \"\"\"\n        self.pca = pca\n\n    def cumulative_variance(\n        self, interactive: bool = False, **kwargs\n    ) -&gt; Union[Figure, PlotlyFigure]:\n        \"\"\"Plot the cumulative explained variance of principal components.\n\n        Args:\n            interactive: If True, returns a Plotly interactive figure.\n                If False, returns a static Matplotlib figure.\n            **kwargs: Additional keyword arguments passed to the underlying plotting functions.\n\n        Returns:\n            Either a Matplotlib figure or a Plotly figure depending on the interactive parameter.\n        \"\"\"\n        if interactive:\n            return self.cumulative_variance_px(**kwargs)\n        else:\n            return self.cumulative_variance_sns(**kwargs)\n\n    def cumulative_variance_px(self, **kwargs) -&gt; PlotlyFigure:\n        \"\"\"Create an interactive Plotly plot of cumulative explained variance.\n\n        Args:\n            **kwargs: Additional keyword arguments passed to px.bar.\n\n        Returns:\n            Plotly figure showing cumulative explained variance.\n        \"\"\"\n        n_components = self.pca.results[\"n_components\"]\n        cum_expl_var = self.pca.results[\"cum_expl_var\"]\n        df = pd.DataFrame(\n            {\n                \"Principal Component\": np.arange(n_components) + 1,\n                \"Explained variance [%]\": cum_expl_var,\n            }\n        )\n        fig = px.bar(\n            df,\n            x=\"Principal Component\",\n            y=\"Explained variance [%]\",\n            title=\"Cumulative explained variance\",\n            labels={\n                \"Principal Component\": \"Principal Component\",\n                \"Explained variance [%]\": \"Explained variance [%]\",\n            },\n            **kwargs,\n        )\n        fig.update_layout(autosize=True, showlegend=False)\n        return fig\n\n    def cumulative_variance_sns(self, **kwargs) -&gt; Figure:\n        \"\"\"Create a static Matplotlib plot of cumulative explained variance.\n\n        Args:\n            **kwargs: Additional keyword arguments for figure customization.\n                'aspect': Width-to-height ratio of the figure (default: 1).\n                'height': Height of the figure in inches (default: 5).\n\n        Returns:\n            Matplotlib figure showing cumulative explained variance.\n        \"\"\"\n        # Set default values for aspect and height\n        aspect = kwargs.get(\"aspect\", 1)\n        height = kwargs.get(\"height\", 5)\n\n        n_components = self.pca.results[\"n_components\"]\n        cum_expl_var = self.pca.results[\"cum_expl_var\"]\n\n        # Calculate width based on aspect ratio and number of components\n        width = height * aspect\n\n        fig, ax = plt.subplots(figsize=(width, height))\n        ax.bar(\n            np.arange(n_components) + 1,\n            cum_expl_var,\n            facecolor=\"grey\",\n            edgecolor=\"none\",\n        )\n        ax.set_xlabel(\"Principal Component\")\n        ax.set_ylabel(\"Explained variance [%]\")\n        ax.set_title(\"Cumulative explained variance\")\n        ax.spines[\"top\"].set_visible(False)\n        ax.spines[\"right\"].set_visible(False)\n        ax.set_xticks(range(1, len(cum_expl_var) + 1))\n        return fig\n\n    def _prepare_data(\n        self, n_components: int = 3, hue: Optional[Union[str, List[str]]] = None\n    ) -&gt; pd.DataFrame:\n        \"\"\"Prepare data for pairplot visualization.\n\n        Args:\n            n_components: Number of principal components to include.\n            hue: Labels used for coloring points. If a string, data is taken from\n                the mint.meta DataFrame. If a list, values are used directly.\n\n        Returns:\n            DataFrame containing the prepared data for visualization.\n        \"\"\"\n        df = self.pca.results[\"df_projected\"].copy()\n        cols = df.columns.to_list()[:n_components]\n        df = df[cols]\n\n        df = pd.merge(\n            df, self.pca.mint.meta.dropna(axis=1, how=\"all\"), left_index=True, right_index=True\n        )\n\n        if hue and (not isinstance(hue, str)):\n            df[\"Label\"] = hue\n            df[\"Label\"] = df[\"Label\"].astype(str)\n\n        return df\n\n    def pairplot(\n        self,\n        n_components: int = 3,\n        hue: Optional[Union[str, List[str]]] = None,\n        fig_kws: Optional[Dict[str, Any]] = None,\n        interactive: bool = False,\n        **kwargs,\n    ) -&gt; Union[sns.axisgrid.PairGrid, PlotlyFigure]:\n        \"\"\"Create a pairplot of principal components.\n\n        Args:\n            n_components: Number of principal components to include in the plot.\n            hue: Labels used for coloring points. If a string, data is taken from\n                the mint.meta DataFrame. If a list, values are used directly.\n            fig_kws: Keyword arguments passed to plt.figure if using seaborn.\n            interactive: If True, returns a Plotly interactive figure.\n                If False, returns a static Seaborn PairGrid.\n            **kwargs: Additional keyword arguments passed to the underlying plotting functions.\n\n        Returns:\n            Either a Seaborn PairGrid or a Plotly figure depending on the interactive parameter.\n        \"\"\"\n        df = self._prepare_data(n_components=n_components, hue=hue)\n\n        if isinstance(hue, list):\n            hue = \"label\"\n\n        if interactive:\n            return self.pairplot_plotly(df, color_col=hue, **kwargs)\n        else:\n            return self.pairplot_sns(df, fig_kws=fig_kws, hue=hue, **kwargs)\n\n    def pairplot_sns(\n        self, df: pd.DataFrame, fig_kws: Optional[Dict[str, Any]] = None, **kwargs\n    ) -&gt; sns.axisgrid.PairGrid:\n        \"\"\"Create a static Seaborn pairplot of principal components.\n\n        Args:\n            df: DataFrame containing the data to visualize.\n            fig_kws: Keyword arguments passed to plt.figure.\n            **kwargs: Additional keyword arguments passed to sns.pairplot.\n\n        Returns:\n            Seaborn PairGrid object.\n        \"\"\"\n        if fig_kws is None:\n            fig_kws = {}\n        plt.figure(**fig_kws)\n        g = sns.pairplot(df, **kwargs)\n        return g\n\n    def pairplot_plotly(\n        self, df: pd.DataFrame, color_col: Optional[str] = None, **kwargs\n    ) -&gt; PlotlyFigure:\n        \"\"\"Create an interactive Plotly pairplot of principal components.\n\n        Args:\n            df: DataFrame containing the data to visualize.\n            color_col: Column name to use for coloring points.\n            **kwargs: Additional keyword arguments passed to ff.create_scatterplotmatrix.\n\n        Returns:\n            Plotly figure object.\n        \"\"\"\n        columns = df.filter(regex=f\"PC|^{color_col}$\").columns\n        fig = ff.create_scatterplotmatrix(\n            df[columns], index=color_col, hovertext=df.index, **kwargs\n        )\n        # set the legendgroup equal to the marker color\n        for t in fig.data:\n            t.legendgroup = t.marker.color\n        return fig\n\n    def loadings(\n        self, interactive: bool = False, **kwargs\n    ) -&gt; Union[sns.axisgrid.FacetGrid, PlotlyFigure]:\n        \"\"\"Plot PCA loadings (feature contributions to principal components).\n\n        Args:\n            interactive: If True, returns a Plotly interactive figure.\n                If False, returns a static Seaborn FacetGrid.\n            **kwargs: Additional keyword arguments passed to the underlying plotting functions.\n\n        Returns:\n            Either a Seaborn FacetGrid or a Plotly figure depending on the interactive parameter.\n        \"\"\"\n        if interactive:\n            return self.loadings_plotly(**kwargs)\n        else:\n            return self.loadings_sns(**kwargs)\n\n    def loadings_sns(self, **kwargs) -&gt; sns.axisgrid.FacetGrid:\n        \"\"\"Create a static Seaborn plot of PCA loadings.\n\n        Args:\n            **kwargs: Additional keyword arguments passed to sns.catplot.\n                If 'row' is not specified, it defaults to 'PC'.\n\n        Returns:\n            Seaborn FacetGrid object.\n        \"\"\"\n        if \"row\" not in kwargs:\n            kwargs[\"row\"] = \"PC\"\n        g = sns.catplot(\n            data=self.pca.results[\"feature_contributions\"],\n            x=\"peak_label\",\n            y=\"Coefficient\",\n            kind=\"bar\",\n            **kwargs,\n        )\n        plt.tight_layout()\n        return g\n\n    def loadings_plotly(self, **kwargs) -&gt; PlotlyFigure:\n        \"\"\"Create an interactive Plotly plot of PCA loadings.\n\n        Args:\n            **kwargs: Additional keyword arguments passed to px.bar.\n                If 'facet_row' is not specified, it defaults to 'PC'.\n\n        Returns:\n            Plotly figure object.\n        \"\"\"\n        if \"facet_row\" not in kwargs:\n            kwargs[\"facet_row\"] = \"PC\"\n        fig = px.bar(\n            self.pca.results[\"feature_contributions\"],\n            x=\"peak_label\",\n            y=\"Coefficient\",\n            barmode=\"group\",\n            **kwargs,\n        )\n        return fig\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.pca.PCA_Plotter.__init__","title":"<code>__init__(pca)</code>","text":"<p>Initialize a PCA_Plotter instance.</p> <p>Parameters:</p> Name Type Description Default <code>pca</code> <code>PrincipalComponentsAnalyser</code> <p>PrincipalComponentsAnalyser instance with results to visualize.</p> required Source code in <code>src/ms_mint/pca.py</code> <pre><code>def __init__(self, pca: PrincipalComponentsAnalyser) -&gt; None:\n    \"\"\"Initialize a PCA_Plotter instance.\n\n    Args:\n        pca: PrincipalComponentsAnalyser instance with results to visualize.\n    \"\"\"\n    self.pca = pca\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.pca.PCA_Plotter.cumulative_variance","title":"<code>cumulative_variance(interactive=False, **kwargs)</code>","text":"<p>Plot the cumulative explained variance of principal components.</p> <p>Parameters:</p> Name Type Description Default <code>interactive</code> <code>bool</code> <p>If True, returns a Plotly interactive figure. If False, returns a static Matplotlib figure.</p> <code>False</code> <code>**kwargs</code> <p>Additional keyword arguments passed to the underlying plotting functions.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[Figure, Figure]</code> <p>Either a Matplotlib figure or a Plotly figure depending on the interactive parameter.</p> Source code in <code>src/ms_mint/pca.py</code> <pre><code>def cumulative_variance(\n    self, interactive: bool = False, **kwargs\n) -&gt; Union[Figure, PlotlyFigure]:\n    \"\"\"Plot the cumulative explained variance of principal components.\n\n    Args:\n        interactive: If True, returns a Plotly interactive figure.\n            If False, returns a static Matplotlib figure.\n        **kwargs: Additional keyword arguments passed to the underlying plotting functions.\n\n    Returns:\n        Either a Matplotlib figure or a Plotly figure depending on the interactive parameter.\n    \"\"\"\n    if interactive:\n        return self.cumulative_variance_px(**kwargs)\n    else:\n        return self.cumulative_variance_sns(**kwargs)\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.pca.PCA_Plotter.cumulative_variance_px","title":"<code>cumulative_variance_px(**kwargs)</code>","text":"<p>Create an interactive Plotly plot of cumulative explained variance.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments passed to px.bar.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Plotly figure showing cumulative explained variance.</p> Source code in <code>src/ms_mint/pca.py</code> <pre><code>def cumulative_variance_px(self, **kwargs) -&gt; PlotlyFigure:\n    \"\"\"Create an interactive Plotly plot of cumulative explained variance.\n\n    Args:\n        **kwargs: Additional keyword arguments passed to px.bar.\n\n    Returns:\n        Plotly figure showing cumulative explained variance.\n    \"\"\"\n    n_components = self.pca.results[\"n_components\"]\n    cum_expl_var = self.pca.results[\"cum_expl_var\"]\n    df = pd.DataFrame(\n        {\n            \"Principal Component\": np.arange(n_components) + 1,\n            \"Explained variance [%]\": cum_expl_var,\n        }\n    )\n    fig = px.bar(\n        df,\n        x=\"Principal Component\",\n        y=\"Explained variance [%]\",\n        title=\"Cumulative explained variance\",\n        labels={\n            \"Principal Component\": \"Principal Component\",\n            \"Explained variance [%]\": \"Explained variance [%]\",\n        },\n        **kwargs,\n    )\n    fig.update_layout(autosize=True, showlegend=False)\n    return fig\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.pca.PCA_Plotter.cumulative_variance_sns","title":"<code>cumulative_variance_sns(**kwargs)</code>","text":"<p>Create a static Matplotlib plot of cumulative explained variance.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments for figure customization. 'aspect': Width-to-height ratio of the figure (default: 1). 'height': Height of the figure in inches (default: 5).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Matplotlib figure showing cumulative explained variance.</p> Source code in <code>src/ms_mint/pca.py</code> <pre><code>def cumulative_variance_sns(self, **kwargs) -&gt; Figure:\n    \"\"\"Create a static Matplotlib plot of cumulative explained variance.\n\n    Args:\n        **kwargs: Additional keyword arguments for figure customization.\n            'aspect': Width-to-height ratio of the figure (default: 1).\n            'height': Height of the figure in inches (default: 5).\n\n    Returns:\n        Matplotlib figure showing cumulative explained variance.\n    \"\"\"\n    # Set default values for aspect and height\n    aspect = kwargs.get(\"aspect\", 1)\n    height = kwargs.get(\"height\", 5)\n\n    n_components = self.pca.results[\"n_components\"]\n    cum_expl_var = self.pca.results[\"cum_expl_var\"]\n\n    # Calculate width based on aspect ratio and number of components\n    width = height * aspect\n\n    fig, ax = plt.subplots(figsize=(width, height))\n    ax.bar(\n        np.arange(n_components) + 1,\n        cum_expl_var,\n        facecolor=\"grey\",\n        edgecolor=\"none\",\n    )\n    ax.set_xlabel(\"Principal Component\")\n    ax.set_ylabel(\"Explained variance [%]\")\n    ax.set_title(\"Cumulative explained variance\")\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"right\"].set_visible(False)\n    ax.set_xticks(range(1, len(cum_expl_var) + 1))\n    return fig\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.pca.PCA_Plotter.loadings","title":"<code>loadings(interactive=False, **kwargs)</code>","text":"<p>Plot PCA loadings (feature contributions to principal components).</p> <p>Parameters:</p> Name Type Description Default <code>interactive</code> <code>bool</code> <p>If True, returns a Plotly interactive figure. If False, returns a static Seaborn FacetGrid.</p> <code>False</code> <code>**kwargs</code> <p>Additional keyword arguments passed to the underlying plotting functions.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[FacetGrid, Figure]</code> <p>Either a Seaborn FacetGrid or a Plotly figure depending on the interactive parameter.</p> Source code in <code>src/ms_mint/pca.py</code> <pre><code>def loadings(\n    self, interactive: bool = False, **kwargs\n) -&gt; Union[sns.axisgrid.FacetGrid, PlotlyFigure]:\n    \"\"\"Plot PCA loadings (feature contributions to principal components).\n\n    Args:\n        interactive: If True, returns a Plotly interactive figure.\n            If False, returns a static Seaborn FacetGrid.\n        **kwargs: Additional keyword arguments passed to the underlying plotting functions.\n\n    Returns:\n        Either a Seaborn FacetGrid or a Plotly figure depending on the interactive parameter.\n    \"\"\"\n    if interactive:\n        return self.loadings_plotly(**kwargs)\n    else:\n        return self.loadings_sns(**kwargs)\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.pca.PCA_Plotter.loadings_plotly","title":"<code>loadings_plotly(**kwargs)</code>","text":"<p>Create an interactive Plotly plot of PCA loadings.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments passed to px.bar. If 'facet_row' is not specified, it defaults to 'PC'.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Plotly figure object.</p> Source code in <code>src/ms_mint/pca.py</code> <pre><code>def loadings_plotly(self, **kwargs) -&gt; PlotlyFigure:\n    \"\"\"Create an interactive Plotly plot of PCA loadings.\n\n    Args:\n        **kwargs: Additional keyword arguments passed to px.bar.\n            If 'facet_row' is not specified, it defaults to 'PC'.\n\n    Returns:\n        Plotly figure object.\n    \"\"\"\n    if \"facet_row\" not in kwargs:\n        kwargs[\"facet_row\"] = \"PC\"\n    fig = px.bar(\n        self.pca.results[\"feature_contributions\"],\n        x=\"peak_label\",\n        y=\"Coefficient\",\n        barmode=\"group\",\n        **kwargs,\n    )\n    return fig\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.pca.PCA_Plotter.loadings_sns","title":"<code>loadings_sns(**kwargs)</code>","text":"<p>Create a static Seaborn plot of PCA loadings.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments passed to sns.catplot. If 'row' is not specified, it defaults to 'PC'.</p> <code>{}</code> <p>Returns:</p> Type Description <code>FacetGrid</code> <p>Seaborn FacetGrid object.</p> Source code in <code>src/ms_mint/pca.py</code> <pre><code>def loadings_sns(self, **kwargs) -&gt; sns.axisgrid.FacetGrid:\n    \"\"\"Create a static Seaborn plot of PCA loadings.\n\n    Args:\n        **kwargs: Additional keyword arguments passed to sns.catplot.\n            If 'row' is not specified, it defaults to 'PC'.\n\n    Returns:\n        Seaborn FacetGrid object.\n    \"\"\"\n    if \"row\" not in kwargs:\n        kwargs[\"row\"] = \"PC\"\n    g = sns.catplot(\n        data=self.pca.results[\"feature_contributions\"],\n        x=\"peak_label\",\n        y=\"Coefficient\",\n        kind=\"bar\",\n        **kwargs,\n    )\n    plt.tight_layout()\n    return g\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.pca.PCA_Plotter.pairplot","title":"<code>pairplot(n_components=3, hue=None, fig_kws=None, interactive=False, **kwargs)</code>","text":"<p>Create a pairplot of principal components.</p> <p>Parameters:</p> Name Type Description Default <code>n_components</code> <code>int</code> <p>Number of principal components to include in the plot.</p> <code>3</code> <code>hue</code> <code>Optional[Union[str, List[str]]]</code> <p>Labels used for coloring points. If a string, data is taken from the mint.meta DataFrame. If a list, values are used directly.</p> <code>None</code> <code>fig_kws</code> <code>Optional[Dict[str, Any]]</code> <p>Keyword arguments passed to plt.figure if using seaborn.</p> <code>None</code> <code>interactive</code> <code>bool</code> <p>If True, returns a Plotly interactive figure. If False, returns a static Seaborn PairGrid.</p> <code>False</code> <code>**kwargs</code> <p>Additional keyword arguments passed to the underlying plotting functions.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[PairGrid, Figure]</code> <p>Either a Seaborn PairGrid or a Plotly figure depending on the interactive parameter.</p> Source code in <code>src/ms_mint/pca.py</code> <pre><code>def pairplot(\n    self,\n    n_components: int = 3,\n    hue: Optional[Union[str, List[str]]] = None,\n    fig_kws: Optional[Dict[str, Any]] = None,\n    interactive: bool = False,\n    **kwargs,\n) -&gt; Union[sns.axisgrid.PairGrid, PlotlyFigure]:\n    \"\"\"Create a pairplot of principal components.\n\n    Args:\n        n_components: Number of principal components to include in the plot.\n        hue: Labels used for coloring points. If a string, data is taken from\n            the mint.meta DataFrame. If a list, values are used directly.\n        fig_kws: Keyword arguments passed to plt.figure if using seaborn.\n        interactive: If True, returns a Plotly interactive figure.\n            If False, returns a static Seaborn PairGrid.\n        **kwargs: Additional keyword arguments passed to the underlying plotting functions.\n\n    Returns:\n        Either a Seaborn PairGrid or a Plotly figure depending on the interactive parameter.\n    \"\"\"\n    df = self._prepare_data(n_components=n_components, hue=hue)\n\n    if isinstance(hue, list):\n        hue = \"label\"\n\n    if interactive:\n        return self.pairplot_plotly(df, color_col=hue, **kwargs)\n    else:\n        return self.pairplot_sns(df, fig_kws=fig_kws, hue=hue, **kwargs)\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.pca.PCA_Plotter.pairplot_plotly","title":"<code>pairplot_plotly(df, color_col=None, **kwargs)</code>","text":"<p>Create an interactive Plotly pairplot of principal components.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing the data to visualize.</p> required <code>color_col</code> <code>Optional[str]</code> <p>Column name to use for coloring points.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to ff.create_scatterplotmatrix.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Plotly figure object.</p> Source code in <code>src/ms_mint/pca.py</code> <pre><code>def pairplot_plotly(\n    self, df: pd.DataFrame, color_col: Optional[str] = None, **kwargs\n) -&gt; PlotlyFigure:\n    \"\"\"Create an interactive Plotly pairplot of principal components.\n\n    Args:\n        df: DataFrame containing the data to visualize.\n        color_col: Column name to use for coloring points.\n        **kwargs: Additional keyword arguments passed to ff.create_scatterplotmatrix.\n\n    Returns:\n        Plotly figure object.\n    \"\"\"\n    columns = df.filter(regex=f\"PC|^{color_col}$\").columns\n    fig = ff.create_scatterplotmatrix(\n        df[columns], index=color_col, hovertext=df.index, **kwargs\n    )\n    # set the legendgroup equal to the marker color\n    for t in fig.data:\n        t.legendgroup = t.marker.color\n    return fig\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.pca.PCA_Plotter.pairplot_sns","title":"<code>pairplot_sns(df, fig_kws=None, **kwargs)</code>","text":"<p>Create a static Seaborn pairplot of principal components.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing the data to visualize.</p> required <code>fig_kws</code> <code>Optional[Dict[str, Any]]</code> <p>Keyword arguments passed to plt.figure.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to sns.pairplot.</p> <code>{}</code> <p>Returns:</p> Type Description <code>PairGrid</code> <p>Seaborn PairGrid object.</p> Source code in <code>src/ms_mint/pca.py</code> <pre><code>def pairplot_sns(\n    self, df: pd.DataFrame, fig_kws: Optional[Dict[str, Any]] = None, **kwargs\n) -&gt; sns.axisgrid.PairGrid:\n    \"\"\"Create a static Seaborn pairplot of principal components.\n\n    Args:\n        df: DataFrame containing the data to visualize.\n        fig_kws: Keyword arguments passed to plt.figure.\n        **kwargs: Additional keyword arguments passed to sns.pairplot.\n\n    Returns:\n        Seaborn PairGrid object.\n    \"\"\"\n    if fig_kws is None:\n        fig_kws = {}\n    plt.figure(**fig_kws)\n    g = sns.pairplot(df, **kwargs)\n    return g\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.pca.PrincipalComponentsAnalyser","title":"<code>PrincipalComponentsAnalyser</code>","text":"<p>Class for applying PCA to MS-MINT analysis results.</p> <p>This class provides functionality to perform Principal Component Analysis on MS-MINT metabolomics data and store the results for visualization.</p> <p>Attributes:</p> Name Type Description <code>mint</code> <p>The Mint instance containing the data to analyze.</p> <code>results</code> <code>Optional[Dict[str, Any]]</code> <p>Dictionary containing PCA results after running the analysis.</p> <code>plot</code> <p>PCA_Plotter instance for visualizing the PCA results.</p> Source code in <code>src/ms_mint/pca.py</code> <pre><code>class PrincipalComponentsAnalyser:\n    \"\"\"Class for applying PCA to MS-MINT analysis results.\n\n    This class provides functionality to perform Principal Component Analysis on\n    MS-MINT metabolomics data and store the results for visualization.\n\n    Attributes:\n        mint: The Mint instance containing the data to analyze.\n        results: Dictionary containing PCA results after running the analysis.\n        plot: PCA_Plotter instance for visualizing the PCA results.\n    \"\"\"\n\n    def __init__(self, mint: Optional[\"ms_mint.Mint.Mint\"] = None) -&gt; None:\n        \"\"\"Initialize a PrincipalComponentsAnalyser instance.\n\n        Args:\n            mint: Mint instance containing the data to analyze.\n        \"\"\"\n        self.mint = mint\n        self.results: Optional[Dict[str, Any]] = None\n        self.plot = PCA_Plotter(self)\n\n    def run(\n        self,\n        n_components: int = 3,\n        on: Optional[str] = None,\n        var_name: str = \"peak_max\",\n        fillna: Union[str, float] = \"median\",\n        apply: Optional[str] = None,\n        groupby: Optional[Union[str, List[str]]] = None,\n        scaler: str = \"standard\",\n    ) -&gt; None:\n        \"\"\"Run Principal Component Analysis on the current results.\n\n        Performs PCA on the data and stores results in self.results.\n\n        Args:\n            n_components: Number of PCA components to calculate.\n            on: Deprecated, use var_name instead.\n            var_name: Column name from results to use for PCA.\n            fillna: Method to fill missing values. One of \"median\", \"mean\", \"zero\",\n                or a numeric value.\n            apply: Transformation to apply to the data before PCA.\n            groupby: Column(s) to group by before analysis.\n            scaler: Method to scale the data. One of \"standard\", \"robust\", \"minmax\".\n\n        Raises:\n            DeprecationWarning: If the deprecated 'on' parameter is used.\n        \"\"\"\n        if on is not None:\n            warnings.warn(\"on is deprecated, use var_name instead\", DeprecationWarning)\n            var_name = on\n\n        df = self.mint.crosstab(var_name=var_name, apply=apply, scaler=scaler, groupby=groupby)\n\n        if fillna == \"median\":\n            fillna = df.median()\n        elif fillna == \"mean\":\n            fillna = df.mean()\n        elif fillna == \"zero\":\n            fillna = 0\n\n        df = df.fillna(fillna)\n\n        min_dim = min(df.shape)\n        n_components = min(n_components, min_dim)\n        pca = PCA(n_components)\n        X_projected = pca.fit_transform(df)\n        # Convert to dataframe\n        df_projected = pd.DataFrame(X_projected, index=df.index.get_level_values(0))\n        # Set columns to PC-1, PC-2, ...\n        df_projected.columns = [f\"PC-{int(i) + 1}\" for i in df_projected.columns]\n\n        # Calculate cumulative explained variance in percent\n        explained_variance = pca.explained_variance_ratio_ * 100\n        cum_expl_var = np.cumsum(explained_variance)\n\n        # Create feature contributions\n        a = np.zeros((n_components, n_components), int)\n        np.fill_diagonal(a, 1)\n        dfc = pd.DataFrame(pca.inverse_transform(a))\n        dfc.columns = df.columns\n        dfc.index = [f\"PC-{i + 1}\" for i in range(n_components)]\n        dfc.index.name = \"PC\"\n        # convert to long format\n        dfc = dfc.stack().reset_index().rename(columns={0: \"Coefficient\"})\n\n        self.results = {\n            \"df_projected\": df_projected,\n            \"cum_expl_var\": cum_expl_var,\n            \"n_components\": n_components,\n            \"type\": \"PCA\",\n            \"feature_contributions\": dfc,\n            \"class\": pca,\n        }\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.pca.PrincipalComponentsAnalyser.__init__","title":"<code>__init__(mint=None)</code>","text":"<p>Initialize a PrincipalComponentsAnalyser instance.</p> <p>Parameters:</p> Name Type Description Default <code>mint</code> <code>Optional['ms_mint.Mint.Mint']</code> <p>Mint instance containing the data to analyze.</p> <code>None</code> Source code in <code>src/ms_mint/pca.py</code> <pre><code>def __init__(self, mint: Optional[\"ms_mint.Mint.Mint\"] = None) -&gt; None:\n    \"\"\"Initialize a PrincipalComponentsAnalyser instance.\n\n    Args:\n        mint: Mint instance containing the data to analyze.\n    \"\"\"\n    self.mint = mint\n    self.results: Optional[Dict[str, Any]] = None\n    self.plot = PCA_Plotter(self)\n</code></pre>"},{"location":"api_reference/visualization/#ms_mint.pca.PrincipalComponentsAnalyser.run","title":"<code>run(n_components=3, on=None, var_name='peak_max', fillna='median', apply=None, groupby=None, scaler='standard')</code>","text":"<p>Run Principal Component Analysis on the current results.</p> <p>Performs PCA on the data and stores results in self.results.</p> <p>Parameters:</p> Name Type Description Default <code>n_components</code> <code>int</code> <p>Number of PCA components to calculate.</p> <code>3</code> <code>on</code> <code>Optional[str]</code> <p>Deprecated, use var_name instead.</p> <code>None</code> <code>var_name</code> <code>str</code> <p>Column name from results to use for PCA.</p> <code>'peak_max'</code> <code>fillna</code> <code>Union[str, float]</code> <p>Method to fill missing values. One of \"median\", \"mean\", \"zero\", or a numeric value.</p> <code>'median'</code> <code>apply</code> <code>Optional[str]</code> <p>Transformation to apply to the data before PCA.</p> <code>None</code> <code>groupby</code> <code>Optional[Union[str, List[str]]]</code> <p>Column(s) to group by before analysis.</p> <code>None</code> <code>scaler</code> <code>str</code> <p>Method to scale the data. One of \"standard\", \"robust\", \"minmax\".</p> <code>'standard'</code> <p>Raises:</p> Type Description <code>DeprecationWarning</code> <p>If the deprecated 'on' parameter is used.</p> Source code in <code>src/ms_mint/pca.py</code> <pre><code>def run(\n    self,\n    n_components: int = 3,\n    on: Optional[str] = None,\n    var_name: str = \"peak_max\",\n    fillna: Union[str, float] = \"median\",\n    apply: Optional[str] = None,\n    groupby: Optional[Union[str, List[str]]] = None,\n    scaler: str = \"standard\",\n) -&gt; None:\n    \"\"\"Run Principal Component Analysis on the current results.\n\n    Performs PCA on the data and stores results in self.results.\n\n    Args:\n        n_components: Number of PCA components to calculate.\n        on: Deprecated, use var_name instead.\n        var_name: Column name from results to use for PCA.\n        fillna: Method to fill missing values. One of \"median\", \"mean\", \"zero\",\n            or a numeric value.\n        apply: Transformation to apply to the data before PCA.\n        groupby: Column(s) to group by before analysis.\n        scaler: Method to scale the data. One of \"standard\", \"robust\", \"minmax\".\n\n    Raises:\n        DeprecationWarning: If the deprecated 'on' parameter is used.\n    \"\"\"\n    if on is not None:\n        warnings.warn(\"on is deprecated, use var_name instead\", DeprecationWarning)\n        var_name = on\n\n    df = self.mint.crosstab(var_name=var_name, apply=apply, scaler=scaler, groupby=groupby)\n\n    if fillna == \"median\":\n        fillna = df.median()\n    elif fillna == \"mean\":\n        fillna = df.mean()\n    elif fillna == \"zero\":\n        fillna = 0\n\n    df = df.fillna(fillna)\n\n    min_dim = min(df.shape)\n    n_components = min(n_components, min_dim)\n    pca = PCA(n_components)\n    X_projected = pca.fit_transform(df)\n    # Convert to dataframe\n    df_projected = pd.DataFrame(X_projected, index=df.index.get_level_values(0))\n    # Set columns to PC-1, PC-2, ...\n    df_projected.columns = [f\"PC-{int(i) + 1}\" for i in df_projected.columns]\n\n    # Calculate cumulative explained variance in percent\n    explained_variance = pca.explained_variance_ratio_ * 100\n    cum_expl_var = np.cumsum(explained_variance)\n\n    # Create feature contributions\n    a = np.zeros((n_components, n_components), int)\n    np.fill_diagonal(a, 1)\n    dfc = pd.DataFrame(pca.inverse_transform(a))\n    dfc.columns = df.columns\n    dfc.index = [f\"PC-{i + 1}\" for i in range(n_components)]\n    dfc.index.name = \"PC\"\n    # convert to long format\n    dfc = dfc.stack().reset_index().rename(columns={0: \"Coefficient\"})\n\n    self.results = {\n        \"df_projected\": df_projected,\n        \"cum_expl_var\": cum_expl_var,\n        \"n_components\": n_components,\n        \"type\": \"PCA\",\n        \"feature_contributions\": dfc,\n        \"class\": pca,\n    }\n</code></pre>"},{"location":"user_guide/","title":"Overview of user guide","text":""},{"location":"user_guide/#ms-mint-mass-spectrometry-metabolomics-integration-toolkit","title":"MS-MINT: Mass Spectrometry Metabolomics Integration Toolkit","text":""},{"location":"user_guide/#introduction","title":"Introduction","text":"<p>MS-MINT is a powerful Python library designed for comprehensive analysis of mass spectrometry data in metabolomics research. It provides an integrated workflow for processing, analyzing, and visualizing metabolomic datasets.</p>"},{"location":"user_guide/#key-features","title":"Key Features","text":""},{"location":"user_guide/#1-data-processing","title":"1. Data Processing","text":"<ul> <li>Support for multiple mass spectrometry file formats (mzXML, mzML, mzHDF)</li> <li>Automated peak detection and extraction</li> <li>Flexible target list management</li> <li>Advanced chromatogram analysis</li> </ul>"},{"location":"user_guide/#2-visualization","title":"2. Visualization","text":"<ul> <li>Interactive and static plotting</li> <li>Heatmaps</li> <li>Peak shape visualization</li> <li>Chromatogram plotting</li> <li>2D histogram analysis</li> </ul>"},{"location":"user_guide/#3-analysis-capabilities","title":"3. Analysis Capabilities","text":"<ul> <li>Peak integration</li> <li>Retention time alignment</li> <li>Intensity normalization</li> <li>Statistical comparisons</li> </ul>"},{"location":"user_guide/#getting-started","title":"Getting Started","text":""},{"location":"user_guide/#installation","title":"Installation","text":"<pre><code>pip install ms-mint\n</code></pre>"},{"location":"user_guide/#basic-workflow","title":"Basic Workflow","text":"<pre><code>from ms_mint import Mint\n\n# Create a Mint instance\nmint = Mint()\n\n# Load target list\nmint.load_targets('path/to/targets.csv')\n\n# Load mass spectrometry files\nmint.load_ms_files('path/to/ms/files/')\n\n# Run analysis\nmint.run()\n\n# Visualize results\nplotter = mint.plotter\nplotter.heatmap()\nplotter.peak_shapes()\n</code></pre>"},{"location":"user_guide/#core-concepts","title":"Core Concepts","text":""},{"location":"user_guide/#target-lists","title":"Target Lists","text":"<p>Target lists define the specific compounds or peaks of interest in your analysis. They include:</p> <ul> <li>Peak labels</li> <li>Theoretical m/z values</li> <li>Retention time windows</li> <li>Intensity thresholds</li> </ul>"},{"location":"user_guide/#file-formats","title":"File Formats","text":"<p>Supported input formats:</p> <ul> <li>CSV</li> <li>Excel (.xlsx)</li> <li>Mass spectrometry files:</li> <li>mzXML</li> <li>mzML</li> <li>mzHDF</li> </ul>"},{"location":"user_guide/#analysis-steps","title":"Analysis Steps","text":"<ol> <li>Target Definition</li> <li>Create a target list with compound information</li> <li> <p>Specify m/z values, retention times, and other parameters</p> </li> <li> <p>Data Loading</p> </li> <li>Load mass spectrometry files</li> <li>Load target list</li> <li> <p>Configure analysis parameters</p> </li> <li> <p>Peak Extraction</p> </li> <li>Automated peak detection</li> <li>Integration based on target specifications</li> <li> <p>Quality filtering</p> </li> <li> <p>Visualization</p> </li> <li>Multiple visualization options</li> <li>Interactive and static plots</li> <li>Customizable color schemes and layouts</li> </ol>"},{"location":"user_guide/#advanced-usage","title":"Advanced Usage","text":""},{"location":"user_guide/#customization","title":"Customization","text":"<ul> <li>Modify peak detection parameters</li> <li>Custom filtering</li> <li>Advanced visualization options</li> </ul>"},{"location":"user_guide/#experimental-notebook-interface","title":"Experimental Notebook Interface","text":"<pre><code>from ms_mint.notebook import Mint\n\n# Interactive Jupyter Notebook mode\nmint = Mint()\nmint.display()\n</code></pre>"},{"location":"user_guide/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Optimized for large metabolomics datasets</li> <li>Supports parallel processing</li> <li>Memory-efficient data handling</li> </ul>"},{"location":"user_guide/#best-practices","title":"Best Practices","text":"<ol> <li>Data Preparation</li> <li>Use high-quality, clean mass spectrometry data</li> <li>Create precise target lists</li> <li> <p>Validate input files</p> </li> <li> <p>Parameter Tuning</p> </li> <li>Adjust peak detection parameters</li> <li>Validate results through visualization</li> <li> <p>Compare multiple analysis runs</p> </li> <li> <p>Reproducibility</p> </li> <li>Document all analysis parameters</li> <li>Use consistent target lists and settings</li> <li>Export and share results</li> </ol>"},{"location":"user_guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user_guide/#common-issues","title":"Common Issues","text":"<ul> <li>Incorrect file formats</li> <li>Mismatched target list specifications</li> <li>Unexpected peak detection results</li> </ul>"},{"location":"user_guide/#debugging-tips","title":"Debugging Tips","text":"<ul> <li>Check input file integrity</li> <li>Verify target list format</li> <li>Use visualization tools to inspect data</li> <li>Consult documentation and example datasets</li> </ul>"},{"location":"user_guide/#contributing","title":"Contributing","text":"<p>MS-MINT is an open-source project. Contributions are welcome!</p> <ul> <li>Report issues on GitHub</li> <li>Submit pull requests</li> <li>Share improvements and extensions</li> </ul>"},{"location":"user_guide/#citation","title":"Citation","text":"<p>When using MS-MINT in your research, please cite the library in your publications DOI: 10.5281/zenodo.12733875</p>"},{"location":"user_guide/#support","title":"Support","text":"<ul> <li>GitHub Repository: https://github.com/LewisResearchGroup/ms-mint</li> <li>Issue Tracker: https://github.com/LewisResearchGroup/ms-mint/issues</li> </ul>"},{"location":"user_guide/#disclaimer","title":"Disclaimer","text":"<p>MS-MINT is provided as-is. Always validate results and consult domain experts.</p>"},{"location":"user_guide/file_formats/","title":"Supported file formats","text":"<p>MS-MINT is designed to support a variety of mass spectrometry (MS) data formats by converting them into a standardized tabular format for downstream analysis. Here's a breakdown of the file types you can use with MS-MINT, based on your code:</p>"},{"location":"user_guide/file_formats/#supported-file-formats-in-ms-mint","title":"Supported File Formats in MS-MINT","text":"Format Extension Description Read By Function mzXML <code>.mzxml</code> An older open XML-based format for MS data. <code>mzxml_to_df()</code> mzML <code>.mzml</code> Widely used open standard for MS data (XML-based). <code>mzml_to_df()</code> mzMLb <code>.mzmlb</code> A binary-efficient variant of mzML (faster, smaller). <code>mzmlb_to_df__pyteomics()</code> HDF5 <code>.hdf</code>, <code>.h5</code> Hierarchical format often used for storing large numerical datasets. <code>pd.read_hdf()</code> Feather <code>.feather</code> Fast, lightweight binary format for DataFrames (used with Arrow). <code>pd.read_feather()</code> Parquet <code>.parquet</code> Columnar data format for fast read and compression. <code>pd.read_parquet()</code>"},{"location":"user_guide/file_formats/#how-it-works","title":"How It Works","text":"<p>The function <code>ms_file_to_df()</code> acts as a universal file loader. It:</p> <ol> <li>Detects the file extension (e.g., <code>.mzML</code>, <code>.hdf</code>, etc.)</li> <li>Dispatches to the appropriate reader (e.g., <code>mzml_to_df</code>, <code>read_parquet</code>)</li> <li>Normalizes the schema to include the following standard columns:</li> </ol> <pre><code>[\"scan_id\", \"ms_level\", \"polarity\", \"scan_time\", \"mz\", \"intensity\"]\n</code></pre> <p>These columns are crucial for MS-MINT processing and analysis.</p>"},{"location":"user_guide/file_formats/#special-cases-and-notes","title":"Special Cases and Notes","text":"<ul> <li>Time Unit Handling:</li> <li> <p>mzXML and mzML files may report scan times in minutes, but MS-MINT normalizes this to seconds.</p> </li> <li> <p>Thermo RAW Parquet Files:</p> </li> <li> <p>If you load a <code>.parquet</code> file not already in MS-MINT format, MS-MINT attempts to reformat it using <code>format_thermo_raw_file_reader_parquet()</code>.</p> </li> <li> <p>mzMLb Support:</p> </li> <li>Only works if the optional dependency <code>pyteomics.mzmlb</code> is available.</li> <li>If not installed, MS-MINT will log a warning but still function for other formats.</li> </ul>"},{"location":"user_guide/target_lists/","title":"Target Lists User Manual","text":""},{"location":"user_guide/target_lists/#introduction","title":"Introduction","text":"<p>Target lists are essential tools in mass spectrometry data analysis, defining precise parameters for extracting and analyzing peaks of interest in chromatographic data.</p>"},{"location":"user_guide/target_lists/#example-target-list","title":"Example Target List","text":"peak_label mz_mean mz_width rt rt_min rt_max rt_unit intensity_threshold target_filename Caffeine 195.0875 10 3.5 3.0 4.0 min 0 caffeine_targets.csv Glucose 203.0794 10 2.7 2.3 3.1 min 0 sugar_targets.csv Acetaminophen 152.0706 10 4.2 3.8 4.6 min 0 drug_targets.csv"},{"location":"user_guide/target_lists/#target-list-structure","title":"Target List Structure","text":"<p>A target list is a pandas DataFrame with nine key columns:</p>"},{"location":"user_guide/target_lists/#1-peak_label","title":"1. peak_label","text":"<ul> <li>Type: String</li> <li>Description: Unique identifier for each peak</li> <li>Key Features:</li> <li>Must be unique across the entire list</li> <li>Automatically converted to string type</li> <li>Default labels (e.g., \"C_0\", \"C_1\") generated if not provided</li> </ul>"},{"location":"user_guide/target_lists/#2-mz_mean","title":"2. mz_mean","text":"<ul> <li>Type: Numeric </li> <li>Description: Theoretical m/z (mass-to-charge) value of the target ion</li> <li>Capabilities:</li> <li>Can be calculated from chemical formula</li> <li>Critical for precise ion extraction</li> </ul>"},{"location":"user_guide/target_lists/#3-mz_width","title":"3. mz_width","text":"<ul> <li>Type: Numeric</li> <li>Description: Peak width in parts per million (ppm)</li> <li>Details:</li> <li>Default: 10 ppm</li> <li>Mass window calculated by: <code>m/z * 1e-6 * mz_width</code></li> </ul>"},{"location":"user_guide/target_lists/#4-rt-retention-time","title":"4. rt (Retention Time)","text":"<ul> <li>Type: Numeric or None</li> <li>Description: Expected peak time</li> <li>Notes: </li> <li>Optional field</li> <li>Informs peak optimization procedures</li> <li>Not directly used in processing</li> </ul>"},{"location":"user_guide/target_lists/#5-rt_min","title":"5. rt_min","text":"<ul> <li>Type: Numeric</li> <li>Description: Starting time for peak integration</li> </ul>"},{"location":"user_guide/target_lists/#6-rt_max","title":"6. rt_max","text":"<ul> <li>Type: Numeric </li> <li>Description: Ending time for peak integration</li> </ul>"},{"location":"user_guide/target_lists/#7-rt_unit","title":"7. rt_unit","text":"<ul> <li>Allowed Values: </li> <li><code>s</code> (seconds)</li> <li><code>min</code> (minutes)</li> <li>Behavior:</li> <li>Automatic conversions:<ul> <li>\"m\", \"minute\", \"minutes\" \u2192 \"min\"</li> <li>\"sec\", \"second\", \"seconds\" \u2192 \"s\"</li> </ul> </li> <li>Standardizes to seconds internally</li> </ul>"},{"location":"user_guide/target_lists/#8-intensity_threshold","title":"8. intensity_threshold","text":"<ul> <li>Type: Numeric (\u2265 0)</li> <li>Description: Minimum intensity for peak inclusion</li> <li>Recommendation: 0 (no filtering)</li> </ul>"},{"location":"user_guide/target_lists/#9-target_filename","title":"9. target_filename","text":"<ul> <li>Type: String</li> <li>Purpose: Tracking origin of target list</li> <li>Usage: Informational only, not used in processing</li> </ul>"},{"location":"user_guide/target_lists/#working-with-target-lists","title":"Working with Target Lists","text":""},{"location":"user_guide/target_lists/#supported-file-formats","title":"Supported File Formats","text":"<ul> <li>CSV (.csv)</li> <li>Excel (.xlsx)</li> </ul>"},{"location":"user_guide/target_lists/#reading-target-lists","title":"Reading Target Lists","text":"<pre><code>from ms_mint.targets import read_targets\n\n# Load a single file\ntargets = read_targets('your_target_list.csv')\n\n# Load multiple files\ntargets = read_targets(['file1.csv', 'file2.xlsx'])\n</code></pre>"},{"location":"user_guide/target_lists/#creating-target-list-programmatically","title":"Creating Target List Programmatically","text":"<pre><code>import pandas as pd\n\ntargets = pd.DataFrame({\n    'peak_label': ['Caffeine', 'Glucose', 'Acetaminophen'],\n    'mz_mean': [195.0875, 203.0794, 152.0706],\n    'mz_width': [10, 10, 10],\n    'rt': [3.5, 2.7, 4.2],\n    'rt_min': [3.0, 2.3, 3.8],\n    'rt_max': [4.0, 3.1, 4.6],\n    'rt_unit': ['min', 'min', 'min'],\n    'intensity_threshold': [0, 0, 0],\n    'target_filename': ['caffeine_targets.csv', 'sugar_targets.csv', 'drug_targets.csv']\n})\n</code></pre>"},{"location":"user_guide/target_lists/#advanced-functionality","title":"Advanced Functionality","text":""},{"location":"user_guide/target_lists/#generating-target-grids","title":"Generating Target Grids","text":"<p>Create a comprehensive grid of targets across retention times:</p> <pre><code>from ms_mint.targets import gen_target_grid\n\nmasses = [100.5, 200.7, 300.2]\ntargets = gen_target_grid(\n    masses=masses,      # List of m/z values\n    dt=0.5,             # Time window size [min]\n    rt_max=10,          # Maximum retention time\n    mz_ppm=10,          # Mass width [ppm]\n    intensity_threshold=0\n)\n</code></pre>"},{"location":"user_guide/target_lists/#comparing-target-lists","title":"Comparing Target Lists","text":"<p>Identify new or changed targets:</p> <pre><code>from ms_mint.targets import diff_targets\n\ndifferences = diff_targets(old_target_list, new_target_list)\n</code></pre>"},{"location":"user_guide/target_lists/#validation-and-troubleshooting","title":"Validation and Troubleshooting","text":""},{"location":"user_guide/target_lists/#validate-target-list","title":"Validate Target List","text":"<pre><code>from ms_mint.targets import check_targets\n\nis_valid = check_targets(your_target_list)\n</code></pre> <p>Validation checks include: - Correct DataFrame structure - Unique string labels - Proper column configuration</p>"},{"location":"user_guide/target_lists/#common-issues","title":"Common Issues","text":"<ul> <li>Duplicate Labels: Ensure unique <code>peak_label</code></li> <li>Unit Conversion: Be careful with retention time units</li> <li>Mass Calculations: Verify m/z values carefully</li> </ul>"},{"location":"user_guide/visualization/","title":"Visualization","text":""},{"location":"user_guide/visualization/#overview","title":"Overview","text":"<p>The MS-MINT visualization tools provide powerful and flexible ways to explore mass spectrometry data, offering both static (Matplotlib) and interactive (Plotly) visualization options.</p>"},{"location":"user_guide/visualization/#visualization-types","title":"Visualization Types","text":""},{"location":"user_guide/visualization/#1-heatmaps","title":"1. Heatmaps","text":""},{"location":"user_guide/visualization/#static-heatmaps","title":"Static Heatmaps","text":"<pre><code># Hierarchical clustering heatmap\nplotter.hierarchical_clustering(\n    data=your_dataframe,      # Data to visualize\n    vmin=-3,                  # Minimum value for color scaling\n    vmax=3,                   # Maximum value for color scaling\n    metric='cosine',          # Distance metric for clustering\n    figsize=(8, 8),           # Figure size\n    xmaxticks=10,             # Maximum x-axis ticks\n    ymaxticks=10              # Maximum y-axis ticks\n)\n</code></pre>"},{"location":"user_guide/visualization/#interactive-heatmaps","title":"Interactive Heatmaps","text":"<pre><code># Create an interactive heatmap\nplotter.heatmap(\n    col_name='peak_max',      # Column to visualize\n    normed_by_cols=True,      # Normalize by column\n    transposed=False,         # Transpose matrix\n    clustered=True,           # Apply hierarchical clustering\n    correlation=False         # Convert to correlation matrix\n)\n</code></pre>"},{"location":"user_guide/visualization/#heatmap-options","title":"Heatmap Options","text":"<ul> <li>Normalization: Scale data by column maximum</li> <li>Clustering: Hierarchical clustering of rows/columns</li> <li>Correlation: Convert to correlation matrix</li> <li>Color Scaling: Customize color range and palette</li> </ul>"},{"location":"user_guide/visualization/#2-peak-shapes","title":"2. Peak Shapes","text":""},{"location":"user_guide/visualization/#static-peak-shape-plots","title":"Static Peak Shape Plots","text":"<pre><code># Plot peak shapes from results\nplotter.peak_shapes(\n    fns=['file1.mzXML', 'file2.mzXML'],  # Specific files\n    peak_labels=['Caffeine', 'Glucose'],  # Specific peaks\n    height=3,                 # Facet height\n    aspect=1.5,               # Facet aspect ratio\n    col_wrap=4,               # Maximum columns\n    legend=True               # Show legend\n)\n</code></pre>"},{"location":"user_guide/visualization/#interactive-peak-shape-plots","title":"Interactive Peak Shape Plots","text":"<pre><code># Interactive peak shape visualization\nplotter.peak_shapes(\n    fns=['file1.mzXML', 'file2.mzXML'],  # Specific files\n    peak_labels=['Caffeine', 'Glucose'],  # Specific peaks\n    interactive=True,         # Use Plotly interactive mode\n    color='ms_file_label'     # Color by file label\n)\n</code></pre>"},{"location":"user_guide/visualization/#3-chromatograms","title":"3. Chromatograms","text":"<pre><code># Plot chromatograms\nplotter.chromatogram(\n    fns=['file1.mzXML', 'file2.mzXML'],  # Specific files\n    peak_labels=['Caffeine', 'Glucose'],  # Specific peaks\n    interactive=False,        # Static plot\n    filters=None              # Optional data filters\n)\n</code></pre>"},{"location":"user_guide/visualization/#4-2d-histograms","title":"4. 2D Histograms","text":"<pre><code># Create 2D histogram of MS file\nplotter.histogram_2d(\n    fn='your_ms_file.mzXML',  # MS file to visualize\n    peak_label='Caffeine',    # Optional peak label to highlight\n    rt_margin=0,              # Retention time margin\n    mz_margin=0               # M/Z margin\n)\n</code></pre>"},{"location":"user_guide/visualization/#advanced-visualization-techniques","title":"Advanced Visualization Techniques","text":""},{"location":"user_guide/visualization/#customization-options","title":"Customization Options","text":"<ul> <li>Color Palettes: Choose from various color schemes</li> <li>Interactive vs. Static: Switch between Plotly and Matplotlib</li> <li>Filtering: Select specific files or peaks</li> <li>Scaling: Normalize and transform data</li> </ul>"},{"location":"user_guide/visualization/#color-customization","title":"Color Customization","text":"<pre><code># Use different color palettes\nplotter.peak_shapes(\n    palette='Plasma',         # Color palette\n    color='ms_file_label'     # Color grouping\n)\n</code></pre>"},{"location":"user_guide/visualization/#best-practices","title":"Best Practices","text":"<ol> <li>Data Preprocessing: Ensure data is clean and standardized</li> <li>Choose Appropriate Visualization: Match plot type to your analysis goals</li> <li>Interactive vs. Static: </li> <li>Use interactive for detailed exploration</li> <li>Use static for publications/reports</li> <li>Color Choices: Select palettes that are color-blind friendly</li> </ol>"},{"location":"user_guide/visualization/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>No Data Displayed: </li> <li>Check data filtering</li> <li>Verify peak labels and file names</li> <li>Performance Issues: </li> <li>Reduce data size</li> <li>Use interactive mode for large datasets</li> <li>Color Mapping: Ensure unique color mapping for different groups</li> </ul>"},{"location":"user_guide/visualization/#performance-tips","title":"Performance Tips","text":"<ul> <li>For large datasets, use interactive Plotly visualizations</li> <li>Limit the number of peaks and files in a single plot</li> <li>Use normalization and scaling to improve visualization clarity</li> </ul>"},{"location":"user_guide/visualization/#example-workflow","title":"Example Workflow","text":"<pre><code>from ms_mint import Mint\n\n# Create Mint instance\nmint = Mint()\n\n# Load data\nmint.load_targets('targets.csv')\nmint.load_ms_files('data_directory/*')\n\n# Run analysis\nmint.run()\n\n# Create plotter\nplotter = mint.plot\n\n# Visualize results\nplotter.heatmap(col_name='peak_max')\nplotter.peak_shapes(interactive=True)\nplotter.chromatogram()\n</code></pre>"},{"location":"user_guide/visualization/#notes","title":"Notes","text":"<ul> <li>Visualization tools are designed to be flexible and intuitive</li> <li>Always verify data and visualization parameters</li> <li>Experiment with different visualization techniques</li> </ul>"}]}